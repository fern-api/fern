{
  "absoluteFilePath": "/DUMMY_PATH",
  "importedDefinitions": {},
  "namedDefinitionFiles": {
    "__package__.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "errors": {
          "DatasetsCommitRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DatasetsCreateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DatasetsDeleteRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DatasetsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DatasetsListDatapointsRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DatasetsListRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DatasetsListVersionsRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DatasetsUpdateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DebugEvaluatorsDebugPostRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DeployDatasetsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DeployEvaluatorsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DeployPromptsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "DeployToolsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluationsCreateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluationsDeleteRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluationsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluationsGetStatsRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluationsListRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluationsUpdateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluationsUpdateStatusRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsCommitRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsCreateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsDeleteRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsListDefaultRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsListRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsListVersionsRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "EvaluatorsUpdateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ListLogsForFileLogsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ListTemplatesToolsTemplatesGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "LogsDeleteRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "LogsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsCallRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsCommitRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsCreateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsDeleteRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsListRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsListVersionsRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsLogRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "PromptsUpdateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "SessionsDeleteRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "SessionsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "SessionsListRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsCommitRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsCreateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsDeleteRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsGetRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsListRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsListVersionsRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsLogRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "ToolsUpdateRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "UpdateEvaluatorsPromptsIdEvaluatorsPostRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
          "UpdateEvaluatorsToolsIdEvaluatorsPostRequestUnprocessableEntityError": {
            "docs": "Validation Error",
            "examples": [
              {
                "docs": undefined,
                "name": undefined,
                "value": {},
              },
            ],
            "status-code": 422,
            "type": "HTTPValidationError",
          },
        },
        "types": {
          "AgentConfigResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "agent_class": {
                "docs": "Class of the agent.",
                "type": "string",
              },
              "created_by": {
                "docs": "The user who created the config.",
                "type": "optional<UserResponse>",
              },
              "description": {
                "docs": "Description of config.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "String ID of config. Starts with `config_`.",
                "type": "string",
              },
              "model_config": {
                "docs": "Model config associated with the agent.",
                "type": "ModelConfigRequest",
              },
              "name": {
                "docs": "Name of config.",
                "type": "string",
              },
              "other": {
                "docs": "Other parameters that define the config.",
                "type": "optional<map<string, unknown>>",
              },
              "status": {
                "docs": "Whether the config is committed or not.",
                "type": "string",
              },
              "tools": {
                "docs": "Tools associated with the agent.",
                "type": "optional<list<ToolConfigRequest>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "BooleanEvaluatorVersionStats": {
            "docs": "Base attributes for stats for an Evaluator Version-Evaluated Version pair
in the Evaluation Report.",
            "inline": undefined,
            "properties": {
              "evaluator_version_id": {
                "docs": "Unique identifier for the Evaluator Version.",
                "type": "string",
              },
              "num_errors": {
                "docs": "The total number of errored Evaluators for this Evaluator Version.",
                "type": "integer",
              },
              "num_false": {
                "docs": "The total number of `False` judgments for this Evaluator Version.",
                "type": "integer",
              },
              "num_judgments": {
                "docs": "The total number of Evaluator judgments for this Evaluator Version. This excludes Nulls and Errors.",
                "type": "integer",
              },
              "num_nulls": {
                "docs": "The total number of null judgments (i.e. abstentions) for this Evaluator Version.",
                "type": "integer",
              },
              "num_true": {
                "docs": "The total number of `True` judgments for this Evaluator Version.",
                "type": "integer",
              },
              "total_logs": {
                "docs": "The total number of Logs generated by this Evaluator Version on the Evaluated Version's Logs. This includes Nulls and Errors.",
                "type": "integer",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "CategoricalFeedbackLabel": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "sentiment": {
                "docs": "Whether the feedback sentiment is positive or negative.",
                "type": "LabelSentiment",
              },
              "status": {
                "docs": "Whether the feedback label is active or inactive.",
                "type": "FeedbackLabelStatus",
              },
              "value": "string",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ChatMessage": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "content": {
                "docs": "The content of the message.",
                "type": "optional<Content>",
              },
              "name": {
                "docs": "Optional name of the message author.",
                "type": "optional<string>",
              },
              "role": {
                "docs": "Role of the message author.",
                "type": "ChatRole",
              },
              "tool_call_id": {
                "docs": "Tool call that this message is responding to.",
                "type": "optional<string>",
              },
              "tool_calls": {
                "docs": "A list of tool calls requested by the assistant.",
                "type": "optional<list<ToolCall>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ChatMessageContentItem": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": {
              "image_url": {
                "type": "ImageChatContent",
              },
              "text": {
                "type": "TextChatContent",
              },
            },
          },
          "ChatMessageWithToolCall": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "content": {
                "docs": "The content of the message.",
                "type": "optional<Content>",
              },
              "name": {
                "docs": "Optional name of the message author.",
                "type": "optional<string>",
              },
              "role": {
                "docs": "Role of the message author.",
                "type": "ChatRole",
              },
              "tool_call": {
                "availability": "deprecated",
                "docs": "NB: Deprecated in favour of tool_calls. A tool call requested by the assistant.",
                "type": "optional<FunctionTool>",
              },
              "tool_call_id": {
                "docs": "Tool call that this message is responding to.",
                "type": "optional<string>",
              },
              "tool_calls": {
                "docs": "A list of tool calls requested by the assistant.",
                "type": "optional<list<ToolCall>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ChatMessageWithToolCallContentItem": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": {
              "image_url": {
                "type": "ImageChatContent",
              },
              "text": {
                "type": "TextChatContent",
              },
            },
          },
          "ChatRole": {
            "docs": "An enumeration.",
            "enum": [
              "user",
              "assistant",
              "system",
              "tool",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "CodeEvaluatorRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "arguments_type": {
                "docs": "Whether this evaluator is target-free or target-required.",
                "type": "EvaluatorArgumentsType",
              },
              "code": {
                "docs": "The code for the evaluator. This code will be executed in a sandboxed environment.",
                "type": "optional<string>",
              },
              "return_type": {
                "docs": "The type of the return value of the evaluator.",
                "type": "EvaluatorReturnTypeEnum",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "CommitRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "commit_message": {
                "docs": "Message describing the changes made.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ConfigResponse": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": {
              "agent": {
                "type": "AgentConfigResponse",
              },
              "evaluator": {
                "type": "EvaluatorConfigResponse",
              },
              "generic": {
                "type": "GenericConfigResponse",
              },
              "model": {
                "type": "ModelConfigResponse",
              },
              "tool": {
                "type": "ToolConfigResponse",
              },
            },
          },
          "Content": {
            "discriminated": false,
            "docs": "The content of the message.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<ChatMessageWithToolCallContentItem>",
            ],
          },
          "CreateDatapointRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "inputs": {
                "docs": "The inputs to the prompt template.",
                "type": "optional<map<string, string>>",
              },
              "messages": {
                "docs": "List of chat messages to provide to the model.",
                "type": "optional<list<ChatMessage>>",
              },
              "target": {
                "docs": "Object with criteria necessary to evaluate generations with this Datapoint. This is passed in as an argument to Evaluators when used in an Evaluation.",
                "type": "optional<map<string, CreateDatapointRequestTargetValue>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "CreateDatapointRequestTargetValue": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "integer",
              "double",
              "boolean",
              "map<string, unknown>",
              "list<unknown>",
            ],
          },
          "CreateEvaluationRequest": {
            "docs": "Request model for creating an Evaluation.

Evaluation benchmark your Prompt/Tool Versions. With the Datapoints in a Dataset Version,
Logs corresponding to the Datapoint and each Evaluated Version are evaluated by the specified Evaluator Versions.
Aggregated statistics are then calculated and presented in the Evaluation.",
            "inline": undefined,
            "properties": {
              "dataset": {
                "docs": "The Dataset Version to use in this Evaluation.",
                "type": "DatasetRequest",
              },
              "evaluatees": {
                "docs": "Unique identifiers for the Prompt/Tool Versions to include in the Evaluation Report.",
                "type": "list<EvaluateeRequest>",
              },
              "evaluators": {
                "docs": "The Evaluators used to evaluate.",
                "type": "list<EvaluatorRequest>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "CreatePromptLogResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "String ID of log.",
                "type": "string",
              },
              "prompt_id": {
                "docs": "ID of the Prompt the log belongs to.",
                "type": "string",
              },
              "session_id": {
                "docs": "String ID of session the log belongs to.",
                "type": "optional<string>",
              },
              "version_id": {
                "docs": "ID of the specific version of the Prompt.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "CreateToolLogResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "String ID of log.",
                "type": "string",
              },
              "session_id": {
                "docs": "String ID of session the log belongs to.",
                "type": "optional<string>",
              },
              "tool_id": {
                "docs": "ID of the Prompt the log belongs to.",
                "type": "string",
              },
              "version_id": {
                "docs": "ID of the specific version of the Tool.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "DashboardConfiguration": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "model_config_ids": {
                "type": "list<string>",
              },
              "time_range_days": "integer",
              "time_unit": {
                "type": "TimeUnit",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "DatapointResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "Unique identifier for the Datapoint. Starts with `dp_`.",
                "type": "string",
              },
              "inputs": {
                "docs": "The inputs to the prompt template.",
                "type": "optional<map<string, string>>",
              },
              "messages": {
                "docs": "List of chat messages to provide to the model.",
                "type": "optional<list<ChatMessage>>",
              },
              "target": {
                "docs": "Object with criteria necessary to evaluate generations with this Datapoint. This is passed in as an argument to Evaluators when used in an Evaluation.",
                "type": "optional<map<string, DatapointResponseTargetValue>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "DatapointResponseTargetValue": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "integer",
              "double",
              "boolean",
              "map<string, unknown>",
              "list<unknown>",
            ],
          },
          "DatasetRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "version_id": {
                "docs": "Unique identifier for the Dataset Version to use in this evaluation. Starts with `dsv_`.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "DatasetResponse": {
            "docs": "Base type that all File Responses should inherit from.

Attributes defined here are common to all File Responses and should be overridden
in the inheriting classes with documentation and appropriate Field definitions.",
            "inline": undefined,
            "properties": {
              "commit_message": {
                "docs": "Message describing the changes made. If provided, a committed version of the Dataset is created. Otherwise, an uncommitted version is created.",
                "type": "optional<string>",
              },
              "created_at": {
                "type": "datetime",
              },
              "created_by": {
                "docs": "The user who created the Dataset.",
                "type": "optional<UserResponse>",
              },
              "datapoints": {
                "docs": "The list of Datapoints in this Dataset version. Only provided if explicitly requested.",
                "type": "optional<list<DatapointResponse>>",
              },
              "datapoints_count": {
                "docs": "The number of Datapoints in this Dataset version.",
                "type": "integer",
              },
              "environments": {
                "docs": "The list of environments the Dataset Version is deployed to.",
                "type": "optional<list<EnvironmentResponse>>",
              },
              "id": {
                "docs": "Unique identifier for the Dataset. Starts with `ds_`.",
                "type": "string",
              },
              "last_used_at": {
                "type": "datetime",
              },
              "name": {
                "docs": "Name of the Dataset, which is used as a unique identifier.",
                "type": "string",
              },
              "status": {
                "docs": "The status of the Dataset Version.",
                "type": "VersionStatus",
              },
              "updated_at": {
                "type": "datetime",
              },
              "version_id": {
                "docs": "Unique identifier for the specific Dataset Version. If no query params provided, the default deployed Dataset Version is returned. Starts with `dsv_`.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EnvironmentResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_at": {
                "type": "datetime",
              },
              "id": "string",
              "name": "string",
              "tag": {
                "type": "EnvironmentTag",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EnvironmentTag": {
            "docs": "An enumeration.",
            "enum": [
              "default",
              "other",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluatedVersionResponse": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "PromptResponse",
              },
              {
                "type": "ToolResponse",
              },
            ],
          },
          "EvaluateeRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "batch_id": {
                "docs": "Unique identifier for the batch of Logs to include in the Evaluation Report.",
                "type": "optional<string>",
              },
              "orchestrated": {
                "default": true,
                "docs": "Whether the Prompt/Tool is orchestrated by Humanloop. Default is `True`. If `False`, a log for the Prompt/Tool should be submitted by the user via the API.",
                "type": "optional<boolean>",
              },
              "version_id": {
                "docs": "Unique identifier for the Prompt/Tool Version to include in the Evaluation Report. Starts with `pv_` for Prompts and `tv_` for Tools.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluateeResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "batch_id": {
                "docs": "Unique identifier for the batch of Logs to include in the Evaluation Report. ",
                "type": "optional<string>",
              },
              "orchestrated": {
                "docs": "Whether the Prompt/Tool is orchestrated by Humanloop. Default is `True`. If `False`, a log for the Prompt/Tool should be submitted by the user via the API.",
                "type": "boolean",
              },
              "version": {
                "type": "EvaluatedVersionResponse",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluationDebugResultResponse": {
            "docs": "This is similar to an `EvaluationResult` but is ephemeral as it is only for synchronous
debug runs. It does not have an ID, or a reference to an evaluation run or even an evaluation
function.",
            "inline": undefined,
            "properties": {
              "datapoint_id": {
                "type": "optional<string>",
              },
              "error": {
                "type": "optional<string>",
              },
              "llm_evaluation_log": {
                "type": "optional<LogResponse>",
              },
              "log": {
                "type": "LogResponse",
              },
              "log_id": "string",
              "value": {
                "type": "optional<Value>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluationEvaluatorResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "orchestrated": {
                "docs": "Whether the Evaluator is orchestrated by Humanloop. Default is `True`. If `False`, a log for the Evaluator should be submitted by the user via the API.",
                "type": "boolean",
              },
              "version": {
                "type": "EvaluatorResponse",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluationResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_at": {
                "type": "datetime",
              },
              "created_by": {
                "type": "optional<UserResponse>",
              },
              "dataset": {
                "docs": "The Dataset Version used in the Evaluation.",
                "type": "DatasetResponse",
              },
              "evaluatees": {
                "docs": "The Prompt/Tool Versions included in the Evaluation.",
                "type": "list<EvaluateeResponse>",
              },
              "evaluators": {
                "docs": "The Evaluator Versions used to evaluate.",
                "type": "list<EvaluationEvaluatorResponse>",
              },
              "id": {
                "docs": "Unique identifier for the Evaluation. Starts with `evr`.",
                "type": "string",
              },
              "status": {
                "docs": "The current status of the Evaluation.

- `"pending"`: The Evaluation has been created but is not actively being worked on by Humanloop.
- `"running"`: Humanloop is checking for any missing Logs and Evaluator Logs, and will generate them where appropriate.
- `"completed"`: All Logs an Evaluator Logs have been generated.
- `"cancelled"`: The Evaluation has been cancelled by the user. Humanloop will stop generating Logs and Evaluator Logs.
",
                "type": "EvaluationStatus",
              },
              "updated_at": {
                "type": "datetime",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluationResultResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_at": {
                "type": "datetime",
              },
              "error": {
                "type": "optional<string>",
              },
              "evaluation_id": {
                "type": "optional<string>",
              },
              "evaluator_id": "string",
              "evaluator_version_id": "string",
              "id": "string",
              "llm_evaluator_log": {
                "type": "optional<LogResponse>",
              },
              "log": {
                "type": "optional<LogResponse>",
              },
              "log_id": "string",
              "updated_at": {
                "type": "datetime",
              },
              "value": {
                "type": "optional<Value>",
              },
              "version": {
                "type": "optional<unknown>",
              },
              "version_id": {
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluationStats": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "overall_stats": {
                "docs": "Stats for the Evaluation Report as a whole.",
                "type": "OverallStats",
              },
              "version_stats": {
                "docs": "Stats for each Evaluated Version in the Evaluation Report.",
                "type": "list<VersionStats>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluationStatus": {
            "docs": "Status of an evaluation.",
            "enum": [
              "pending",
              "running",
              "completed",
              "cancelled",
              "failed",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluatorActivationDeactivationRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "evaluators_to_activate": {
                "docs": "Monitoring Evaluators to activate. These will be automatically run on new Logs.",
                "type": "optional<list<EvaluatorActivationDeactivationRequestEvaluatorsToActivateItem>>",
              },
              "evaluators_to_deactivate": {
                "docs": "Evaluators to deactivate. These will not be run on new Logs.",
                "type": "optional<list<EvaluatorActivationDeactivationRequestEvaluatorsToDeactivateItem>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluatorActivationDeactivationRequestEvaluatorsToActivateItem": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "MonitoringEvaluatorVersionRequest",
              },
              {
                "type": "MonitoringEvaluatorEnvironmentRequest",
              },
            ],
          },
          "EvaluatorActivationDeactivationRequestEvaluatorsToDeactivateItem": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "MonitoringEvaluatorVersionRequest",
              },
              {
                "type": "MonitoringEvaluatorEnvironmentRequest",
              },
            ],
          },
          "EvaluatorArgumentsType": {
            "docs": "Enum representing the possible argument types of an evaluator.",
            "enum": [
              "target_free",
              "target_required",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluatorConfigResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "arguments_type": {
                "docs": "Whether this evaluator is target-free or target-required.",
                "type": "optional<EvaluatorArgumentsType>",
              },
              "code": {
                "docs": "The code for the evaluator. This code will be executed in a sandboxed environment.",
                "type": "optional<string>",
              },
              "created_by": {
                "docs": "The user who created the config.",
                "type": "optional<UserResponse>",
              },
              "description": {
                "docs": "Description of config.",
                "type": "optional<string>",
              },
              "evaluator_type": {
                "docs": "Type of evaluator.",
                "type": "string",
              },
              "id": {
                "docs": "String ID of config. Starts with `config_`.",
                "type": "string",
              },
              "model_config": {
                "docs": "The model config defining the LLM evaluator.",
                "type": "optional<ModelConfigResponse>",
              },
              "name": {
                "docs": "Name of config.",
                "type": "string",
              },
              "other": {
                "docs": "Other parameters that define the config.",
                "type": "optional<map<string, unknown>>",
              },
              "return_type": {
                "docs": "The type of the return value of the evaluator.",
                "type": "optional<EvaluatorReturnTypeEnum>",
              },
              "status": {
                "docs": "Whether the config is committed or not.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluatorRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "orchestrated": {
                "default": true,
                "docs": "Whether the Evaluator is orchestrated by Humanloop. Default is `True`. If `False`, a log for the Evaluator should be submitted by the user via the API.",
                "type": "optional<boolean>",
              },
              "version_id": {
                "docs": "Unique identifier for the Evaluator Version to use in this evaluation. Starts with `evv_`.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluatorResponse": {
            "docs": "Request model for creating a new Evaluator",
            "inline": undefined,
            "properties": {
              "commit_message": {
                "docs": "Message describing the changes made.",
                "type": "optional<string>",
              },
              "created_at": {
                "type": "datetime",
              },
              "created_by": {
                "docs": "The user who created the Prompt.",
                "type": "optional<UserResponse>",
              },
              "directory_id": {
                "docs": "Unique identifier for the Directory of the Evaluator.",
                "type": "optional<string>",
              },
              "environments": {
                "docs": "The list of environments the Prompt Version is deployed to.",
                "type": "optional<list<EnvironmentResponse>>",
              },
              "id": {
                "docs": "Unique identifier for the Evaluator.",
                "type": "string",
              },
              "inputs": {
                "docs": "Inputs associated to the Prompt. Inputs correspond to any of the variables used within the Prompt template.",
                "type": "list<InputResponse>",
              },
              "last_used_at": {
                "type": "datetime",
              },
              "name": {
                "docs": "Name of the Evaluator, which is used as a unique identifier.",
                "type": "string",
              },
              "spec": {
                "display-name": "Spec",
                "type": "Spec",
              },
              "status": {
                "type": "VersionStatus",
              },
              "total_logs_count": {
                "docs": "The number of logs that have been generated across all Prompt Versions",
                "type": "integer",
              },
              "updated_at": {
                "type": "datetime",
              },
              "version_id": {
                "docs": "Unique identifier for the specific Evaluator Version. If no query params provided, the default deployed Evaluator Version is returned.",
                "type": "string",
              },
              "version_logs_count": {
                "docs": "The number of logs that have been generated for this Prompt Version",
                "type": "integer",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "EvaluatorReturnTypeEnum": {
            "docs": "Enum representing the possible return types of an evaluator.",
            "enum": [
              "boolean",
              "number",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "FeedbackClass": {
            "docs": "An enumeration.",
            "enum": [
              "select",
              "multi_select",
              "text",
              "number",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "FeedbackLabelStatus": {
            "docs": "Controls whether the label is displayed in the UI.",
            "enum": [
              "unset",
              "active",
              "inactive",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "FeedbackResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_at": {
                "docs": "User defined timestamp for when the feedback was created. ",
                "type": "optional<datetime>",
              },
              "data_id": {
                "docs": "ID to associate the feedback to a previously logged datapoint.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "String ID of user feedback. Starts with `ann_`, short for annotation.",
                "type": "string",
              },
              "type": {
                "display-name": "Feedback type",
                "docs": "The type of feedback. The default feedback types available are 'rating', 'action', 'issue', 'correction', and 'comment'.",
                "type": "FeedbackResponseType",
              },
              "user": {
                "docs": "A unique identifier to who provided the feedback.",
                "type": "optional<string>",
              },
              "value": {
                "display-name": "Feedback value",
                "docs": "The feedback value to set. This would be the appropriate text for 'correction' or 'comment', or a label to apply for 'rating', 'action', or 'issue'.",
                "type": "FeedbackResponseValue",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "FeedbackResponseType": {
            "discriminated": false,
            "docs": "The type of feedback. The default feedback types available are 'rating', 'action', 'issue', 'correction', and 'comment'.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "FeedbackType",
              },
              "string",
            ],
          },
          "FeedbackResponseValue": {
            "discriminated": false,
            "docs": "The feedback value to set. This would be the appropriate text for 'correction' or 'comment', or a label to apply for 'rating', 'action', or 'issue'.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "double",
              "string",
            ],
          },
          "FeedbackType": {
            "docs": "An enumeration.",
            "enum": [
              "rating",
              "action",
              "issue",
              "correction",
              "comment",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "FeedbackTypeModel": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "type": {
                "display-name": "Feedback type",
                "docs": "The type of feedback. The default feedback types available are 'rating', 'action', 'issue', 'correction', and 'comment'.",
                "type": "FeedbackTypeModelType",
              },
              "values": {
                "docs": "The allowed values for categorical feedback types. Not populated for `correction` and `comment`.",
                "type": "optional<list<CategoricalFeedbackLabel>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "FeedbackTypeModelType": {
            "discriminated": false,
            "docs": "The type of feedback. The default feedback types available are 'rating', 'action', 'issue', 'correction', and 'comment'.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "FeedbackType",
              },
              "string",
            ],
          },
          "FeedbackTypes": {
            "type": "list<FeedbackTypeModel>",
          },
          "File": {
            "discriminated": false,
            "docs": "The File that the deployed Version belongs to.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "PromptResponse",
              },
              {
                "type": "ToolResponse",
              },
              {
                "type": "DatasetResponse",
              },
              {
                "type": "EvaluatorResponse",
              },
            ],
          },
          "FunctionTool": {
            "docs": "A function tool to be called by the model where user owns runtime.",
            "inline": undefined,
            "properties": {
              "arguments": {
                "type": "optional<string>",
              },
              "name": "string",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "FunctionToolChoice": {
            "docs": "A function tool to be called by the model where user owns runtime.",
            "inline": undefined,
            "properties": {
              "name": "string",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "GenericConfigResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_by": {
                "docs": "The user who created the config.",
                "type": "optional<UserResponse>",
              },
              "description": {
                "docs": "Description of config.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "String ID of config. Starts with `config_`.",
                "type": "string",
              },
              "name": {
                "docs": "Name of config.",
                "type": "string",
              },
              "other": {
                "docs": "Other parameters that define the config.",
                "type": "optional<map<string, unknown>>",
              },
              "status": {
                "docs": "Whether the config is committed or not.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "HTTPValidationError": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "detail": {
                "type": "optional<list<ValidationError>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "HumanEvaluatorRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "arguments_type": {
                "docs": "Whether this evaluator is target-free or target-required.",
                "type": "EvaluatorArgumentsType",
              },
              "return_type": {
                "docs": "The type of the return value of the evaluator.",
                "type": "EvaluatorReturnTypeEnum",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ImageChatContent": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "image_url": {
                "docs": "The message's image content.",
                "type": "ImageUrl",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ImageUrl": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "detail": {
                "docs": "Specify the detail level of the image provided to the model. For more details see: https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding",
                "type": "optional<ImageUrlDetail>",
              },
              "url": {
                "docs": "Either a URL of the image or the base64 encoded image data.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ImageUrlDetail": {
            "docs": "Specify the detail level of the image provided to the model. For more details see: https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding",
            "enum": [
              "high",
              "low",
              "auto",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "InputResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "name": {
                "docs": "Type of input.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "Judgment": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "boolean",
              "double",
            ],
          },
          "LLMEvaluatorRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "arguments_type": {
                "docs": "Whether this evaluator is target-free or target-required.",
                "type": "EvaluatorArgumentsType",
              },
              "prompt": {
                "docs": "The prompt parameters used to generate.",
                "type": "optional<PromptKernelRequest>",
              },
              "return_type": {
                "docs": "The type of the return value of the evaluator.",
                "type": "EvaluatorReturnTypeEnum",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "LabelSentiment": {
            "docs": "How a label should be treated in calculating Version performance.

Used by a File's PAPV (Positive Action Per View) metric.",
            "enum": [
              "positive",
              "negative",
              "neutral",
              "unset",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "LinkedToolRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "description": {
                "docs": "The description of the linked tool.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "The ID of the linked tool. Starts with "oc_"",
                "type": "string",
              },
              "name": {
                "docs": "The name of the linked tool.",
                "type": "optional<string>",
              },
              "parameters": {
                "docs": "The parameters of the linked tool.",
                "type": "optional<map<string, unknown>>",
              },
              "source": {
                "docs": "The source of the linked tool. For a linked tool it should be `organization`",
                "type": "literal<"organization">",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "LinkedToolResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "description": {
                "docs": "Description of the tool referenced by the model",
                "type": "string",
              },
              "id": {
                "docs": "Unique identifier for the Tool linked.",
                "type": "string",
              },
              "name": {
                "docs": "Name for the tool referenced by the model.",
                "type": "string",
              },
              "parameters": {
                "docs": "Parameters needed to run the Tool, defined in JSON Schema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "version_id": {
                "docs": "Unique identifier for the Tool Version linked.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ListDatasets": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "records": {
                "docs": "The list of Datasets.",
                "type": "list<DatasetResponse>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ListEvaluators": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "records": {
                "docs": "The list of Evaluators.",
                "type": "list<EvaluatorResponse>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ListPrompts": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "records": {
                "docs": "The list of Prompts.",
                "type": "list<PromptResponse>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ListTools": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "records": {
                "docs": "The list of Tools.",
                "type": "list<ToolResponse>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "LogResponse": {
            "docs": "Request model for logging a datapoint.",
            "inline": undefined,
            "properties": {
              "batch_ids": {
                "docs": "List of batch IDs the log belongs to.",
                "type": "optional<list<string>>",
              },
              "config": {
                "type": "ConfigResponse",
              },
              "config_id": {
                "docs": "Unique ID of a config to associate to the log.",
                "type": "optional<string>",
              },
              "created_at": {
                "docs": "User defined timestamp for when the log was created. ",
                "type": "optional<datetime>",
              },
              "duration": {
                "docs": "Duration of the logged event in seconds.",
                "type": "optional<double>",
              },
              "environment": {
                "docs": "The environment name used to create the log.",
                "type": "optional<string>",
              },
              "error": {
                "docs": "Error message if the log is an error.",
                "type": "optional<string>",
              },
              "evaluation_results": {
                "type": "list<EvaluationResultResponse>",
              },
              "feedback": {
                "type": "optional<list<FeedbackResponse>>",
              },
              "finish_reason": {
                "docs": "Reason the generation finished.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "String ID of logged datapoint. Starts with `data_`.",
                "type": "string",
              },
              "inputs": {
                "docs": "The inputs passed to the prompt template.",
                "type": "optional<map<string, unknown>>",
              },
              "judgment": {
                "type": "optional<Judgment>",
              },
              "messages": {
                "docs": "The messages passed to the to provider chat endpoint.",
                "type": "optional<list<ChatMessageWithToolCall>>",
              },
              "metadata": {
                "docs": "Any additional metadata to record.",
                "type": "optional<map<string, unknown>>",
              },
              "metric_values": {
                "type": "optional<list<MetricValueResponse>>",
              },
              "observability_status": {
                "type": "ObservabilityStatus",
              },
              "output": {
                "docs": "Generated output from your model for the provided inputs. Can be `None` if logging an error, or if logging a parent datapoint with the intention to populate it later",
                "type": "optional<string>",
              },
              "output_cost": {
                "docs": "Cost in dollars associated to the tokens in the output.",
                "type": "optional<double>",
              },
              "output_message": {
                "docs": "The message returned by the provider.",
                "type": "optional<ChatMessageWithToolCall>",
              },
              "output_tokens": {
                "docs": "Number of tokens in the output generated by the model.",
                "type": "optional<integer>",
              },
              "parent_id": {
                "docs": "ID associated to the parent datapoint in a session.",
                "type": "optional<string>",
              },
              "parent_reference_id": {
                "docs": "A unique string identifying the previously-logged parent datapoint in a session. Allows you to log nested datapoints with your internal system IDs by passing the same reference ID as `parent_id` in a prior log request. Specify at most one of this or `parent_id`. Note that this cannot refer to a datapoint being logged in the same request.",
                "type": "optional<string>",
              },
              "project": {
                "docs": "The name of the project associated with this log",
                "type": "optional<string>",
              },
              "project_id": {
                "docs": "The unique ID of the project associated with this log.",
                "type": "optional<string>",
              },
              "prompt_cost": {
                "docs": "Cost in dollars associated to the tokens in the prompt.",
                "type": "optional<double>",
              },
              "prompt_tokens": {
                "docs": "Number of tokens in the prompt used to generate the output.",
                "type": "optional<integer>",
              },
              "provider_latency": {
                "docs": "Latency of provider response.",
                "type": "optional<double>",
              },
              "provider_request": {
                "docs": "Raw request sent to provider.",
                "type": "optional<map<string, unknown>>",
              },
              "provider_response": {
                "docs": "Raw response received the provider.",
                "type": "optional<map<string, unknown>>",
              },
              "raw_output": {
                "docs": "Raw output from the provider.",
                "type": "optional<string>",
              },
              "reference_id": {
                "docs": "Unique user-provided string identifying the datapoint.",
                "type": "optional<string>",
              },
              "save": {
                "default": true,
                "docs": "Whether the request/response payloads will be stored on Humanloop.",
                "type": "optional<boolean>",
              },
              "session_id": {
                "docs": "ID of the session to associate the datapoint.",
                "type": "optional<string>",
              },
              "session_reference_id": {
                "docs": "A unique string identifying the session to associate the datapoint to. Allows you to log multiple datapoints to a session (using an ID kept by your internal systems) by passing the same `session_reference_id` in subsequent log requests. Specify at most one of this or `session_id`.",
                "type": "optional<string>",
              },
              "source": {
                "docs": "Identifies where the model was called from.",
                "type": "optional<string>",
              },
              "source_datapoint_id": {
                "docs": "ID of the source datapoint if this is a log derived from a datapoint in a dataset.",
                "type": "optional<string>",
              },
              "tokens": {
                "docs": "Total number of tokens in the prompt and output.",
                "type": "optional<integer>",
              },
              "tool_choice": {
                "docs": "Controls how the model uses tools. The following options are supported: 'none' forces the model to not call a tool; the default when no tools are provided as part of the model config. 'auto' the model can decide to call one of the provided tools; the default when tools are provided as part of the model config. Providing {'type': 'function', 'function': {name': <TOOL_NAME>}} forces the model to use the named function.",
                "type": "optional<LogResponseToolChoice>",
              },
              "tools": {
                "type": "optional<list<ToolResultResponse>>",
              },
              "trial_id": {
                "docs": "Unique ID of an experiment trial to associate to the log.",
                "type": "optional<string>",
              },
              "updated_at": {
                "type": "datetime",
              },
              "user": {
                "docs": "User email address provided when creating the datapoint.",
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "LogResponseToolChoice": {
            "discriminated": false,
            "docs": "Controls how the model uses tools. The following options are supported: 'none' forces the model to not call a tool; the default when no tools are provided as part of the model config. 'auto' the model can decide to call one of the provided tools; the default when tools are provided as part of the model config. Providing {'type': 'function', 'function': {name': <TOOL_NAME>}} forces the model to use the named function.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "literal<"none">",
              "literal<"auto">",
              "literal<"required">",
              {
                "type": "ToolChoice",
              },
            ],
          },
          "MetricValueResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "metric_id": "string",
              "metric_name": "string",
              "metric_value": "double",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ModelConfigRequest": {
            "docs": "Model config used for logging both chat and completion.",
            "inline": undefined,
            "properties": {
              "chat_template": {
                "docs": "Messages prepended to the list of messages sent to the provider. These messages that will take your specified inputs to form your final request to the provider model. Input variables within the template should be specified with syntax: {{INPUT_NAME}}.",
                "type": "optional<list<ChatMessageWithToolCall>>",
              },
              "description": {
                "docs": "A description of the model config.",
                "type": "optional<string>",
              },
              "endpoint": {
                "docs": "The provider model endpoint used.",
                "type": "optional<ModelEndpoints>",
              },
              "frequency_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.",
                "type": "optional<double>",
              },
              "max_tokens": {
                "default": -1,
                "docs": "The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt",
                "type": "optional<integer>",
              },
              "model": {
                "docs": "The model instance used. E.g. text-davinci-002.",
                "type": "string",
              },
              "name": {
                "docs": "A friendly display name for the model config. If not provided, a name will be generated.",
                "type": "optional<string>",
              },
              "other": {
                "docs": "Other parameter values to be passed to the provider call.",
                "type": "optional<map<string, unknown>>",
              },
              "presence_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.",
                "type": "optional<double>",
              },
              "prompt_template": {
                "docs": "Prompt template that will take your specified inputs to form your final request to the model. Input variables within the prompt template should be specified with syntax: {{INPUT_NAME}}.",
                "type": "optional<string>",
              },
              "provider": {
                "docs": "The company providing the underlying model service.",
                "type": "optional<ModelProviders>",
              },
              "response_format": {
                "docs": "The format of the response. Only type json_object is currently supported for chat.",
                "type": "optional<ResponseFormat>",
              },
              "seed": {
                "docs": "If specified, model will make a best effort to sample deterministically, but it is not guaranteed.",
                "type": "optional<integer>",
              },
              "stop": {
                "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
                "type": "optional<ModelConfigRequestStop>",
              },
              "temperature": {
                "default": 1,
                "docs": "What sampling temperature to use when making a generation. Higher values means the model will be more creative.",
                "type": "optional<double>",
              },
              "tools": {
                "docs": "Make tools available to OpenAIs chat model as functions.",
                "type": "optional<list<ModelConfigRequestToolsItem>>",
              },
              "top_p": {
                "default": 1,
                "docs": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.",
                "type": "optional<double>",
              },
              "type": {
                "type": "optional<literal<"model">>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ModelConfigRequestStop": {
            "discriminated": false,
            "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<string>",
            ],
          },
          "ModelConfigRequestToolsItem": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "LinkedToolRequest",
              },
              {
                "type": "ModelConfigToolRequest",
              },
            ],
          },
          "ModelConfigResponse": {
            "docs": "Model config request.

Contains fields that are common to all (i.e. both chat and complete) endpoints.",
            "inline": undefined,
            "properties": {
              "chat_template": {
                "docs": "Messages prepended to the list of messages sent to the provider. These messages that will take your specified inputs to form your final request to the provider model. NB: Input variables within the template should be specified with syntax: {{INPUT_NAME}}.",
                "type": "optional<list<ChatMessageWithToolCall>>",
              },
              "description": {
                "docs": "A description of the model config.",
                "type": "optional<string>",
              },
              "endpoint": {
                "docs": "The provider model endpoint used.",
                "type": "optional<ModelEndpoints>",
              },
              "frequency_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.",
                "type": "optional<double>",
              },
              "id": {
                "docs": "String ID of config. Starts with `config_`.",
                "type": "string",
              },
              "max_tokens": {
                "default": -1,
                "docs": "The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt",
                "type": "optional<integer>",
              },
              "model": {
                "docs": "The model instance used. E.g. text-davinci-002.",
                "type": "string",
              },
              "name": {
                "docs": "A friendly display name for the model config. If not provided, a name will be generated.",
                "type": "optional<string>",
              },
              "other": {
                "docs": "Other parameter values to be passed to the provider call.",
                "type": "optional<map<string, unknown>>",
              },
              "presence_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.",
                "type": "optional<double>",
              },
              "prompt_template": {
                "docs": "Prompt template that will take your specified inputs to form your final request to the model. NB: Input variables within the prompt template should be specified with syntax: {{INPUT_NAME}}.",
                "type": "optional<string>",
              },
              "provider": {
                "docs": "The company providing the underlying model service.",
                "type": "optional<ModelProviders>",
              },
              "response_format": {
                "docs": "The format of the response. Only type json_object is currently supported for chat.",
                "type": "optional<ResponseFormat>",
              },
              "seed": {
                "docs": "If specified, model will make a best effort to sample deterministically, but it is not guaranteed.",
                "type": "optional<integer>",
              },
              "stop": {
                "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
                "type": "optional<ModelConfigResponseStop>",
              },
              "temperature": {
                "default": 1,
                "docs": "What sampling temperature to use when making a generation. Higher values means the model will be more creative.",
                "type": "optional<double>",
              },
              "tool_configs": {
                "availability": "deprecated",
                "docs": "NB: Deprecated with tools field. Definition of tools shown to the model.",
                "type": "optional<list<ToolConfigResponse>>",
              },
              "tools": {
                "docs": "Tools shown to the model.",
                "type": "optional<list<ToolResponse>>",
              },
              "top_p": {
                "default": 1,
                "docs": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.",
                "type": "optional<double>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ModelConfigResponseStop": {
            "discriminated": false,
            "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<string>",
            ],
          },
          "ModelConfigToolRequest": {
            "docs": "Definition of tool within a model config.

The subset of ToolConfig parameters received by the chat endpoint.
Does not have things like the signature or setup schema.",
            "inline": undefined,
            "properties": {
              "description": {
                "docs": "The description of the tool shown to the model.",
                "type": "optional<string>",
              },
              "name": {
                "docs": "The name of the tool shown to the model.",
                "type": "string",
              },
              "other": {
                "docs": "Other parameters that define the config.",
                "type": "optional<map<string, unknown>>",
              },
              "parameters": {
                "docs": "Definition of parameters needed to run the tool. Provided in jsonschema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "preset_name": {
                "docs": "If is_preset = true, this is the name of the preset tool on Humanloop. This is used as the key to look up the Humanloop runtime of the tool",
                "type": "optional<string>",
              },
              "source": {
                "docs": "Source of the tool. If defined at an organization level will be 'organization' else 'inline'.",
                "type": "optional<ToolSource>",
              },
              "source_code": {
                "docs": "Code source of the tool.",
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ModelEndpoints": {
            "docs": "Supported model provider endpoints.",
            "enum": [
              "complete",
              "chat",
              "edit",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ModelProviders": {
            "docs": "Supported model providers.",
            "enum": [
              "openai",
              "openai_azure",
              "ai21",
              "mock",
              "anthropic",
              "langchain",
              "cohere",
              "replicate",
              "google",
              "groq",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "MonitoringEvaluatorEnvironmentRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "environment_id": {
                "docs": "Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.",
                "type": "string",
              },
              "evaluator_id": {
                "docs": "Unique identifier for the Evaluator to be used for monitoring.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "MonitoringEvaluatorResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_at": {
                "type": "datetime",
              },
              "state": {
                "docs": "The state of the Monitoring Evaluator. Either `active` or `inactive`",
                "type": "MonitoringEvaluatorState",
              },
              "updated_at": {
                "type": "datetime",
              },
              "version": {
                "docs": "The deployed Version.",
                "type": "optional<EvaluatorResponse>",
              },
              "version_reference": {
                "docs": "The Evaluator Version used for monitoring. This can be a specific Version by ID, or a Version deployed to an Environment.",
                "type": "VersionReferenceResponse",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "MonitoringEvaluatorState": {
            "docs": "State of an evaluator connected to a file",
            "enum": [
              "active",
              "inactive",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "MonitoringEvaluatorVersionRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "evaluator_version_id": {
                "docs": "Unique identifier for the Evaluator Version to be used for monitoring.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "NumericEvaluatorVersionStats": {
            "docs": "Base attributes for stats for an Evaluator Version-Evaluated Version pair
in the Evaluation Report.",
            "inline": undefined,
            "properties": {
              "evaluator_version_id": {
                "docs": "Unique identifier for the Evaluator Version.",
                "type": "string",
              },
              "mean": {
                "type": "optional<double>",
              },
              "num_errors": {
                "docs": "The total number of errored Evaluators for this Evaluator Version.",
                "type": "integer",
              },
              "num_judgments": {
                "docs": "The total number of Evaluator judgments for this Evaluator Version. This excludes Nulls and Errors.",
                "type": "integer",
              },
              "num_nulls": {
                "docs": "The total number of null judgments (i.e. abstentions) for this Evaluator Version.",
                "type": "integer",
              },
              "percentiles": {
                "type": "map<string, double>",
              },
              "std": {
                "type": "optional<double>",
              },
              "total_logs": {
                "docs": "The total number of Logs generated by this Evaluator Version on the Evaluated Version's Logs. This includes Nulls and Errors.",
                "type": "integer",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ObservabilityStatus": {
            "docs": "Status of a Log for observability.

Observability is implemented by running monitoring Evaluators on Logs.",
            "enum": [
              "pending",
              "running",
              "completed",
              "failed",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "OverallStats": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "num_datapoints": {
                "docs": "The total number of Datapoints in the Evaluation Report's Dataset Version.",
                "type": "integer",
              },
              "total_evaluator_logs": {
                "docs": "The total number of Evaluator Logs in the Evaluation Report.",
                "type": "integer",
              },
              "total_logs": {
                "docs": "The total number of Logs in the Evaluation Report.",
                "type": "integer",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PaginatedDataDatapointResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "page": "integer",
              "records": {
                "type": "list<DatapointResponse>",
              },
              "size": "integer",
              "total": "integer",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PaginatedDataDatasetResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "page": "integer",
              "records": {
                "type": "list<DatasetResponse>",
              },
              "size": "integer",
              "total": "integer",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PaginatedDataEvaluationResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "page": "integer",
              "records": {
                "type": "list<EvaluationResponse>",
              },
              "size": "integer",
              "total": "integer",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PaginatedDataPromptLogResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "page": "integer",
              "records": {
                "type": "list<PromptLogResponse>",
              },
              "size": "integer",
              "total": "integer",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PaginatedDataSessionResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "page": "integer",
              "records": {
                "type": "list<SessionResponse>",
              },
              "size": "integer",
              "total": "integer",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PlatformAccessEnum": {
            "docs": "An enumeration.",
            "enum": [
              "superadmin",
              "supportadmin",
              "user",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ProjectSortBy": {
            "docs": "An enumeration.",
            "enum": [
              "created_at",
              "updated_at",
              "name",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PromptCallLogResponse": {
            "docs": "Sample specific response details for a Prompt call",
            "inline": undefined,
            "properties": {
              "created_at": {
                "docs": "User defined timestamp for when the log was created. ",
                "type": "optional<datetime>",
              },
              "error": {
                "docs": "Error message if the log is an error.",
                "type": "optional<string>",
              },
              "finish_reason": {
                "docs": "Reason the generation finished.",
                "type": "optional<string>",
              },
              "index": {
                "docs": "The index of the sample in the batch.",
                "type": "integer",
              },
              "output": {
                "docs": "Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.",
                "type": "optional<string>",
              },
              "output_cost": {
                "docs": "Cost in dollars associated to the tokens in the output.",
                "type": "optional<double>",
              },
              "output_message": {
                "docs": "The message returned by the provider.",
                "type": "optional<ChatMessage>",
              },
              "output_tokens": {
                "docs": "Number of tokens in the output generated by the model.",
                "type": "optional<integer>",
              },
              "prompt_cost": {
                "docs": "Cost in dollars associated to the tokens in the prompt.",
                "type": "optional<double>",
              },
              "prompt_tokens": {
                "docs": "Number of tokens in the prompt used to generate the output.",
                "type": "optional<integer>",
              },
              "provider_latency": {
                "docs": "Duration of the logged event in seconds.",
                "type": "optional<double>",
              },
              "raw_output": {
                "docs": "Raw output from the provider.",
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PromptCallResponse": {
            "docs": "Response model for a Prompt call with potentially multiple log samples.",
            "inline": undefined,
            "properties": {
              "batches": {
                "docs": "Array of Batch Ids that this log is part of. Batches are used to group Logs together for offline Evaluations",
                "type": "optional<list<string>>",
              },
              "environment": {
                "docs": "The name of the Environment the Log is associated to.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "ID of the log.",
                "type": "string",
              },
              "inputs": {
                "docs": "The inputs passed to the prompt template.",
                "type": "optional<map<string, unknown>>",
              },
              "logs": {
                "docs": "The logs generated by the Prompt call.",
                "type": "list<PromptCallLogResponse>",
              },
              "messages": {
                "docs": "The messages passed to the to provider chat endpoint.",
                "type": "optional<list<ChatMessage>>",
              },
              "metadata": {
                "docs": "Any additional metadata to record.",
                "type": "optional<map<string, unknown>>",
              },
              "parent_id": {
                "docs": "Unique identifier for the parent Log in a Session. Should only be provided if `session_id` is provided. If provided, the Log will be nested under the parent Log within the Session.",
                "type": "optional<string>",
              },
              "prompt": {
                "docs": "Prompt details used to generate the log.",
                "type": "PromptResponse",
              },
              "save": {
                "default": true,
                "docs": "Whether the request/response payloads will be stored on Humanloop.",
                "type": "optional<boolean>",
              },
              "session_id": {
                "docs": "Unique identifier for the Session to associate the Log to. Allows you to record multiple Logs to a Session (using an ID kept by your internal systems) by passing the same `session_id` in subsequent log requests. ",
                "type": "optional<string>",
              },
              "source": {
                "docs": "Identifies where the model was called from.",
                "type": "optional<string>",
              },
              "source_datapoint_id": {
                "docs": "Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.",
                "type": "optional<string>",
              },
              "tool_choice": {
                "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
                "type": "optional<PromptCallResponseToolChoice>",
              },
              "user": {
                "docs": "End-user ID related to the Log.",
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PromptCallResponseToolChoice": {
            "discriminated": false,
            "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "literal<"none">",
              "literal<"auto">",
              "literal<"required">",
              {
                "type": "ToolChoice",
              },
            ],
          },
          "PromptCallStreamResponse": {
            "docs": "Response model for calling Prompt in streaming mode.",
            "inline": undefined,
            "properties": {
              "created_at": {
                "docs": "User defined timestamp for when the log was created. ",
                "type": "optional<datetime>",
              },
              "error": {
                "docs": "Error message if the log is an error.",
                "type": "optional<string>",
              },
              "finish_reason": {
                "docs": "Reason the generation finished.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "ID of the log.",
                "type": "string",
              },
              "index": {
                "docs": "The index of the sample in the batch.",
                "type": "integer",
              },
              "output": {
                "docs": "Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.",
                "type": "optional<string>",
              },
              "output_cost": {
                "docs": "Cost in dollars associated to the tokens in the output.",
                "type": "optional<double>",
              },
              "output_message": {
                "docs": "The message returned by the provider.",
                "type": "optional<ChatMessage>",
              },
              "output_tokens": {
                "docs": "Number of tokens in the output generated by the model.",
                "type": "optional<integer>",
              },
              "prompt_cost": {
                "docs": "Cost in dollars associated to the tokens in the prompt.",
                "type": "optional<double>",
              },
              "prompt_id": {
                "docs": "ID of the Prompt the log belongs to.",
                "type": "string",
              },
              "prompt_tokens": {
                "docs": "Number of tokens in the prompt used to generate the output.",
                "type": "optional<integer>",
              },
              "provider_latency": {
                "docs": "Duration of the logged event in seconds.",
                "type": "optional<double>",
              },
              "raw_output": {
                "docs": "Raw output from the provider.",
                "type": "optional<string>",
              },
              "version_id": {
                "docs": "ID of the specific version of the Prompt.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PromptKernelRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "endpoint": {
                "docs": "The provider model endpoint used.",
                "type": "optional<ModelEndpoints>",
              },
              "frequency_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.",
                "type": "optional<double>",
              },
              "linked_tools": {
                "docs": "The IDs of the Tools in your organization that the model can choose to call if Tool calling is supported. The default deployed version of that tool is called.",
                "type": "optional<list<string>>",
              },
              "max_tokens": {
                "default": -1,
                "docs": "The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt",
                "type": "optional<integer>",
              },
              "model": {
                "docs": "The model instance used, e.g. `gpt-4`. See [supported models](https://humanloop.com/docs/supported-models)",
                "type": "string",
              },
              "other": {
                "docs": "Other parameter values to be passed to the provider call.",
                "type": "optional<map<string, unknown>>",
              },
              "presence_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.",
                "type": "optional<double>",
              },
              "provider": {
                "docs": "The company providing the underlying model service.",
                "type": "optional<ModelProviders>",
              },
              "response_format": {
                "docs": "The format of the response. Only `{"type": "json_object"}` is currently supported for chat.",
                "type": "optional<ResponseFormat>",
              },
              "seed": {
                "docs": "If specified, model will make a best effort to sample deterministically, but it is not guaranteed.",
                "type": "optional<integer>",
              },
              "stop": {
                "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
                "type": "optional<PromptKernelRequestStop>",
              },
              "temperature": {
                "default": 1,
                "docs": "What sampling temperature to use when making a generation. Higher values means the model will be more creative.",
                "type": "optional<double>",
              },
              "template": {
                "docs": "For chat endpoint, provide a Chat template. For completion endpoint, provide a Prompt template. Input variables within the template should be specified with double curly bracket syntax: {{INPUT_NAME}}.",
                "type": "optional<Template>",
              },
              "tools": {
                "docs": "The tool specification that the model can choose to call if Tool calling is supported.",
                "type": "optional<list<ToolFunction>>",
              },
              "top_p": {
                "default": 1,
                "docs": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.",
                "type": "optional<double>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PromptKernelRequestStop": {
            "discriminated": false,
            "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<string>",
            ],
          },
          "PromptLogResponse": {
            "docs": "Request for creating a Prompt log.",
            "inline": undefined,
            "properties": {
              "batches": {
                "docs": "Array of Batch Ids that this log is part of. Batches are used to group Logs together for offline Evaluations",
                "type": "optional<list<string>>",
              },
              "created_at": {
                "docs": "User defined timestamp for when the log was created. ",
                "type": "optional<datetime>",
              },
              "environment": {
                "docs": "The name of the Environment the Log is associated to.",
                "type": "optional<string>",
              },
              "error": {
                "docs": "Error message if the log is an error.",
                "type": "optional<string>",
              },
              "finish_reason": {
                "docs": "Reason the generation finished.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "Unique identifier for the Log.",
                "type": "string",
              },
              "inputs": {
                "docs": "The inputs passed to the prompt template.",
                "type": "optional<map<string, unknown>>",
              },
              "messages": {
                "docs": "The messages passed to the to provider chat endpoint.",
                "type": "optional<list<ChatMessage>>",
              },
              "metadata": {
                "docs": "Any additional metadata to record.",
                "type": "optional<map<string, unknown>>",
              },
              "output": {
                "docs": "Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.",
                "type": "optional<string>",
              },
              "output_cost": {
                "docs": "Cost in dollars associated to the tokens in the output.",
                "type": "optional<double>",
              },
              "output_message": {
                "docs": "The message returned by the provider.",
                "type": "optional<ChatMessage>",
              },
              "output_tokens": {
                "docs": "Number of tokens in the output generated by the model.",
                "type": "optional<integer>",
              },
              "parent_id": {
                "docs": "Unique identifier for the parent Log in a Session. Should only be provided if `session_id` is provided. If provided, the Log will be nested under the parent Log within the Session.",
                "type": "optional<string>",
              },
              "prompt": {
                "docs": "Prompt details used to generate the log.",
                "type": "PromptResponse",
              },
              "prompt_cost": {
                "docs": "Cost in dollars associated to the tokens in the prompt.",
                "type": "optional<double>",
              },
              "prompt_tokens": {
                "docs": "Number of tokens in the prompt used to generate the output.",
                "type": "optional<integer>",
              },
              "provider_latency": {
                "docs": "Duration of the logged event in seconds.",
                "type": "optional<double>",
              },
              "provider_request": {
                "docs": "Raw request sent to provider.",
                "type": "optional<map<string, unknown>>",
              },
              "provider_response": {
                "docs": "Raw response received the provider.",
                "type": "optional<map<string, unknown>>",
              },
              "raw_output": {
                "docs": "Raw output from the provider.",
                "type": "optional<string>",
              },
              "save": {
                "default": true,
                "docs": "Whether the request/response payloads will be stored on Humanloop.",
                "type": "optional<boolean>",
              },
              "session_id": {
                "docs": "Unique identifier for the Session to associate the Log to. Allows you to record multiple Logs to a Session (using an ID kept by your internal systems) by passing the same `session_id` in subsequent log requests. ",
                "type": "optional<string>",
              },
              "source": {
                "docs": "Identifies where the model was called from.",
                "type": "optional<string>",
              },
              "source_datapoint_id": {
                "docs": "Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.",
                "type": "optional<string>",
              },
              "tool_choice": {
                "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
                "type": "optional<PromptLogResponseToolChoice>",
              },
              "user": {
                "docs": "End-user ID related to the Log.",
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PromptLogResponseToolChoice": {
            "discriminated": false,
            "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "literal<"none">",
              "literal<"auto">",
              "literal<"required">",
              {
                "type": "ToolChoice",
              },
            ],
          },
          "PromptResponse": {
            "docs": "Request model for creating a new Prompt",
            "inline": undefined,
            "properties": {
              "commit_message": {
                "docs": "Message describing the changes made.",
                "type": "optional<string>",
              },
              "created_at": {
                "type": "datetime",
              },
              "created_by": {
                "docs": "The user who created the Prompt.",
                "type": "optional<UserResponse>",
              },
              "directory_id": {
                "docs": "Unique identifier for the Directory of the Prompt. ",
                "type": "optional<string>",
              },
              "endpoint": {
                "docs": "The provider model endpoint used.",
                "type": "optional<ModelEndpoints>",
              },
              "environments": {
                "docs": "The list of environments the Prompt Version is deployed to.",
                "type": "optional<list<EnvironmentResponse>>",
              },
              "frequency_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.",
                "type": "optional<double>",
              },
              "id": {
                "docs": "Unique identifier for the Prompt.",
                "type": "string",
              },
              "inputs": {
                "docs": "Inputs associated to the Prompt. Inputs correspond to any of the variables used within the Prompt template.",
                "type": "list<InputResponse>",
              },
              "last_used_at": {
                "type": "datetime",
              },
              "linked_tools": {
                "docs": "The IDs of the Tools in your organization that the model can choose to call if Tool calling is supported. The default deployed version of that tool is called.",
                "type": "optional<list<LinkedToolResponse>>",
              },
              "max_tokens": {
                "default": -1,
                "docs": "The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt",
                "type": "optional<integer>",
              },
              "model": {
                "docs": "The model instance used, e.g. `gpt-4`. See [supported models](https://humanloop.com/docs/supported-models)",
                "type": "string",
              },
              "name": {
                "docs": "Name of the Prompt, which is used as a unique identifier.",
                "type": "string",
              },
              "other": {
                "docs": "Other parameter values to be passed to the provider call.",
                "type": "optional<map<string, unknown>>",
              },
              "presence_penalty": {
                "default": 0,
                "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.",
                "type": "optional<double>",
              },
              "provider": {
                "docs": "The company providing the underlying model service.",
                "type": "optional<ModelProviders>",
              },
              "response_format": {
                "docs": "The format of the response. Only `{"type": "json_object"}` is currently supported for chat.",
                "type": "optional<ResponseFormat>",
              },
              "seed": {
                "docs": "If specified, model will make a best effort to sample deterministically, but it is not guaranteed.",
                "type": "optional<integer>",
              },
              "status": {
                "docs": "The status of the Prompt Version.",
                "type": "VersionStatus",
              },
              "stop": {
                "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
                "type": "optional<PromptResponseStop>",
              },
              "temperature": {
                "default": 1,
                "docs": "What sampling temperature to use when making a generation. Higher values means the model will be more creative.",
                "type": "optional<double>",
              },
              "template": {
                "docs": "For chat endpoint, provide a Chat template. For completion endpoint, provide a Prompt template. Input variables within the template should be specified with double curly bracket syntax: {{INPUT_NAME}}.",
                "type": "optional<Template>",
              },
              "tools": {
                "docs": "The tool specification that the model can choose to call if Tool calling is supported.",
                "type": "optional<list<ToolFunction>>",
              },
              "top_p": {
                "default": 1,
                "docs": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.",
                "type": "optional<double>",
              },
              "total_logs_count": {
                "docs": "The number of logs that have been generated across all Prompt Versions",
                "type": "integer",
              },
              "updated_at": {
                "type": "datetime",
              },
              "version_id": {
                "docs": "Unique identifier for the specific Prompt Version. If no query params provided, the default deployed Prompt Version is returned.",
                "type": "string",
              },
              "version_logs_count": {
                "docs": "The number of logs that have been generated for this Prompt Version",
                "type": "integer",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "PromptResponseStop": {
            "discriminated": false,
            "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<string>",
            ],
          },
          "ProviderApiKeys": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "ai21": {
                "type": "optional<string>",
              },
              "anthropic": {
                "type": "optional<string>",
              },
              "cohere": {
                "type": "optional<string>",
              },
              "mock": {
                "type": "optional<string>",
              },
              "openai": {
                "type": "optional<string>",
              },
              "openai_azure": {
                "type": "optional<string>",
              },
              "openai_azure_endpoint": {
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ResponseFormat": {
            "docs": "Response format of the model.",
            "inline": undefined,
            "properties": {
              "type": {
                "type": "literal<"json_object">",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "SessionResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_at": {
                "type": "datetime",
              },
              "id": {
                "docs": "Unique identifier for the Session.",
                "type": "string",
              },
              "logs": {
                "docs": "List of Logs associated with this Session.",
                "type": "list<PromptLogResponse>",
              },
              "updated_at": {
                "type": "datetime",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "SortOrder": {
            "docs": "An enumeration.",
            "enum": [
              "asc",
              "desc",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "Spec": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "evaluator_type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": {
              "human": {
                "type": "HumanEvaluatorRequest",
              },
              "llm": {
                "type": "LLMEvaluatorRequest",
              },
              "python": {
                "type": "CodeEvaluatorRequest",
              },
            },
          },
          "Template": {
            "discriminated": false,
            "docs": "For chat endpoint, provide a Chat template. For completion endpoint, provide a Prompt template. Input variables within the template should be specified with double curly bracket syntax: {{INPUT_NAME}}.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<ChatMessage>",
            ],
          },
          "TextChatContent": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "text": {
                "docs": "The message's text content.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "TimeUnit": {
            "docs": "An enumeration.",
            "enum": [
              "day",
              "week",
              "month",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolCall": {
            "docs": "A tool call to be made.",
            "inline": undefined,
            "properties": {
              "function": {
                "type": "FunctionTool",
              },
              "id": "string",
              "type": {
                "type": "ToolType",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolChoice": {
            "docs": "Tool choice to force the model to use a tool.",
            "inline": undefined,
            "properties": {
              "function": {
                "type": "FunctionToolChoice",
              },
              "type": {
                "type": "ToolType",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolConfigRequest": {
            "docs": "Definition of tool within a model config.

The subset of ToolConfig parameters received by the chat endpoint.
Does not have things like the signature or setup schema.",
            "inline": undefined,
            "properties": {
              "description": {
                "docs": "The description of the tool shown to the model.",
                "type": "optional<string>",
              },
              "name": {
                "docs": "The name of the tool shown to the model.",
                "type": "string",
              },
              "other": {
                "docs": "Other parameters that define the config.",
                "type": "optional<map<string, unknown>>",
              },
              "parameters": {
                "docs": "Definition of parameters needed to run the tool. Provided in jsonschema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "preset_name": {
                "docs": "If is_preset = true, this is the name of the preset tool on Humanloop. This is used as the key to look up the Humanloop runtime of the tool",
                "type": "optional<string>",
              },
              "source": {
                "docs": "Source of the tool. If defined at an organization level will be 'organization' else 'inline'.",
                "type": "optional<ToolSource>",
              },
              "source_code": {
                "docs": "Code source of the tool.",
                "type": "optional<string>",
              },
              "type": {
                "type": "literal<"tool">",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolConfigResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_by": {
                "docs": "The user who created the config.",
                "type": "optional<UserResponse>",
              },
              "description": {
                "docs": "Description of the tool referenced by the model",
                "type": "optional<string>",
              },
              "id": {
                "docs": "String ID of config. Starts with `config_`.",
                "type": "string",
              },
              "is_preset": {
                "docs": "Whether the tool is one where Humanloop defines runtime or not.",
                "type": "optional<boolean>",
              },
              "name": {
                "docs": "Name for the tool referenced by the model.",
                "type": "string",
              },
              "other": {
                "docs": "Other parameters that define the config.",
                "type": "optional<map<string, unknown>>",
              },
              "parameters": {
                "docs": "Definition of parameters needed to run the tool. Provided in jsonschema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "preset_name": {
                "docs": "If is_preset = true, this is the name of the preset tool on Humanloop. This is used as the key to lookup the Humanloop runtime of the tool",
                "type": "optional<string>",
              },
              "setup_schema": {
                "docs": "Definition of parameters needed to run the tool. Provided in jsonschema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "signature": {
                "docs": "The function signature of the tool when being called.",
                "type": "optional<string>",
              },
              "source": {
                "docs": "Source of the tool. If defined at an organization level will be 'organization' else 'inline'.",
                "type": "optional<ToolSource>",
              },
              "source_code": {
                "docs": "Code source of the tool.",
                "type": "optional<string>",
              },
              "status": {
                "docs": "Whether the config is committed or not.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolFunction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "description": {
                "docs": "Description of the tool referenced by the model",
                "type": "string",
              },
              "name": {
                "docs": "Name for the tool referenced by the model.",
                "type": "string",
              },
              "parameters": {
                "docs": "Parameters needed to run the Tool, defined in JSON Schema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolKernelRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "function": {
                "docs": "Callable function specification of the Tool shown to the model for tool calling.",
                "type": "optional<ToolFunction>",
              },
              "setup_values": {
                "docs": "Values needed to setup the Tool, defined in JSON Schema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "source_code": {
                "docs": "Code source of the Tool.",
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolResponse": {
            "docs": "Request to create a new Tool.",
            "inline": undefined,
            "properties": {
              "commit_message": {
                "docs": "Message describing the changes made.",
                "type": "optional<string>",
              },
              "created_at": {
                "type": "datetime",
              },
              "created_by": {
                "docs": "The user who created the Prompt.",
                "type": "optional<UserResponse>",
              },
              "directory_id": {
                "docs": "Unique identifier for the Directory of the Prompt. ",
                "type": "optional<string>",
              },
              "environments": {
                "docs": "The list of environments the Prompt Version is deployed to.",
                "type": "optional<list<EnvironmentResponse>>",
              },
              "function": {
                "docs": "Callable function specification of the Tool shown to the model for tool calling.",
                "type": "optional<ToolFunction>",
              },
              "id": {
                "docs": "Unique identifier for Tool.",
                "type": "string",
              },
              "inputs": {
                "docs": "Inputs associated to the Prompt. Inputs correspond to any of the variables used within the Prompt template.",
                "type": "list<InputResponse>",
              },
              "last_used_at": {
                "type": "datetime",
              },
              "name": {
                "docs": "Name of the Tool, which is used as a unique identifier.",
                "type": "string",
              },
              "setup_values": {
                "docs": "Values needed to setup the Tool, defined in JSON Schema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "signature": {
                "docs": "Signature of the Tool.",
                "type": "optional<string>",
              },
              "source_code": {
                "docs": "Code source of the Tool.",
                "type": "optional<string>",
              },
              "status": {
                "docs": "The status of the Prompt Version.",
                "type": "VersionStatus",
              },
              "tool_type": {
                "docs": "Type of Tool.",
                "type": "optional<ToolType>",
              },
              "total_logs_count": {
                "docs": "The number of logs that have been generated across all Prompt Versions",
                "type": "integer",
              },
              "updated_at": {
                "type": "datetime",
              },
              "version_id": {
                "docs": "Unique identifier for the specific Tool Version. If no query params provided, the default deployed Tool Version is returned.",
                "type": "string",
              },
              "version_logs_count": {
                "docs": "The number of logs that have been generated for this Prompt Version",
                "type": "integer",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolResultResponse": {
            "docs": "A result from a tool used to populate the prompt template",
            "inline": undefined,
            "properties": {
              "id": "string",
              "name": "string",
              "result": "string",
              "signature": "string",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolSource": {
            "docs": "Source of tool. Used to differentiate between tools and tool versions when they are combined in a list.

V4 uses organization and inline. Those are deprecated and will be removed in favour of tool and tool_version.",
            "enum": [
              "organization",
              "inline",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolTemplateResponse": {
            "docs": "Template for a Humanloop runnable tool.",
            "inline": undefined,
            "properties": {
              "description": {
                "docs": "Description of the tool referenced by the model",
                "type": "string",
              },
              "name": {
                "docs": "Name for the tool referenced by the model.",
                "type": "string",
              },
              "parameters": {
                "docs": "Parameters needed to run the Tool, defined in JSON Schema format: https://json-schema.org/",
                "type": "optional<map<string, unknown>>",
              },
              "setup_schema": {
                "docs": "Schema required to setup the Tool runtime, e.g. API keys.",
                "type": "optional<map<string, unknown>>",
              },
              "signature": {
                "docs": "Signature of the Tool.",
                "type": "optional<string>",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ToolType": {
            "docs": "Type of tool.",
            "enum": [
              "pinecone_search",
              "google",
              "mock",
              "snippet",
              "json_schema",
              "get_api_call",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "UpdateDatesetAction": {
            "docs": "An enumeration.",
            "enum": [
              "set",
              "add",
              "remove",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "UserResponse": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "email_address": {
                "docs": "The User's email address.",
                "type": "string",
              },
              "full_name": {
                "docs": "The User's full name.",
                "type": "optional<string>",
              },
              "id": {
                "docs": "Unique identifier for User. Starts with `usr`.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ValidationError": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "loc": {
                "type": "list<ValidationErrorLocItem>",
              },
              "msg": "string",
              "type": "string",
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "ValidationErrorLocItem": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "integer",
            ],
          },
          "Value": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "boolean",
              "double",
            ],
          },
          "Version": {
            "discriminated": false,
            "docs": "The specific Version being referenced.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "PromptResponse",
              },
              {
                "type": "ToolResponse",
              },
              {
                "type": "DatasetResponse",
              },
              {
                "type": "EvaluatorResponse",
              },
            ],
          },
          "VersionDeploymentResponse": {
            "docs": "A variable reference to the Version deployed to an Environment",
            "inline": undefined,
            "properties": {
              "environment": {
                "docs": "The Environment that the Version is deployed to.",
                "type": "EnvironmentResponse",
              },
              "file": {
                "display-name": "File",
                "docs": "The File that the deployed Version belongs to.",
                "type": "File",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "VersionIdResponse": {
            "docs": "A reference to a specific Version by its ID",
            "inline": undefined,
            "properties": {
              "version": {
                "display-name": "Version",
                "docs": "The specific Version being referenced.",
                "type": "Version",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "VersionReferenceResponse": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": {
              "environment": {
                "type": "VersionDeploymentResponse",
              },
              "version": {
                "type": "VersionIdResponse",
              },
            },
          },
          "VersionStats": {
            "docs": "Stats for an Evaluated Version in the Evaluation Report.",
            "inline": undefined,
            "properties": {
              "evaluator_version_stats": {
                "docs": "Stats for each Evaluator Version used to evaluate this Evaluated Version.",
                "type": "list<VersionStatsEvaluatorVersionStatsItem>",
              },
              "num_logs": {
                "docs": "The total number of existing Logs for this Evaluated Version within the Evaluation Report. These are Logs that have been generated by this Evaluated Version on a Datapoint belonging to the Evaluation Report's Dataset Version.",
                "type": "integer",
              },
              "version_id": {
                "docs": "Unique identifier for the Evaluated Version.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yml",
            },
          },
          "VersionStatsEvaluatorVersionStatsItem": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "NumericEvaluatorVersionStats",
              },
              {
                "type": "BooleanEvaluatorVersionStats",
              },
            ],
          },
          "VersionStatus": {
            "docs": "An enumeration.",
            "enum": [
              "uncommitted",
              "committed",
              "deleted",
            ],
            "source": {
              "openapi": "../openapi.yml",
            },
          },
        },
      },
      "rawContents": "errors:
  PromptsListRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsCreateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsDeleteRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsUpdateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsListVersionsRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DeployPromptsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsCommitRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsLogRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  PromptsCallRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  UpdateEvaluatorsPromptsIdEvaluatorsPostRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsListRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsCreateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsDeleteRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsUpdateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsListVersionsRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DeployToolsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsCommitRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ToolsLogRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  UpdateEvaluatorsToolsIdEvaluatorsPostRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ListTemplatesToolsTemplatesGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsListRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsCreateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsDeleteRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsUpdateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsListDatapointsRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsListVersionsRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DatasetsCommitRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DeployDatasetsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluationsListRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluationsCreateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluationsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluationsDeleteRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluationsUpdateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluationsUpdateStatusRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluationsGetStatsRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsListRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsCreateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsDeleteRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsUpdateRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsListVersionsRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DeployEvaluatorsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsCommitRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  EvaluatorsListDefaultRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  DebugEvaluatorsDebugPostRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  ListLogsForFileLogsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  LogsDeleteRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  LogsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  SessionsGetRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  SessionsDeleteRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
  SessionsListRequestUnprocessableEntityError:
    status-code: 422
    type: HTTPValidationError
    docs: Validation Error
    examples:
      - value: {}
types:
  AgentConfigResponse:
    properties:
      id:
        type: string
        docs: String ID of config. Starts with `config_`.
      other:
        type: optional<map<string, unknown>>
        docs: Other parameters that define the config.
      created_by:
        type: optional<UserResponse>
        docs: The user who created the config.
      status:
        type: string
        docs: Whether the config is committed or not.
      name:
        type: string
        docs: Name of config.
      description:
        type: optional<string>
        docs: Description of config.
      agent_class:
        type: string
        docs: Class of the agent.
      tools:
        type: optional<list<ToolConfigRequest>>
        docs: Tools associated with the agent.
      model_config:
        type: ModelConfigRequest
        docs: Model config associated with the agent.
    source:
      openapi: ../openapi.yml
  BooleanEvaluatorVersionStats:
    docs: |-
      Base attributes for stats for an Evaluator Version-Evaluated Version pair
      in the Evaluation Report.
    properties:
      evaluator_version_id:
        type: string
        docs: Unique identifier for the Evaluator Version.
      total_logs:
        type: integer
        docs: >-
          The total number of Logs generated by this Evaluator Version on the
          Evaluated Version's Logs. This includes Nulls and Errors.
      num_judgments:
        type: integer
        docs: >-
          The total number of Evaluator judgments for this Evaluator Version.
          This excludes Nulls and Errors.
      num_nulls:
        type: integer
        docs: >-
          The total number of null judgments (i.e. abstentions) for this
          Evaluator Version.
      num_errors:
        type: integer
        docs: The total number of errored Evaluators for this Evaluator Version.
      num_true:
        type: integer
        docs: The total number of `True` judgments for this Evaluator Version.
      num_false:
        type: integer
        docs: The total number of `False` judgments for this Evaluator Version.
    source:
      openapi: ../openapi.yml
  CategoricalFeedbackLabel:
    properties:
      value: string
      sentiment:
        type: LabelSentiment
        docs: Whether the feedback sentiment is positive or negative.
      status:
        type: FeedbackLabelStatus
        docs: Whether the feedback label is active or inactive.
    source:
      openapi: ../openapi.yml
  ChatMessageContentItem:
    discriminant: type
    base-properties: {}
    union:
      text:
        type: TextChatContent
      image_url:
        type: ImageChatContent
    source:
      openapi: ../openapi.yml
  Content:
    discriminated: false
    docs: The content of the message.
    union:
      - string
      - list<ChatMessageWithToolCallContentItem>
    source:
      openapi: ../openapi.yml
    inline: true
  ChatMessage:
    properties:
      content:
        type: optional<Content>
        docs: The content of the message.
      name:
        type: optional<string>
        docs: Optional name of the message author.
      tool_call_id:
        type: optional<string>
        docs: Tool call that this message is responding to.
      role:
        type: ChatRole
        docs: Role of the message author.
      tool_calls:
        type: optional<list<ToolCall>>
        docs: A list of tool calls requested by the assistant.
    source:
      openapi: ../openapi.yml
  ChatMessageWithToolCallContentItem:
    discriminant: type
    base-properties: {}
    union:
      text:
        type: TextChatContent
      image_url:
        type: ImageChatContent
    source:
      openapi: ../openapi.yml
  ChatMessageWithToolCall:
    properties:
      content:
        type: optional<Content>
        docs: The content of the message.
      name:
        type: optional<string>
        docs: Optional name of the message author.
      tool_call_id:
        type: optional<string>
        docs: Tool call that this message is responding to.
      role:
        type: ChatRole
        docs: Role of the message author.
      tool_calls:
        type: optional<list<ToolCall>>
        docs: A list of tool calls requested by the assistant.
      tool_call:
        type: optional<FunctionTool>
        docs: >-
          NB: Deprecated in favour of tool_calls. A tool call requested by the
          assistant.
        availability: deprecated
    source:
      openapi: ../openapi.yml
  ChatRole:
    enum:
      - user
      - assistant
      - system
      - tool
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  CodeEvaluatorRequest:
    properties:
      arguments_type:
        type: EvaluatorArgumentsType
        docs: Whether this evaluator is target-free or target-required.
      return_type:
        type: EvaluatorReturnTypeEnum
        docs: The type of the return value of the evaluator.
      code:
        type: optional<string>
        docs: >-
          The code for the evaluator. This code will be executed in a sandboxed
          environment.
    source:
      openapi: ../openapi.yml
  CommitRequest:
    properties:
      commit_message:
        type: string
        docs: Message describing the changes made.
    source:
      openapi: ../openapi.yml
  ConfigResponse:
    discriminant: type
    base-properties: {}
    union:
      model:
        type: ModelConfigResponse
      tool:
        type: ToolConfigResponse
      evaluator:
        type: EvaluatorConfigResponse
      agent:
        type: AgentConfigResponse
      generic:
        type: GenericConfigResponse
    source:
      openapi: ../openapi.yml
  CreateDatapointRequestTargetValue:
    discriminated: false
    union:
      - string
      - integer
      - double
      - boolean
      - map<string, unknown>
      - list<unknown>
    source:
      openapi: ../openapi.yml
    inline: true
  CreateDatapointRequest:
    properties:
      inputs:
        type: optional<map<string, string>>
        docs: The inputs to the prompt template.
      messages:
        type: optional<list<ChatMessage>>
        docs: List of chat messages to provide to the model.
      target:
        type: optional<map<string, CreateDatapointRequestTargetValue>>
        docs: >-
          Object with criteria necessary to evaluate generations with this
          Datapoint. This is passed in as an argument to Evaluators when used in
          an Evaluation.
    source:
      openapi: ../openapi.yml
  CreateEvaluationRequest:
    docs: >-
      Request model for creating an Evaluation.


      Evaluation benchmark your Prompt/Tool Versions. With the Datapoints in a
      Dataset Version,

      Logs corresponding to the Datapoint and each Evaluated Version are
      evaluated by the specified Evaluator Versions.

      Aggregated statistics are then calculated and presented in the Evaluation.
    properties:
      dataset:
        type: DatasetRequest
        docs: The Dataset Version to use in this Evaluation.
      evaluatees:
        docs: >-
          Unique identifiers for the Prompt/Tool Versions to include in the
          Evaluation Report.
        type: list<EvaluateeRequest>
      evaluators:
        docs: The Evaluators used to evaluate.
        type: list<EvaluatorRequest>
    source:
      openapi: ../openapi.yml
  CreatePromptLogResponse:
    properties:
      id:
        type: string
        docs: String ID of log.
      prompt_id:
        type: string
        docs: ID of the Prompt the log belongs to.
      version_id:
        type: string
        docs: ID of the specific version of the Prompt.
      session_id:
        type: optional<string>
        docs: String ID of session the log belongs to.
    source:
      openapi: ../openapi.yml
  CreateToolLogResponse:
    properties:
      id:
        type: string
        docs: String ID of log.
      tool_id:
        type: string
        docs: ID of the Prompt the log belongs to.
      version_id:
        type: string
        docs: ID of the specific version of the Tool.
      session_id:
        type: optional<string>
        docs: String ID of session the log belongs to.
    source:
      openapi: ../openapi.yml
  DashboardConfiguration:
    properties:
      time_unit:
        type: TimeUnit
      time_range_days: integer
      model_config_ids:
        type: list<string>
    source:
      openapi: ../openapi.yml
  DatapointResponseTargetValue:
    discriminated: false
    union:
      - string
      - integer
      - double
      - boolean
      - map<string, unknown>
      - list<unknown>
    source:
      openapi: ../openapi.yml
    inline: true
  DatapointResponse:
    properties:
      inputs:
        type: optional<map<string, string>>
        docs: The inputs to the prompt template.
      messages:
        type: optional<list<ChatMessage>>
        docs: List of chat messages to provide to the model.
      target:
        type: optional<map<string, DatapointResponseTargetValue>>
        docs: >-
          Object with criteria necessary to evaluate generations with this
          Datapoint. This is passed in as an argument to Evaluators when used in
          an Evaluation.
      id:
        type: string
        docs: Unique identifier for the Datapoint. Starts with `dp_`.
    source:
      openapi: ../openapi.yml
  DatasetResponse:
    docs: >-
      Base type that all File Responses should inherit from.


      Attributes defined here are common to all File Responses and should be
      overridden

      in the inheriting classes with documentation and appropriate Field
      definitions.
    properties:
      id:
        type: string
        docs: Unique identifier for the Dataset. Starts with `ds_`.
      name:
        type: string
        docs: Name of the Dataset, which is used as a unique identifier.
      version_id:
        type: string
        docs: >-
          Unique identifier for the specific Dataset Version. If no query params
          provided, the default deployed Dataset Version is returned. Starts
          with `dsv_`.
      environments:
        type: optional<list<EnvironmentResponse>>
        docs: The list of environments the Dataset Version is deployed to.
      created_at:
        type: datetime
      updated_at:
        type: datetime
      created_by:
        type: optional<UserResponse>
        docs: The user who created the Dataset.
      status:
        type: VersionStatus
        docs: The status of the Dataset Version.
      last_used_at:
        type: datetime
      commit_message:
        type: optional<string>
        docs: >-
          Message describing the changes made. If provided, a committed version
          of the Dataset is created. Otherwise, an uncommitted version is
          created.
      datapoints_count:
        type: integer
        docs: The number of Datapoints in this Dataset version.
      datapoints:
        type: optional<list<DatapointResponse>>
        docs: >-
          The list of Datapoints in this Dataset version. Only provided if
          explicitly requested.
    source:
      openapi: ../openapi.yml
  EnvironmentResponse:
    properties:
      id: string
      created_at:
        type: datetime
      name: string
      tag:
        type: EnvironmentTag
    source:
      openapi: ../openapi.yml
  EnvironmentTag:
    enum:
      - default
      - other
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  EvaluatedVersionResponse:
    discriminated: false
    union:
      - type: PromptResponse
      - type: ToolResponse
    source:
      openapi: ../openapi.yml
  EvaluateeRequest:
    properties:
      version_id:
        type: string
        docs: >-
          Unique identifier for the Prompt/Tool Version to include in the
          Evaluation Report. Starts with `pv_` for Prompts and `tv_` for Tools.
      batch_id:
        type: optional<string>
        docs: >-
          Unique identifier for the batch of Logs to include in the Evaluation
          Report.
      orchestrated:
        type: optional<boolean>
        docs: >-
          Whether the Prompt/Tool is orchestrated by Humanloop. Default is
          `True`. If `False`, a log for the Prompt/Tool should be submitted by
          the user via the API.
        default: true
    source:
      openapi: ../openapi.yml
  EvaluateeResponse:
    properties:
      version:
        type: EvaluatedVersionResponse
      batch_id:
        type: optional<string>
        docs: >-
          Unique identifier for the batch of Logs to include in the Evaluation
          Report. 
      orchestrated:
        type: boolean
        docs: >-
          Whether the Prompt/Tool is orchestrated by Humanloop. Default is
          `True`. If `False`, a log for the Prompt/Tool should be submitted by
          the user via the API.
    source:
      openapi: ../openapi.yml
  Value:
    discriminated: false
    union:
      - boolean
      - double
    source:
      openapi: ../openapi.yml
    inline: true
  EvaluationDebugResultResponse:
    docs: >-
      This is similar to an `EvaluationResult` but is ephemeral as it is only
      for synchronous

      debug runs. It does not have an ID, or a reference to an evaluation run or
      even an evaluation

      function.
    properties:
      log_id: string
      log:
        type: LogResponse
      datapoint_id:
        type: optional<string>
      llm_evaluation_log:
        type: optional<LogResponse>
      value:
        type: optional<Value>
      error:
        type: optional<string>
    source:
      openapi: ../openapi.yml
  EvaluationEvaluatorResponse:
    properties:
      version:
        type: EvaluatorResponse
      orchestrated:
        type: boolean
        docs: >-
          Whether the Evaluator is orchestrated by Humanloop. Default is `True`.
          If `False`, a log for the Evaluator should be submitted by the user
          via the API.
    source:
      openapi: ../openapi.yml
  EvaluationResponse:
    properties:
      id:
        type: string
        docs: Unique identifier for the Evaluation. Starts with `evr`.
      dataset:
        type: DatasetResponse
        docs: The Dataset Version used in the Evaluation.
      evaluatees:
        docs: The Prompt/Tool Versions included in the Evaluation.
        type: list<EvaluateeResponse>
      evaluators:
        docs: The Evaluator Versions used to evaluate.
        type: list<EvaluationEvaluatorResponse>
      status:
        type: EvaluationStatus
        docs: >
          The current status of the Evaluation.


          - `"pending"`: The Evaluation has been created but is not actively
          being worked on by Humanloop.

          - `"running"`: Humanloop is checking for any missing Logs and
          Evaluator Logs, and will generate them where appropriate.

          - `"completed"`: All Logs an Evaluator Logs have been generated.

          - `"cancelled"`: The Evaluation has been cancelled by the user.
          Humanloop will stop generating Logs and Evaluator Logs.
      created_at:
        type: datetime
      created_by:
        type: optional<UserResponse>
      updated_at:
        type: datetime
    source:
      openapi: ../openapi.yml
  EvaluationResultResponse:
    properties:
      id: string
      evaluator_id: string
      evaluator_version_id: string
      evaluation_id:
        type: optional<string>
      log_id: string
      log:
        type: optional<LogResponse>
      version_id:
        type: optional<string>
      version:
        type: optional<unknown>
      value:
        type: optional<Value>
      error:
        type: optional<string>
      updated_at:
        type: datetime
      created_at:
        type: datetime
      llm_evaluator_log:
        type: optional<LogResponse>
    source:
      openapi: ../openapi.yml
  EvaluationStats:
    properties:
      overall_stats:
        type: OverallStats
        docs: Stats for the Evaluation Report as a whole.
      version_stats:
        docs: Stats for each Evaluated Version in the Evaluation Report.
        type: list<VersionStats>
    source:
      openapi: ../openapi.yml
  EvaluationStatus:
    enum:
      - pending
      - running
      - completed
      - cancelled
      - failed
    docs: Status of an evaluation.
    source:
      openapi: ../openapi.yml
  EvaluatorActivationDeactivationRequestEvaluatorsToActivateItem:
    discriminated: false
    union:
      - type: MonitoringEvaluatorVersionRequest
      - type: MonitoringEvaluatorEnvironmentRequest
    source:
      openapi: ../openapi.yml
    inline: true
  EvaluatorActivationDeactivationRequestEvaluatorsToDeactivateItem:
    discriminated: false
    union:
      - type: MonitoringEvaluatorVersionRequest
      - type: MonitoringEvaluatorEnvironmentRequest
    source:
      openapi: ../openapi.yml
    inline: true
  EvaluatorActivationDeactivationRequest:
    properties:
      evaluators_to_activate:
        type: >-
          optional<list<EvaluatorActivationDeactivationRequestEvaluatorsToActivateItem>>
        docs: >-
          Monitoring Evaluators to activate. These will be automatically run on
          new Logs.
      evaluators_to_deactivate:
        type: >-
          optional<list<EvaluatorActivationDeactivationRequestEvaluatorsToDeactivateItem>>
        docs: Evaluators to deactivate. These will not be run on new Logs.
    source:
      openapi: ../openapi.yml
  EvaluatorArgumentsType:
    enum:
      - target_free
      - target_required
    docs: Enum representing the possible argument types of an evaluator.
    source:
      openapi: ../openapi.yml
  EvaluatorConfigResponse:
    properties:
      id:
        type: string
        docs: String ID of config. Starts with `config_`.
      other:
        type: optional<map<string, unknown>>
        docs: Other parameters that define the config.
      created_by:
        type: optional<UserResponse>
        docs: The user who created the config.
      status:
        type: string
        docs: Whether the config is committed or not.
      name:
        type: string
        docs: Name of config.
      description:
        type: optional<string>
        docs: Description of config.
      evaluator_type:
        type: string
        docs: Type of evaluator.
      model_config:
        type: optional<ModelConfigResponse>
        docs: The model config defining the LLM evaluator.
      code:
        type: optional<string>
        docs: >-
          The code for the evaluator. This code will be executed in a sandboxed
          environment.
      arguments_type:
        type: optional<EvaluatorArgumentsType>
        docs: Whether this evaluator is target-free or target-required.
      return_type:
        type: optional<EvaluatorReturnTypeEnum>
        docs: The type of the return value of the evaluator.
    source:
      openapi: ../openapi.yml
  Spec:
    discriminant: evaluator_type
    base-properties: {}
    union:
      llm:
        type: LLMEvaluatorRequest
      python:
        type: CodeEvaluatorRequest
      human:
        type: HumanEvaluatorRequest
    source:
      openapi: ../openapi.yml
  EvaluatorResponse:
    docs: Request model for creating a new Evaluator
    properties:
      id:
        type: string
        docs: Unique identifier for the Evaluator.
      name:
        type: string
        docs: Name of the Evaluator, which is used as a unique identifier.
      version_id:
        type: string
        docs: >-
          Unique identifier for the specific Evaluator Version. If no query
          params provided, the default deployed Evaluator Version is returned.
      directory_id:
        type: optional<string>
        docs: Unique identifier for the Directory of the Evaluator.
      environments:
        type: optional<list<EnvironmentResponse>>
        docs: The list of environments the Prompt Version is deployed to.
      created_at:
        type: datetime
      updated_at:
        type: datetime
      created_by:
        type: optional<UserResponse>
        docs: The user who created the Prompt.
      status:
        type: VersionStatus
      last_used_at:
        type: datetime
      commit_message:
        type: optional<string>
        docs: Message describing the changes made.
      spec:
        display-name: Spec
        type: Spec
      version_logs_count:
        type: integer
        docs: The number of logs that have been generated for this Prompt Version
      total_logs_count:
        type: integer
        docs: The number of logs that have been generated across all Prompt Versions
      inputs:
        docs: >-
          Inputs associated to the Prompt. Inputs correspond to any of the
          variables used within the Prompt template.
        type: list<InputResponse>
    source:
      openapi: ../openapi.yml
  EvaluatorReturnTypeEnum:
    enum:
      - boolean
      - number
    docs: Enum representing the possible return types of an evaluator.
    source:
      openapi: ../openapi.yml
  FeedbackClass:
    enum:
      - select
      - multi_select
      - text
      - number
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  FeedbackLabelStatus:
    enum:
      - unset
      - active
      - inactive
    docs: Controls whether the label is displayed in the UI.
    source:
      openapi: ../openapi.yml
  FeedbackResponseType:
    discriminated: false
    docs: >-
      The type of feedback. The default feedback types available are 'rating',
      'action', 'issue', 'correction', and 'comment'.
    union:
      - type: FeedbackType
      - string
    source:
      openapi: ../openapi.yml
    inline: true
  FeedbackResponseValue:
    discriminated: false
    docs: >-
      The feedback value to set. This would be the appropriate text for
      'correction' or 'comment', or a label to apply for 'rating', 'action', or
      'issue'.
    union:
      - double
      - string
    source:
      openapi: ../openapi.yml
    inline: true
  FeedbackResponse:
    properties:
      type:
        display-name: Feedback type
        type: FeedbackResponseType
        docs: >-
          The type of feedback. The default feedback types available are
          'rating', 'action', 'issue', 'correction', and 'comment'.
      value:
        display-name: Feedback value
        type: FeedbackResponseValue
        docs: >-
          The feedback value to set. This would be the appropriate text for
          'correction' or 'comment', or a label to apply for 'rating', 'action',
          or 'issue'.
      data_id:
        type: optional<string>
        docs: ID to associate the feedback to a previously logged datapoint.
      user:
        type: optional<string>
        docs: A unique identifier to who provided the feedback.
      created_at:
        type: optional<datetime>
        docs: 'User defined timestamp for when the feedback was created. '
      id:
        type: string
        docs: String ID of user feedback. Starts with `ann_`, short for annotation.
    source:
      openapi: ../openapi.yml
  FeedbackTypeModelType:
    discriminated: false
    docs: >-
      The type of feedback. The default feedback types available are 'rating',
      'action', 'issue', 'correction', and 'comment'.
    union:
      - type: FeedbackType
      - string
    source:
      openapi: ../openapi.yml
    inline: true
  FeedbackTypeModel:
    properties:
      type:
        display-name: Feedback type
        type: FeedbackTypeModelType
        docs: >-
          The type of feedback. The default feedback types available are
          'rating', 'action', 'issue', 'correction', and 'comment'.
      values:
        type: optional<list<CategoricalFeedbackLabel>>
        docs: >-
          The allowed values for categorical feedback types. Not populated for
          `correction` and `comment`.
    source:
      openapi: ../openapi.yml
  FeedbackTypes:
    type: list<FeedbackTypeModel>
  FunctionTool:
    docs: A function tool to be called by the model where user owns runtime.
    properties:
      name: string
      arguments:
        type: optional<string>
    source:
      openapi: ../openapi.yml
  FunctionToolChoice:
    docs: A function tool to be called by the model where user owns runtime.
    properties:
      name: string
    source:
      openapi: ../openapi.yml
  GenericConfigResponse:
    properties:
      id:
        type: string
        docs: String ID of config. Starts with `config_`.
      other:
        type: optional<map<string, unknown>>
        docs: Other parameters that define the config.
      created_by:
        type: optional<UserResponse>
        docs: The user who created the config.
      status:
        type: string
        docs: Whether the config is committed or not.
      name:
        type: string
        docs: Name of config.
      description:
        type: optional<string>
        docs: Description of config.
    source:
      openapi: ../openapi.yml
  HTTPValidationError:
    properties:
      detail:
        type: optional<list<ValidationError>>
    source:
      openapi: ../openapi.yml
  HumanEvaluatorRequest:
    properties:
      arguments_type:
        type: EvaluatorArgumentsType
        docs: Whether this evaluator is target-free or target-required.
      return_type:
        type: EvaluatorReturnTypeEnum
        docs: The type of the return value of the evaluator.
    source:
      openapi: ../openapi.yml
  ImageChatContent:
    properties:
      image_url:
        type: ImageUrl
        docs: The message's image content.
    source:
      openapi: ../openapi.yml
  ImageUrlDetail:
    enum:
      - high
      - low
      - auto
    docs: >-
      Specify the detail level of the image provided to the model. For more
      details see:
      https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding
    source:
      openapi: ../openapi.yml
  ImageUrl:
    properties:
      url:
        type: string
        docs: Either a URL of the image or the base64 encoded image data.
      detail:
        type: optional<ImageUrlDetail>
        docs: >-
          Specify the detail level of the image provided to the model. For more
          details see:
          https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding
    source:
      openapi: ../openapi.yml
  InputResponse:
    properties:
      name:
        type: string
        docs: Type of input.
    source:
      openapi: ../openapi.yml
  LLMEvaluatorRequest:
    properties:
      arguments_type:
        type: EvaluatorArgumentsType
        docs: Whether this evaluator is target-free or target-required.
      return_type:
        type: EvaluatorReturnTypeEnum
        docs: The type of the return value of the evaluator.
      prompt:
        type: optional<PromptKernelRequest>
        docs: The prompt parameters used to generate.
    source:
      openapi: ../openapi.yml
  LabelSentiment:
    enum:
      - positive
      - negative
      - neutral
      - unset
    docs: |-
      How a label should be treated in calculating Version performance.

      Used by a File's PAPV (Positive Action Per View) metric.
    source:
      openapi: ../openapi.yml
  LinkedToolRequest:
    properties:
      id:
        type: string
        docs: The ID of the linked tool. Starts with "oc_"
      source:
        type: literal<"organization">
        docs: >-
          The source of the linked tool. For a linked tool it should be
          `organization`
      name:
        type: optional<string>
        docs: The name of the linked tool.
      description:
        type: optional<string>
        docs: The description of the linked tool.
      parameters:
        type: optional<map<string, unknown>>
        docs: The parameters of the linked tool.
    source:
      openapi: ../openapi.yml
  LinkedToolResponse:
    properties:
      name:
        type: string
        docs: Name for the tool referenced by the model.
      description:
        type: string
        docs: Description of the tool referenced by the model
      parameters:
        type: optional<map<string, unknown>>
        docs: >-
          Parameters needed to run the Tool, defined in JSON Schema format:
          https://json-schema.org/
      id:
        type: string
        docs: Unique identifier for the Tool linked.
      version_id:
        type: string
        docs: Unique identifier for the Tool Version linked.
    source:
      openapi: ../openapi.yml
  ListDatasets:
    properties:
      records:
        docs: The list of Datasets.
        type: list<DatasetResponse>
    source:
      openapi: ../openapi.yml
  ListEvaluators:
    properties:
      records:
        docs: The list of Evaluators.
        type: list<EvaluatorResponse>
    source:
      openapi: ../openapi.yml
  ListPrompts:
    properties:
      records:
        docs: The list of Prompts.
        type: list<PromptResponse>
    source:
      openapi: ../openapi.yml
  ListTools:
    properties:
      records:
        docs: The list of Tools.
        type: list<ToolResponse>
    source:
      openapi: ../openapi.yml
  Judgment:
    discriminated: false
    union:
      - boolean
      - double
    source:
      openapi: ../openapi.yml
    inline: true
  LogResponseToolChoice:
    discriminated: false
    docs: >-
      Controls how the model uses tools. The following options are supported:
      'none' forces the model to not call a tool; the default when no tools are
      provided as part of the model config. 'auto' the model can decide to call
      one of the provided tools; the default when tools are provided as part of
      the model config. Providing {'type': 'function', 'function': {name':
      <TOOL_NAME>}} forces the model to use the named function.
    union:
      - literal<"none">
      - literal<"auto">
      - literal<"required">
      - type: ToolChoice
    source:
      openapi: ../openapi.yml
    inline: true
  LogResponse:
    docs: Request model for logging a datapoint.
    properties:
      project:
        type: optional<string>
        docs: The name of the project associated with this log
      project_id:
        type: optional<string>
        docs: The unique ID of the project associated with this log.
      session_id:
        type: optional<string>
        docs: ID of the session to associate the datapoint.
      session_reference_id:
        type: optional<string>
        docs: >-
          A unique string identifying the session to associate the datapoint to.
          Allows you to log multiple datapoints to a session (using an ID kept
          by your internal systems) by passing the same `session_reference_id`
          in subsequent log requests. Specify at most one of this or
          `session_id`.
      parent_id:
        type: optional<string>
        docs: ID associated to the parent datapoint in a session.
      parent_reference_id:
        type: optional<string>
        docs: >-
          A unique string identifying the previously-logged parent datapoint in
          a session. Allows you to log nested datapoints with your internal
          system IDs by passing the same reference ID as `parent_id` in a prior
          log request. Specify at most one of this or `parent_id`. Note that
          this cannot refer to a datapoint being logged in the same request.
      inputs:
        type: optional<map<string, unknown>>
        docs: The inputs passed to the prompt template.
      source:
        type: optional<string>
        docs: Identifies where the model was called from.
      metadata:
        type: optional<map<string, unknown>>
        docs: Any additional metadata to record.
      save:
        type: optional<boolean>
        docs: Whether the request/response payloads will be stored on Humanloop.
        default: true
      source_datapoint_id:
        type: optional<string>
        docs: >-
          ID of the source datapoint if this is a log derived from a datapoint
          in a dataset.
      id:
        type: string
        docs: String ID of logged datapoint. Starts with `data_`.
      reference_id:
        type: optional<string>
        docs: Unique user-provided string identifying the datapoint.
      trial_id:
        type: optional<string>
        docs: Unique ID of an experiment trial to associate to the log.
      messages:
        type: optional<list<ChatMessageWithToolCall>>
        docs: The messages passed to the to provider chat endpoint.
      output:
        type: optional<string>
        docs: >-
          Generated output from your model for the provided inputs. Can be
          `None` if logging an error, or if logging a parent datapoint with the
          intention to populate it later
      judgment:
        type: optional<Judgment>
      config_id:
        type: optional<string>
        docs: Unique ID of a config to associate to the log.
      config:
        type: ConfigResponse
      environment:
        type: optional<string>
        docs: The environment name used to create the log.
      feedback:
        type: optional<list<FeedbackResponse>>
      created_at:
        type: optional<datetime>
        docs: 'User defined timestamp for when the log was created. '
      error:
        type: optional<string>
        docs: Error message if the log is an error.
      duration:
        type: optional<double>
        docs: Duration of the logged event in seconds.
      output_message:
        type: optional<ChatMessageWithToolCall>
        docs: The message returned by the provider.
      prompt_tokens:
        type: optional<integer>
        docs: Number of tokens in the prompt used to generate the output.
      output_tokens:
        type: optional<integer>
        docs: Number of tokens in the output generated by the model.
      prompt_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the prompt.
      output_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the output.
      provider_request:
        type: optional<map<string, unknown>>
        docs: Raw request sent to provider.
      provider_response:
        type: optional<map<string, unknown>>
        docs: Raw response received the provider.
      user:
        type: optional<string>
        docs: User email address provided when creating the datapoint.
      provider_latency:
        type: optional<double>
        docs: Latency of provider response.
      tokens:
        type: optional<integer>
        docs: Total number of tokens in the prompt and output.
      raw_output:
        type: optional<string>
        docs: Raw output from the provider.
      finish_reason:
        type: optional<string>
        docs: Reason the generation finished.
      metric_values:
        type: optional<list<MetricValueResponse>>
      tools:
        type: optional<list<ToolResultResponse>>
      tool_choice:
        type: optional<LogResponseToolChoice>
        docs: >-
          Controls how the model uses tools. The following options are
          supported: 'none' forces the model to not call a tool; the default
          when no tools are provided as part of the model config. 'auto' the
          model can decide to call one of the provided tools; the default when
          tools are provided as part of the model config. Providing {'type':
          'function', 'function': {name': <TOOL_NAME>}} forces the model to use
          the named function.
      evaluation_results:
        type: list<EvaluationResultResponse>
      observability_status:
        type: ObservabilityStatus
      updated_at:
        type: datetime
      batch_ids:
        type: optional<list<string>>
        docs: List of batch IDs the log belongs to.
    source:
      openapi: ../openapi.yml
  MetricValueResponse:
    properties:
      metric_id: string
      metric_name: string
      metric_value: double
    source:
      openapi: ../openapi.yml
  ModelConfigRequestStop:
    discriminated: false
    docs: >-
      The string (or list of strings) after which the model will stop
      generating. The returned text will not contain the stop sequence.
    union:
      - string
      - list<string>
    source:
      openapi: ../openapi.yml
    inline: true
  ModelConfigRequestToolsItem:
    discriminated: false
    union:
      - type: LinkedToolRequest
      - type: ModelConfigToolRequest
    source:
      openapi: ../openapi.yml
    inline: true
  ModelConfigRequest:
    docs: Model config used for logging both chat and completion.
    properties:
      name:
        type: optional<string>
        docs: >-
          A friendly display name for the model config. If not provided, a name
          will be generated.
      description:
        type: optional<string>
        docs: A description of the model config.
      provider:
        type: optional<ModelProviders>
        docs: The company providing the underlying model service.
      model:
        type: string
        docs: The model instance used. E.g. text-davinci-002.
      max_tokens:
        type: optional<integer>
        docs: >-
          The maximum number of tokens to generate. Provide max_tokens=-1 to
          dynamically calculate the maximum number of tokens to generate given
          the length of the prompt
        default: -1
      temperature:
        type: optional<double>
        docs: >-
          What sampling temperature to use when making a generation. Higher
          values means the model will be more creative.
        default: 1
      top_p:
        type: optional<double>
        docs: >-
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass.
        default: 1
      stop:
        type: optional<ModelConfigRequestStop>
        docs: >-
          The string (or list of strings) after which the model will stop
          generating. The returned text will not contain the stop sequence.
      presence_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the generation so far.
        default: 0
      frequency_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on how frequently they appear in the generation so far.
        default: 0
      other:
        type: optional<map<string, unknown>>
        docs: Other parameter values to be passed to the provider call.
      seed:
        type: optional<integer>
        docs: >-
          If specified, model will make a best effort to sample
          deterministically, but it is not guaranteed.
      response_format:
        type: optional<ResponseFormat>
        docs: >-
          The format of the response. Only type json_object is currently
          supported for chat.
      endpoint:
        type: optional<ModelEndpoints>
        docs: The provider model endpoint used.
      prompt_template:
        type: optional<string>
        docs: >-
          Prompt template that will take your specified inputs to form your
          final request to the model. Input variables within the prompt template
          should be specified with syntax: {{INPUT_NAME}}.
      chat_template:
        type: optional<list<ChatMessageWithToolCall>>
        docs: >-
          Messages prepended to the list of messages sent to the provider. These
          messages that will take your specified inputs to form your final
          request to the provider model. Input variables within the template
          should be specified with syntax: {{INPUT_NAME}}.
      tools:
        type: optional<list<ModelConfigRequestToolsItem>>
        docs: Make tools available to OpenAIs chat model as functions.
      type:
        type: optional<literal<"model">>
    source:
      openapi: ../openapi.yml
  ModelConfigResponseStop:
    discriminated: false
    docs: >-
      The string (or list of strings) after which the model will stop
      generating. The returned text will not contain the stop sequence.
    union:
      - string
      - list<string>
    source:
      openapi: ../openapi.yml
    inline: true
  ModelConfigResponse:
    docs: >-
      Model config request.


      Contains fields that are common to all (i.e. both chat and complete)
      endpoints.
    properties:
      id:
        type: string
        docs: String ID of config. Starts with `config_`.
      other:
        type: optional<map<string, unknown>>
        docs: Other parameter values to be passed to the provider call.
      name:
        type: optional<string>
        docs: >-
          A friendly display name for the model config. If not provided, a name
          will be generated.
      description:
        type: optional<string>
        docs: A description of the model config.
      provider:
        type: optional<ModelProviders>
        docs: The company providing the underlying model service.
      model:
        type: string
        docs: The model instance used. E.g. text-davinci-002.
      max_tokens:
        type: optional<integer>
        docs: >-
          The maximum number of tokens to generate. Provide max_tokens=-1 to
          dynamically calculate the maximum number of tokens to generate given
          the length of the prompt
        default: -1
      temperature:
        type: optional<double>
        docs: >-
          What sampling temperature to use when making a generation. Higher
          values means the model will be more creative.
        default: 1
      top_p:
        type: optional<double>
        docs: >-
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass.
        default: 1
      stop:
        type: optional<ModelConfigResponseStop>
        docs: >-
          The string (or list of strings) after which the model will stop
          generating. The returned text will not contain the stop sequence.
      presence_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the generation so far.
        default: 0
      frequency_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on how frequently they appear in the generation so far.
        default: 0
      seed:
        type: optional<integer>
        docs: >-
          If specified, model will make a best effort to sample
          deterministically, but it is not guaranteed.
      response_format:
        type: optional<ResponseFormat>
        docs: >-
          The format of the response. Only type json_object is currently
          supported for chat.
      prompt_template:
        type: optional<string>
        docs: >-
          Prompt template that will take your specified inputs to form your
          final request to the model. NB: Input variables within the prompt
          template should be specified with syntax: {{INPUT_NAME}}.
      chat_template:
        type: optional<list<ChatMessageWithToolCall>>
        docs: >-
          Messages prepended to the list of messages sent to the provider. These
          messages that will take your specified inputs to form your final
          request to the provider model. NB: Input variables within the template
          should be specified with syntax: {{INPUT_NAME}}.
      tool_configs:
        type: optional<list<ToolConfigResponse>>
        docs: >-
          NB: Deprecated with tools field. Definition of tools shown to the
          model.
        availability: deprecated
      tools:
        type: optional<list<ToolResponse>>
        docs: Tools shown to the model.
      endpoint:
        type: optional<ModelEndpoints>
        docs: The provider model endpoint used.
    source:
      openapi: ../openapi.yml
  ModelConfigToolRequest:
    docs: |-
      Definition of tool within a model config.

      The subset of ToolConfig parameters received by the chat endpoint.
      Does not have things like the signature or setup schema.
    properties:
      name:
        type: string
        docs: The name of the tool shown to the model.
      description:
        type: optional<string>
        docs: The description of the tool shown to the model.
      parameters:
        type: optional<map<string, unknown>>
        docs: >-
          Definition of parameters needed to run the tool. Provided in
          jsonschema format: https://json-schema.org/
      source:
        type: optional<ToolSource>
        docs: >-
          Source of the tool. If defined at an organization level will be
          'organization' else 'inline'.
      source_code:
        type: optional<string>
        docs: Code source of the tool.
      other:
        type: optional<map<string, unknown>>
        docs: Other parameters that define the config.
      preset_name:
        type: optional<string>
        docs: >-
          If is_preset = true, this is the name of the preset tool on Humanloop.
          This is used as the key to look up the Humanloop runtime of the tool
    source:
      openapi: ../openapi.yml
  ModelEndpoints:
    enum:
      - complete
      - chat
      - edit
    docs: Supported model provider endpoints.
    source:
      openapi: ../openapi.yml
  ModelProviders:
    enum:
      - openai
      - openai_azure
      - ai21
      - mock
      - anthropic
      - langchain
      - cohere
      - replicate
      - google
      - groq
    docs: Supported model providers.
    source:
      openapi: ../openapi.yml
  MonitoringEvaluatorEnvironmentRequest:
    properties:
      evaluator_id:
        type: string
        docs: Unique identifier for the Evaluator to be used for monitoring.
      environment_id:
        type: string
        docs: >-
          Unique identifier for the Environment. The Evaluator Version deployed
          to this Environment will be used for monitoring.
    source:
      openapi: ../openapi.yml
  MonitoringEvaluatorResponse:
    properties:
      version_reference:
        type: VersionReferenceResponse
        docs: >-
          The Evaluator Version used for monitoring. This can be a specific
          Version by ID, or a Version deployed to an Environment.
      version:
        type: optional<EvaluatorResponse>
        docs: The deployed Version.
      state:
        type: MonitoringEvaluatorState
        docs: The state of the Monitoring Evaluator. Either `active` or `inactive`
      created_at:
        type: datetime
      updated_at:
        type: datetime
    source:
      openapi: ../openapi.yml
  MonitoringEvaluatorState:
    enum:
      - active
      - inactive
    docs: State of an evaluator connected to a file
    source:
      openapi: ../openapi.yml
  MonitoringEvaluatorVersionRequest:
    properties:
      evaluator_version_id:
        type: string
        docs: Unique identifier for the Evaluator Version to be used for monitoring.
    source:
      openapi: ../openapi.yml
  NumericEvaluatorVersionStats:
    docs: |-
      Base attributes for stats for an Evaluator Version-Evaluated Version pair
      in the Evaluation Report.
    properties:
      evaluator_version_id:
        type: string
        docs: Unique identifier for the Evaluator Version.
      total_logs:
        type: integer
        docs: >-
          The total number of Logs generated by this Evaluator Version on the
          Evaluated Version's Logs. This includes Nulls and Errors.
      num_judgments:
        type: integer
        docs: >-
          The total number of Evaluator judgments for this Evaluator Version.
          This excludes Nulls and Errors.
      num_nulls:
        type: integer
        docs: >-
          The total number of null judgments (i.e. abstentions) for this
          Evaluator Version.
      num_errors:
        type: integer
        docs: The total number of errored Evaluators for this Evaluator Version.
      mean:
        type: optional<double>
      std:
        type: optional<double>
      percentiles:
        type: map<string, double>
    source:
      openapi: ../openapi.yml
  ObservabilityStatus:
    enum:
      - pending
      - running
      - completed
      - failed
    docs: |-
      Status of a Log for observability.

      Observability is implemented by running monitoring Evaluators on Logs.
    source:
      openapi: ../openapi.yml
  OverallStats:
    properties:
      num_datapoints:
        type: integer
        docs: >-
          The total number of Datapoints in the Evaluation Report's Dataset
          Version.
      total_logs:
        type: integer
        docs: The total number of Logs in the Evaluation Report.
      total_evaluator_logs:
        type: integer
        docs: The total number of Evaluator Logs in the Evaluation Report.
    source:
      openapi: ../openapi.yml
  PaginatedDataDatapointResponse:
    properties:
      records:
        type: list<DatapointResponse>
      page: integer
      size: integer
      total: integer
    source:
      openapi: ../openapi.yml
  PaginatedDataDatasetResponse:
    properties:
      records:
        type: list<DatasetResponse>
      page: integer
      size: integer
      total: integer
    source:
      openapi: ../openapi.yml
  PaginatedDataEvaluationResponse:
    properties:
      records:
        type: list<EvaluationResponse>
      page: integer
      size: integer
      total: integer
    source:
      openapi: ../openapi.yml
  PaginatedDataPromptLogResponse:
    properties:
      records:
        type: list<PromptLogResponse>
      page: integer
      size: integer
      total: integer
    source:
      openapi: ../openapi.yml
  PaginatedDataSessionResponse:
    properties:
      records:
        type: list<SessionResponse>
      page: integer
      size: integer
      total: integer
    source:
      openapi: ../openapi.yml
  PlatformAccessEnum:
    enum:
      - superadmin
      - supportadmin
      - user
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  ProjectSortBy:
    enum:
      - created_at
      - updated_at
      - name
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  PromptCallLogResponse:
    docs: Sample specific response details for a Prompt call
    properties:
      output:
        type: optional<string>
        docs: >-
          Generated output from your model for the provided inputs. Can be
          `None` if logging an error, or if creating a parent Log with the
          intention to populate it later.
      raw_output:
        type: optional<string>
        docs: Raw output from the provider.
      created_at:
        type: optional<datetime>
        docs: 'User defined timestamp for when the log was created. '
      error:
        type: optional<string>
        docs: Error message if the log is an error.
      provider_latency:
        type: optional<double>
        docs: Duration of the logged event in seconds.
      output_message:
        type: optional<ChatMessage>
        docs: The message returned by the provider.
      prompt_tokens:
        type: optional<integer>
        docs: Number of tokens in the prompt used to generate the output.
      output_tokens:
        type: optional<integer>
        docs: Number of tokens in the output generated by the model.
      prompt_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the prompt.
      output_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the output.
      finish_reason:
        type: optional<string>
        docs: Reason the generation finished.
      index:
        type: integer
        docs: The index of the sample in the batch.
    source:
      openapi: ../openapi.yml
  PromptCallResponseToolChoice:
    discriminated: false
    docs: >-
      Controls how the model uses tools. The following options are supported: 

      - `'none'` means the model will not call any tool and instead generates a
      message; this is the default when no tools are provided as part of the
      Prompt. 

      - `'auto'` means the model can decide to call one or more of the provided
      tools; this is the default when tools are provided as part of the Prompt. 

      - `'required'` means the model can decide to call one or more of the
      provided tools. 

      - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the
      model to use the named function.
    union:
      - literal<"none">
      - literal<"auto">
      - literal<"required">
      - type: ToolChoice
    source:
      openapi: ../openapi.yml
    inline: true
  PromptCallResponse:
    docs: Response model for a Prompt call with potentially multiple log samples.
    properties:
      prompt:
        type: PromptResponse
        docs: Prompt details used to generate the log.
      messages:
        type: optional<list<ChatMessage>>
        docs: The messages passed to the to provider chat endpoint.
      tool_choice:
        type: optional<PromptCallResponseToolChoice>
        docs: >-
          Controls how the model uses tools. The following options are
          supported: 

          - `'none'` means the model will not call any tool and instead
          generates a message; this is the default when no tools are provided as
          part of the Prompt. 

          - `'auto'` means the model can decide to call one or more of the
          provided tools; this is the default when tools are provided as part of
          the Prompt. 

          - `'required'` means the model can decide to call one or more of the
          provided tools. 

          - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the
          model to use the named function.
      session_id:
        type: optional<string>
        docs: >-
          Unique identifier for the Session to associate the Log to. Allows you
          to record multiple Logs to a Session (using an ID kept by your
          internal systems) by passing the same `session_id` in subsequent log
          requests. 
      parent_id:
        type: optional<string>
        docs: >-
          Unique identifier for the parent Log in a Session. Should only be
          provided if `session_id` is provided. If provided, the Log will be
          nested under the parent Log within the Session.
      inputs:
        type: optional<map<string, unknown>>
        docs: The inputs passed to the prompt template.
      source:
        type: optional<string>
        docs: Identifies where the model was called from.
      metadata:
        type: optional<map<string, unknown>>
        docs: Any additional metadata to record.
      save:
        type: optional<boolean>
        docs: Whether the request/response payloads will be stored on Humanloop.
        default: true
      source_datapoint_id:
        type: optional<string>
        docs: >-
          Unique identifier for the Datapoint that this Log is derived from.
          This can be used by Humanloop to associate Logs to Evaluations. If
          provided, Humanloop will automatically associate this Log to
          Evaluations that require a Log for this Datapoint-Version pair.
      batches:
        type: optional<list<string>>
        docs: >-
          Array of Batch Ids that this log is part of. Batches are used to group
          Logs together for offline Evaluations
      user:
        type: optional<string>
        docs: End-user ID related to the Log.
      environment:
        type: optional<string>
        docs: The name of the Environment the Log is associated to.
      id:
        type: string
        docs: ID of the log.
      logs:
        docs: The logs generated by the Prompt call.
        type: list<PromptCallLogResponse>
    source:
      openapi: ../openapi.yml
  PromptCallStreamResponse:
    docs: Response model for calling Prompt in streaming mode.
    properties:
      output:
        type: optional<string>
        docs: >-
          Generated output from your model for the provided inputs. Can be
          `None` if logging an error, or if creating a parent Log with the
          intention to populate it later.
      raw_output:
        type: optional<string>
        docs: Raw output from the provider.
      created_at:
        type: optional<datetime>
        docs: 'User defined timestamp for when the log was created. '
      error:
        type: optional<string>
        docs: Error message if the log is an error.
      provider_latency:
        type: optional<double>
        docs: Duration of the logged event in seconds.
      output_message:
        type: optional<ChatMessage>
        docs: The message returned by the provider.
      prompt_tokens:
        type: optional<integer>
        docs: Number of tokens in the prompt used to generate the output.
      output_tokens:
        type: optional<integer>
        docs: Number of tokens in the output generated by the model.
      prompt_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the prompt.
      output_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the output.
      finish_reason:
        type: optional<string>
        docs: Reason the generation finished.
      index:
        type: integer
        docs: The index of the sample in the batch.
      id:
        type: string
        docs: ID of the log.
      prompt_id:
        type: string
        docs: ID of the Prompt the log belongs to.
      version_id:
        type: string
        docs: ID of the specific version of the Prompt.
    source:
      openapi: ../openapi.yml
  Template:
    discriminated: false
    docs: >-
      For chat endpoint, provide a Chat template. For completion endpoint,
      provide a Prompt template. Input variables within the template should be
      specified with double curly bracket syntax: {{INPUT_NAME}}.
    union:
      - string
      - list<ChatMessage>
    source:
      openapi: ../openapi.yml
    inline: true
  PromptKernelRequestStop:
    discriminated: false
    docs: >-
      The string (or list of strings) after which the model will stop
      generating. The returned text will not contain the stop sequence.
    union:
      - string
      - list<string>
    source:
      openapi: ../openapi.yml
    inline: true
  PromptKernelRequest:
    properties:
      model:
        type: string
        docs: >-
          The model instance used, e.g. `gpt-4`. See [supported
          models](https://humanloop.com/docs/supported-models)
      endpoint:
        type: optional<ModelEndpoints>
        docs: The provider model endpoint used.
      template:
        type: optional<Template>
        docs: >-
          For chat endpoint, provide a Chat template. For completion endpoint,
          provide a Prompt template. Input variables within the template should
          be specified with double curly bracket syntax: {{INPUT_NAME}}.
      provider:
        type: optional<ModelProviders>
        docs: The company providing the underlying model service.
      max_tokens:
        type: optional<integer>
        docs: >-
          The maximum number of tokens to generate. Provide max_tokens=-1 to
          dynamically calculate the maximum number of tokens to generate given
          the length of the prompt
        default: -1
      temperature:
        type: optional<double>
        docs: >-
          What sampling temperature to use when making a generation. Higher
          values means the model will be more creative.
        default: 1
      top_p:
        type: optional<double>
        docs: >-
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass.
        default: 1
      stop:
        type: optional<PromptKernelRequestStop>
        docs: >-
          The string (or list of strings) after which the model will stop
          generating. The returned text will not contain the stop sequence.
      presence_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the generation so far.
        default: 0
      frequency_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on how frequently they appear in the generation so far.
        default: 0
      other:
        type: optional<map<string, unknown>>
        docs: Other parameter values to be passed to the provider call.
      seed:
        type: optional<integer>
        docs: >-
          If specified, model will make a best effort to sample
          deterministically, but it is not guaranteed.
      response_format:
        type: optional<ResponseFormat>
        docs: >-
          The format of the response. Only `{"type": "json_object"}` is
          currently supported for chat.
      tools:
        type: optional<list<ToolFunction>>
        docs: >-
          The tool specification that the model can choose to call if Tool
          calling is supported.
      linked_tools:
        type: optional<list<string>>
        docs: >-
          The IDs of the Tools in your organization that the model can choose to
          call if Tool calling is supported. The default deployed version of
          that tool is called.
    source:
      openapi: ../openapi.yml
  PromptLogResponseToolChoice:
    discriminated: false
    docs: >-
      Controls how the model uses tools. The following options are supported: 

      - `'none'` means the model will not call any tool and instead generates a
      message; this is the default when no tools are provided as part of the
      Prompt. 

      - `'auto'` means the model can decide to call one or more of the provided
      tools; this is the default when tools are provided as part of the Prompt. 

      - `'required'` means the model can decide to call one or more of the
      provided tools. 

      - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the
      model to use the named function.
    union:
      - literal<"none">
      - literal<"auto">
      - literal<"required">
      - type: ToolChoice
    source:
      openapi: ../openapi.yml
    inline: true
  PromptLogResponse:
    docs: Request for creating a Prompt log.
    properties:
      output_message:
        type: optional<ChatMessage>
        docs: The message returned by the provider.
      prompt_tokens:
        type: optional<integer>
        docs: Number of tokens in the prompt used to generate the output.
      output_tokens:
        type: optional<integer>
        docs: Number of tokens in the output generated by the model.
      prompt_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the prompt.
      output_cost:
        type: optional<double>
        docs: Cost in dollars associated to the tokens in the output.
      finish_reason:
        type: optional<string>
        docs: Reason the generation finished.
      prompt:
        type: PromptResponse
        docs: Prompt details used to generate the log.
      messages:
        type: optional<list<ChatMessage>>
        docs: The messages passed to the to provider chat endpoint.
      tool_choice:
        type: optional<PromptLogResponseToolChoice>
        docs: >-
          Controls how the model uses tools. The following options are
          supported: 

          - `'none'` means the model will not call any tool and instead
          generates a message; this is the default when no tools are provided as
          part of the Prompt. 

          - `'auto'` means the model can decide to call one or more of the
          provided tools; this is the default when tools are provided as part of
          the Prompt. 

          - `'required'` means the model can decide to call one or more of the
          provided tools. 

          - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the
          model to use the named function.
      output:
        type: optional<string>
        docs: >-
          Generated output from your model for the provided inputs. Can be
          `None` if logging an error, or if creating a parent Log with the
          intention to populate it later.
      raw_output:
        type: optional<string>
        docs: Raw output from the provider.
      created_at:
        type: optional<datetime>
        docs: 'User defined timestamp for when the log was created. '
      error:
        type: optional<string>
        docs: Error message if the log is an error.
      provider_latency:
        type: optional<double>
        docs: Duration of the logged event in seconds.
      provider_request:
        type: optional<map<string, unknown>>
        docs: Raw request sent to provider.
      provider_response:
        type: optional<map<string, unknown>>
        docs: Raw response received the provider.
      session_id:
        type: optional<string>
        docs: >-
          Unique identifier for the Session to associate the Log to. Allows you
          to record multiple Logs to a Session (using an ID kept by your
          internal systems) by passing the same `session_id` in subsequent log
          requests. 
      parent_id:
        type: optional<string>
        docs: >-
          Unique identifier for the parent Log in a Session. Should only be
          provided if `session_id` is provided. If provided, the Log will be
          nested under the parent Log within the Session.
      inputs:
        type: optional<map<string, unknown>>
        docs: The inputs passed to the prompt template.
      source:
        type: optional<string>
        docs: Identifies where the model was called from.
      metadata:
        type: optional<map<string, unknown>>
        docs: Any additional metadata to record.
      save:
        type: optional<boolean>
        docs: Whether the request/response payloads will be stored on Humanloop.
        default: true
      source_datapoint_id:
        type: optional<string>
        docs: >-
          Unique identifier for the Datapoint that this Log is derived from.
          This can be used by Humanloop to associate Logs to Evaluations. If
          provided, Humanloop will automatically associate this Log to
          Evaluations that require a Log for this Datapoint-Version pair.
      batches:
        type: optional<list<string>>
        docs: >-
          Array of Batch Ids that this log is part of. Batches are used to group
          Logs together for offline Evaluations
      user:
        type: optional<string>
        docs: End-user ID related to the Log.
      environment:
        type: optional<string>
        docs: The name of the Environment the Log is associated to.
      id:
        type: string
        docs: Unique identifier for the Log.
    source:
      openapi: ../openapi.yml
  PromptResponseStop:
    discriminated: false
    docs: >-
      The string (or list of strings) after which the model will stop
      generating. The returned text will not contain the stop sequence.
    union:
      - string
      - list<string>
    source:
      openapi: ../openapi.yml
    inline: true
  PromptResponse:
    docs: Request model for creating a new Prompt
    properties:
      id:
        type: string
        docs: Unique identifier for the Prompt.
      name:
        type: string
        docs: Name of the Prompt, which is used as a unique identifier.
      version_id:
        type: string
        docs: >-
          Unique identifier for the specific Prompt Version. If no query params
          provided, the default deployed Prompt Version is returned.
      directory_id:
        type: optional<string>
        docs: 'Unique identifier for the Directory of the Prompt. '
      environments:
        type: optional<list<EnvironmentResponse>>
        docs: The list of environments the Prompt Version is deployed to.
      created_at:
        type: datetime
      updated_at:
        type: datetime
      created_by:
        type: optional<UserResponse>
        docs: The user who created the Prompt.
      status:
        type: VersionStatus
        docs: The status of the Prompt Version.
      last_used_at:
        type: datetime
      model:
        type: string
        docs: >-
          The model instance used, e.g. `gpt-4`. See [supported
          models](https://humanloop.com/docs/supported-models)
      endpoint:
        type: optional<ModelEndpoints>
        docs: The provider model endpoint used.
      template:
        type: optional<Template>
        docs: >-
          For chat endpoint, provide a Chat template. For completion endpoint,
          provide a Prompt template. Input variables within the template should
          be specified with double curly bracket syntax: {{INPUT_NAME}}.
      provider:
        type: optional<ModelProviders>
        docs: The company providing the underlying model service.
      max_tokens:
        type: optional<integer>
        docs: >-
          The maximum number of tokens to generate. Provide max_tokens=-1 to
          dynamically calculate the maximum number of tokens to generate given
          the length of the prompt
        default: -1
      temperature:
        type: optional<double>
        docs: >-
          What sampling temperature to use when making a generation. Higher
          values means the model will be more creative.
        default: 1
      top_p:
        type: optional<double>
        docs: >-
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass.
        default: 1
      stop:
        type: optional<PromptResponseStop>
        docs: >-
          The string (or list of strings) after which the model will stop
          generating. The returned text will not contain the stop sequence.
      presence_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the generation so far.
        default: 0
      frequency_penalty:
        type: optional<double>
        docs: >-
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on how frequently they appear in the generation so far.
        default: 0
      other:
        type: optional<map<string, unknown>>
        docs: Other parameter values to be passed to the provider call.
      seed:
        type: optional<integer>
        docs: >-
          If specified, model will make a best effort to sample
          deterministically, but it is not guaranteed.
      response_format:
        type: optional<ResponseFormat>
        docs: >-
          The format of the response. Only `{"type": "json_object"}` is
          currently supported for chat.
      tools:
        type: optional<list<ToolFunction>>
        docs: >-
          The tool specification that the model can choose to call if Tool
          calling is supported.
      linked_tools:
        type: optional<list<LinkedToolResponse>>
        docs: >-
          The IDs of the Tools in your organization that the model can choose to
          call if Tool calling is supported. The default deployed version of
          that tool is called.
      commit_message:
        type: optional<string>
        docs: Message describing the changes made.
      version_logs_count:
        type: integer
        docs: The number of logs that have been generated for this Prompt Version
      total_logs_count:
        type: integer
        docs: The number of logs that have been generated across all Prompt Versions
      inputs:
        docs: >-
          Inputs associated to the Prompt. Inputs correspond to any of the
          variables used within the Prompt template.
        type: list<InputResponse>
    source:
      openapi: ../openapi.yml
  ProviderApiKeys:
    properties:
      openai:
        type: optional<string>
      ai21:
        type: optional<string>
      mock:
        type: optional<string>
      anthropic:
        type: optional<string>
      cohere:
        type: optional<string>
      openai_azure:
        type: optional<string>
      openai_azure_endpoint:
        type: optional<string>
    source:
      openapi: ../openapi.yml
  ResponseFormat:
    docs: Response format of the model.
    properties:
      type:
        type: literal<"json_object">
    source:
      openapi: ../openapi.yml
  SessionResponse:
    properties:
      id:
        type: string
        docs: Unique identifier for the Session.
      created_at:
        type: datetime
      updated_at:
        type: datetime
      logs:
        docs: List of Logs associated with this Session.
        type: list<PromptLogResponse>
    source:
      openapi: ../openapi.yml
  SortOrder:
    enum:
      - asc
      - desc
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  TextChatContent:
    properties:
      text:
        type: string
        docs: The message's text content.
    source:
      openapi: ../openapi.yml
  TimeUnit:
    enum:
      - day
      - week
      - month
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  ToolCall:
    docs: A tool call to be made.
    properties:
      id: string
      type:
        type: ToolType
      function:
        type: FunctionTool
    source:
      openapi: ../openapi.yml
  ToolChoice:
    docs: Tool choice to force the model to use a tool.
    properties:
      type:
        type: ToolType
      function:
        type: FunctionToolChoice
    source:
      openapi: ../openapi.yml
  ToolConfigRequest:
    docs: |-
      Definition of tool within a model config.

      The subset of ToolConfig parameters received by the chat endpoint.
      Does not have things like the signature or setup schema.
    properties:
      name:
        type: string
        docs: The name of the tool shown to the model.
      description:
        type: optional<string>
        docs: The description of the tool shown to the model.
      parameters:
        type: optional<map<string, unknown>>
        docs: >-
          Definition of parameters needed to run the tool. Provided in
          jsonschema format: https://json-schema.org/
      source:
        type: optional<ToolSource>
        docs: >-
          Source of the tool. If defined at an organization level will be
          'organization' else 'inline'.
      source_code:
        type: optional<string>
        docs: Code source of the tool.
      other:
        type: optional<map<string, unknown>>
        docs: Other parameters that define the config.
      preset_name:
        type: optional<string>
        docs: >-
          If is_preset = true, this is the name of the preset tool on Humanloop.
          This is used as the key to look up the Humanloop runtime of the tool
      type:
        type: literal<"tool">
    source:
      openapi: ../openapi.yml
  ToolConfigResponse:
    properties:
      id:
        type: string
        docs: String ID of config. Starts with `config_`.
      other:
        type: optional<map<string, unknown>>
        docs: Other parameters that define the config.
      created_by:
        type: optional<UserResponse>
        docs: The user who created the config.
      status:
        type: string
        docs: Whether the config is committed or not.
      name:
        type: string
        docs: Name for the tool referenced by the model.
      description:
        type: optional<string>
        docs: Description of the tool referenced by the model
      source:
        type: optional<ToolSource>
        docs: >-
          Source of the tool. If defined at an organization level will be
          'organization' else 'inline'.
      source_code:
        type: optional<string>
        docs: Code source of the tool.
      setup_schema:
        type: optional<map<string, unknown>>
        docs: >-
          Definition of parameters needed to run the tool. Provided in
          jsonschema format: https://json-schema.org/
      parameters:
        type: optional<map<string, unknown>>
        docs: >-
          Definition of parameters needed to run the tool. Provided in
          jsonschema format: https://json-schema.org/
      signature:
        type: optional<string>
        docs: The function signature of the tool when being called.
      is_preset:
        type: optional<boolean>
        docs: Whether the tool is one where Humanloop defines runtime or not.
      preset_name:
        type: optional<string>
        docs: >-
          If is_preset = true, this is the name of the preset tool on Humanloop.
          This is used as the key to lookup the Humanloop runtime of the tool
    source:
      openapi: ../openapi.yml
  ToolFunction:
    properties:
      name:
        type: string
        docs: Name for the tool referenced by the model.
      description:
        type: string
        docs: Description of the tool referenced by the model
      parameters:
        type: optional<map<string, unknown>>
        docs: >-
          Parameters needed to run the Tool, defined in JSON Schema format:
          https://json-schema.org/
    source:
      openapi: ../openapi.yml
  ToolKernelRequest:
    properties:
      function:
        type: optional<ToolFunction>
        docs: >-
          Callable function specification of the Tool shown to the model for
          tool calling.
      source_code:
        type: optional<string>
        docs: Code source of the Tool.
      setup_values:
        type: optional<map<string, unknown>>
        docs: >-
          Values needed to setup the Tool, defined in JSON Schema format:
          https://json-schema.org/
    source:
      openapi: ../openapi.yml
  ToolResultResponse:
    docs: A result from a tool used to populate the prompt template
    properties:
      id: string
      name: string
      signature: string
      result: string
    source:
      openapi: ../openapi.yml
  ToolSource:
    enum:
      - organization
      - inline
    docs: >-
      Source of tool. Used to differentiate between tools and tool versions when
      they are combined in a list.


      V4 uses organization and inline. Those are deprecated and will be removed
      in favour of tool and tool_version.
    source:
      openapi: ../openapi.yml
  ToolTemplateResponse:
    docs: Template for a Humanloop runnable tool.
    properties:
      name:
        type: string
        docs: Name for the tool referenced by the model.
      description:
        type: string
        docs: Description of the tool referenced by the model
      parameters:
        type: optional<map<string, unknown>>
        docs: >-
          Parameters needed to run the Tool, defined in JSON Schema format:
          https://json-schema.org/
      signature:
        type: optional<string>
        docs: Signature of the Tool.
      setup_schema:
        type: optional<map<string, unknown>>
        docs: Schema required to setup the Tool runtime, e.g. API keys.
    source:
      openapi: ../openapi.yml
  UpdateDatesetAction:
    enum:
      - set
      - add
      - remove
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  ValidationErrorLocItem:
    discriminated: false
    union:
      - string
      - integer
    source:
      openapi: ../openapi.yml
    inline: true
  ValidationError:
    properties:
      loc:
        type: list<ValidationErrorLocItem>
      msg: string
      type: string
    source:
      openapi: ../openapi.yml
  File:
    discriminated: false
    docs: The File that the deployed Version belongs to.
    union:
      - type: PromptResponse
      - type: ToolResponse
      - type: DatasetResponse
      - type: EvaluatorResponse
    source:
      openapi: ../openapi.yml
    inline: true
  VersionDeploymentResponse:
    docs: A variable reference to the Version deployed to an Environment
    properties:
      file:
        display-name: File
        type: File
        docs: The File that the deployed Version belongs to.
      environment:
        type: EnvironmentResponse
        docs: The Environment that the Version is deployed to.
    source:
      openapi: ../openapi.yml
  Version:
    discriminated: false
    docs: The specific Version being referenced.
    union:
      - type: PromptResponse
      - type: ToolResponse
      - type: DatasetResponse
      - type: EvaluatorResponse
    source:
      openapi: ../openapi.yml
    inline: true
  VersionIdResponse:
    docs: A reference to a specific Version by its ID
    properties:
      version:
        display-name: Version
        type: Version
        docs: The specific Version being referenced.
    source:
      openapi: ../openapi.yml
  VersionReferenceResponse:
    discriminant: type
    base-properties: {}
    union:
      environment:
        type: VersionDeploymentResponse
      version:
        type: VersionIdResponse
    source:
      openapi: ../openapi.yml
  VersionStatsEvaluatorVersionStatsItem:
    discriminated: false
    union:
      - type: NumericEvaluatorVersionStats
      - type: BooleanEvaluatorVersionStats
    source:
      openapi: ../openapi.yml
    inline: true
  VersionStats:
    docs: Stats for an Evaluated Version in the Evaluation Report.
    properties:
      version_id:
        type: string
        docs: Unique identifier for the Evaluated Version.
      num_logs:
        type: integer
        docs: >-
          The total number of existing Logs for this Evaluated Version within
          the Evaluation Report. These are Logs that have been generated by this
          Evaluated Version on a Datapoint belonging to the Evaluation Report's
          Dataset Version.
      evaluator_version_stats:
        docs: >-
          Stats for each Evaluator Version used to evaluate this Evaluated
          Version.
        type: list<VersionStatsEvaluatorVersionStatsItem>
    source:
      openapi: ../openapi.yml
  VersionStatus:
    enum:
      - uncommitted
      - committed
      - deleted
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  ToolType:
    enum:
      - pinecone_search
      - google
      - mock
      - snippet
      - json_schema
      - get_api_call
    docs: Type of tool.
    source:
      openapi: ../openapi.yml
  ToolResponse:
    docs: Request to create a new Tool.
    properties:
      id:
        type: string
        docs: Unique identifier for Tool.
      name:
        type: string
        docs: Name of the Tool, which is used as a unique identifier.
      version_id:
        type: string
        docs: >-
          Unique identifier for the specific Tool Version. If no query params
          provided, the default deployed Tool Version is returned.
      directory_id:
        type: optional<string>
        docs: 'Unique identifier for the Directory of the Prompt. '
      environments:
        type: optional<list<EnvironmentResponse>>
        docs: The list of environments the Prompt Version is deployed to.
      created_at:
        type: datetime
      updated_at:
        type: datetime
      created_by:
        type: optional<UserResponse>
        docs: The user who created the Prompt.
      status:
        type: VersionStatus
        docs: The status of the Prompt Version.
      last_used_at:
        type: datetime
      function:
        type: optional<ToolFunction>
        docs: >-
          Callable function specification of the Tool shown to the model for
          tool calling.
      source_code:
        type: optional<string>
        docs: Code source of the Tool.
      setup_values:
        type: optional<map<string, unknown>>
        docs: >-
          Values needed to setup the Tool, defined in JSON Schema format:
          https://json-schema.org/
      tool_type:
        type: optional<ToolType>
        docs: Type of Tool.
      commit_message:
        type: optional<string>
        docs: Message describing the changes made.
      signature:
        type: optional<string>
        docs: Signature of the Tool.
      version_logs_count:
        type: integer
        docs: The number of logs that have been generated for this Prompt Version
      total_logs_count:
        type: integer
        docs: The number of logs that have been generated across all Prompt Versions
      inputs:
        docs: >-
          Inputs associated to the Prompt. Inputs correspond to any of the
          variables used within the Prompt template.
        type: list<InputResponse>
    source:
      openapi: ../openapi.yml
  FeedbackType:
    enum:
      - rating
      - action
      - issue
      - correction
      - comment
    docs: An enumeration.
    source:
      openapi: ../openapi.yml
  UserResponse:
    properties:
      id:
        type: string
        docs: Unique identifier for User. Starts with `usr`.
      email_address:
        type: string
        docs: The User's email address.
      full_name:
        type: optional<string>
        docs: The User's full name.
    source:
      openapi: ../openapi.yml
  DatasetRequest:
    properties:
      version_id:
        type: string
        docs: >-
          Unique identifier for the Dataset Version to use in this evaluation.
          Starts with `dsv_`.
    source:
      openapi: ../openapi.yml
  EvaluatorRequest:
    properties:
      version_id:
        type: string
        docs: >-
          Unique identifier for the Evaluator Version to use in this evaluation.
          Starts with `evv_`.
      orchestrated:
        type: optional<boolean>
        docs: >-
          Whether the Evaluator is orchestrated by Humanloop. Default is `True`.
          If `False`, a log for the Evaluator should be submitted by the user
          via the API.
        default: true
    source:
      openapi: ../openapi.yml
",
    },
    "datasets.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "docs": "Datasets are collections of input-output pairs that you can use within Humanloop for Evaluations.

#### What is a Dataset?

A Dataset is a collection of unique Datapoints. These Datapoints contain `inputs` and `target` fields. The `inputs`
are used to populate a Prompt's template and the `target` can be referenced by Evaluators to evaluate the quality of
the generated output.

Note that Humanloop automatically deduplicates Datapoints. If you try to add a Datapoint that already exists, it will
be ignored. If you intentionally want to add a duplicate Datapoint, you can add a unique identifier to the Datapoint's
inputs such as `{_dedupe_id: <unique ID>}`.

#### Creating Dataset versions

Datasets have immutable versions. To add/remove Datapoint to/from an existing version, use the **Create** endpoint
and specify `action` as `"add"` or `"remove"` respectively. You may also specify the `version_id` or `environment`
query parameters to identify the existing version to base the new version on. If neither is provided, the version
deployed to the default Environment will be used.

",
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "display-name": "Datasets",
          "endpoints": {
            "commit": {
              "auth": true,
              "display-name": "Commit",
              "docs": "Commit the Dataset Version with the given ID.",
              "errors": [
                "root.DatasetsCommitRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "request": {
                    "commit_message": "commit_message",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "datapoints_count": 1,
                      "id": "id",
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/datasets/{id}/versions/{version_id}/commit",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Dataset.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Dataset.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "type": "root.CommitRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.DatasetResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "create": {
              "auth": true,
              "display-name": "Create Dataset",
              "docs": "Create a Dataset.

Dataset have immutable versions. When you call this endpoint
with the same Dataset name but different parameters, a new version of
the Dataset will be created.

If you provide a commit message, then the new version will be committed;
otherwise it will be uncommitted. If you try to commit an already committed version,
an exception will be raised.

By default, the new Dataset version will be set to the list of Datapoints provided in
the request.
You can create a new version by adding or removing Datapoints from an existing version
by specifying `action` as `add` or `remove` respectively. In this case, you may specify
the `version_id` or `environment` query parameters to identify the existing version to base
the new version on. If neither is provided, the default deployed version will be used.

Humanloop also deduplicates Datapoints. If you try to add a Datapoint that already
exists, it will be ignored.",
              "errors": [
                "root.DatasetsCreateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "request": {
                    "datapoints": [
                      {},
                    ],
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "datapoints_count": 1,
                      "id": "id",
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/datasets",
              "request": {
                "body": {
                  "properties": {
                    "action": {
                      "docs": "The action to take with the provided Datapoints.

 - If `"set"`, the created version will only contain the Datapoints provided in this request. 
 - If `"add"`, the created version will contain the Datapoints provided in this request in addition to the Datapoints in the target version. 
 - If `"remove"`, the created version will contain the Datapoints in the target version except for the Datapoints provided in this request. 

If `"add"` or `"remove"`, one of the `version_id` or `environment` query parameters may be provided.",
                      "type": "optional<root.UpdateDatesetAction>",
                    },
                    "commit_message": {
                      "docs": "Message describing the changes made. If provided, a committed version of the Dataset is created. Otherwise, an uncommitted version is created.",
                      "type": "optional<string>",
                    },
                    "datapoints": {
                      "docs": "The Datapoints to create this Dataset version with. Modify the `action` field to determine how these Datapoints are used.",
                      "type": "list<root.CreateDatapointRequest>",
                    },
                    "name": {
                      "docs": "Name of the Dataset, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "DatasetRequest",
                "path-parameters": undefined,
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag to identify a deployed Version to base the created Version on. Only used when `action` is `"add"` or `"remove"`.",
                    "type": "optional<string>",
                  },
                  "version_id": {
                    "docs": "ID of the specific Dataset version to base the created Version on. Only used when `action` is `"add"` or `"remove"`.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.DatasetResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "delete": {
              "auth": true,
              "display-name": "Delete Dataset",
              "docs": "Delete the Dataset with the given ID.",
              "errors": [
                "root.DatasetsDeleteRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                },
              ],
              "method": "DELETE",
              "pagination": undefined,
              "path": "/datasets/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Dataset.",
                  "type": "string",
                },
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "deploy": {
              "auth": true,
              "display-name": "Deploy",
              "docs": "Deploy Dataset to Environment.

Set the deployed Version for the specified Environment.",
              "errors": [
                "root.DeployDatasetsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "query-parameters": {
                    "environment_id": "environment_id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "datapoints_count": 1,
                      "id": "id",
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/datasets/{id}/versions/{version_id}/deploy",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Dataset.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Dataset.",
                  "type": "string",
                },
              },
              "request": {
                "name": "DeployDatasetsIdVersionsVersionIdDeployPostRequest",
                "query-parameters": {
                  "environment_id": {
                    "docs": "Unique identifier for the Environment to deploy the Version to.",
                    "type": "string",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.DatasetResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "get": {
              "auth": true,
              "display-name": "Get Dataset",
              "docs": "Retrieve the Dataset with the given ID.

Unless `include_datapoints` is set to `true`, the response will not include
the Datapoints.
Use the List Datapoints endpoint (`GET /{id}/datapoints`) to efficiently
retrieve Datapoints for a large Dataset.

By default the deployed version of the Dataset is returned. Use the query parameters
`version_id` or `environment` to target a specific version of the Dataset.",
              "errors": [
                "root.DatasetsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "datapoints_count": 1,
                      "id": "id",
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/datasets/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Dataset.",
                  "type": "string",
                },
              },
              "request": {
                "name": "DatasetsGetRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag to retrieve a deployed Version from.",
                    "type": "optional<string>",
                  },
                  "include_datapoints": {
                    "docs": "If set to `true`, include all Datapoints in the response. Defaults to `false`. Consider using the paginated List Datapoints endpoint instead.",
                    "type": "optional<boolean>",
                  },
                  "version_id": {
                    "docs": "A specific Version ID of the Dataset to retrieve.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.DatasetResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "list": {
              "auth": true,
              "display-name": "List ",
              "docs": "Get a list of Datasets.",
              "errors": [
                "root.DatasetsListRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "response": {
                    "body": {
                      "page": 1,
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "datapoints_count": 1,
                          "id": "id",
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "name": "name",
                          "status": "uncommitted",
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                        },
                      ],
                      "size": 1,
                      "total": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/datasets",
              "request": {
                "name": "DatasetsListRequest",
                "query-parameters": {
                  "name": {
                    "docs": "Case-insensitive filter for Dataset name.",
                    "type": "optional<string>",
                  },
                  "order": {
                    "docs": "Direction to sort by.",
                    "type": "optional<root.SortOrder>",
                  },
                  "page": {
                    "docs": "Page offset for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Datasets to fetch.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 0,
                      "multipleOf": undefined,
                    },
                  },
                  "sort_by": {
                    "docs": "Field to sort Datasets by",
                    "type": "optional<root.ProjectSortBy>",
                  },
                  "user_filter": {
                    "docs": "Case-insensitive filter for users in the Dataset. This filter matches against both email address and name of users.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PaginatedDataDatasetResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listdatapoints": {
              "auth": true,
              "display-name": "List Datapoints",
              "docs": "List all Datapoints for the Dataset with the given ID.",
              "errors": [
                "root.DatasetsListDatapointsRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "page": 1,
                      "records": [
                        {
                          "id": "id",
                        },
                      ],
                      "size": 1,
                      "total": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/datasets/{id}/datapoints",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Dataset.",
                  "type": "string",
                },
              },
              "request": {
                "name": "DatasetsListDatapointsRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag to retrieve a deployed Version from.",
                    "type": "optional<string>",
                  },
                  "page": {
                    "docs": "Page number for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Datapoints to fetch.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 0,
                      "multipleOf": undefined,
                    },
                  },
                  "version_id": {
                    "docs": "A specific Version ID of the Dataset to retrieve.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PaginatedDataDatapointResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listversions": {
              "auth": true,
              "display-name": "List Versions",
              "docs": "Get a list of the versions for a Dataset.",
              "errors": [
                "root.DatasetsListVersionsRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "datapoints_count": 1,
                          "id": "id",
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "name": "name",
                          "status": "uncommitted",
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/datasets/{id}/versions",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Dataset.",
                  "type": "string",
                },
              },
              "request": {
                "name": "DatasetsListVersionsRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "Filter versions by environment tag. If no environment is provided, all versions are returned.",
                    "type": "optional<string>",
                  },
                  "evaluation_aggregates": "optional<boolean>",
                  "status": {
                    "docs": "Filter versions by status: 'uncommitted', 'committed'. If no status is provided, all versions are returned.",
                    "type": "optional<root.VersionStatus>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ListDatasets",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "update": {
              "auth": true,
              "display-name": "Update Dataset",
              "docs": "Update the Dataset with the given ID.",
              "errors": [
                "root.DatasetsUpdateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "datapoints_count": 1,
                      "id": "id",
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                    },
                  },
                },
              ],
              "method": "PATCH",
              "pagination": undefined,
              "path": "/datasets/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Dataset.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "name": {
                      "docs": "Name of the Dataset, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "UpdateDatasetRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.DatasetResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yml",
          },
        },
      },
      "rawContents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    list:
      path: /datasets
      method: GET
      auth: true
      docs: Get a list of Datasets.
      source:
        openapi: ../openapi.yml
      display-name: 'List '
      request:
        name: DatasetsListRequest
        query-parameters:
          page:
            type: optional<integer>
            docs: Page offset for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Datasets to fetch.
            validation:
              min: 0
          name:
            type: optional<string>
            docs: Case-insensitive filter for Dataset name.
          user_filter:
            type: optional<string>
            docs: >-
              Case-insensitive filter for users in the Dataset. This filter
              matches against both email address and name of users.
          sort_by:
            type: optional<root.ProjectSortBy>
            docs: Field to sort Datasets by
          order:
            type: optional<root.SortOrder>
            docs: Direction to sort by.
      response:
        docs: Successful Response
        type: root.PaginatedDataDatasetResponse
      errors:
        - root.DatasetsListRequestUnprocessableEntityError
      examples:
        - response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  datapoints_count: 1
              page: 1
              size: 1
              total: 1
    create:
      path: /datasets
      method: POST
      auth: true
      docs: >-
        Create a Dataset.


        Dataset have immutable versions. When you call this endpoint

        with the same Dataset name but different parameters, a new version of

        the Dataset will be created.


        If you provide a commit message, then the new version will be committed;

        otherwise it will be uncommitted. If you try to commit an already
        committed version,

        an exception will be raised.


        By default, the new Dataset version will be set to the list of
        Datapoints provided in

        the request.

        You can create a new version by adding or removing Datapoints from an
        existing version

        by specifying `action` as `add` or `remove` respectively. In this case,
        you may specify

        the `version_id` or `environment` query parameters to identify the
        existing version to base

        the new version on. If neither is provided, the default deployed version
        will be used.


        Humanloop also deduplicates Datapoints. If you try to add a Datapoint
        that already

        exists, it will be ignored.
      source:
        openapi: ../openapi.yml
      display-name: Create Dataset
      request:
        name: DatasetRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: >-
              ID of the specific Dataset version to base the created Version on.
              Only used when `action` is `"add"` or `"remove"`.
          environment:
            type: optional<string>
            docs: >-
              An environment tag to identify a deployed Version to base the
              created Version on. Only used when `action` is `"add"` or
              `"remove"`.
        body:
          properties:
            name:
              type: optional<string>
              docs: Name of the Dataset, which is used as a unique identifier.
            commit_message:
              type: optional<string>
              docs: >-
                Message describing the changes made. If provided, a committed
                version of the Dataset is created. Otherwise, an uncommitted
                version is created.
            datapoints:
              docs: >-
                The Datapoints to create this Dataset version with. Modify the
                `action` field to determine how these Datapoints are used.
              type: list<root.CreateDatapointRequest>
            action:
              type: optional<root.UpdateDatesetAction>
              docs: >-
                The action to take with the provided Datapoints.

                 - If `"set"`, the created version will only contain the Datapoints provided in this request. 
                 - If `"add"`, the created version will contain the Datapoints provided in this request in addition to the Datapoints in the target version. 
                 - If `"remove"`, the created version will contain the Datapoints in the target version except for the Datapoints provided in this request. 

                If `"add"` or `"remove"`, one of the `version_id` or
                `environment` query parameters may be provided.
        content-type: application/json
      response:
        docs: Successful Response
        type: root.DatasetResponse
      errors:
        - root.DatasetsCreateRequestUnprocessableEntityError
      examples:
        - request:
            datapoints:
              - {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              datapoints_count: 1
    get:
      path: /datasets/{id}
      method: GET
      auth: true
      docs: >-
        Retrieve the Dataset with the given ID.


        Unless `include_datapoints` is set to `true`, the response will not
        include

        the Datapoints.

        Use the List Datapoints endpoint (`GET /{id}/datapoints`) to efficiently

        retrieve Datapoints for a large Dataset.


        By default the deployed version of the Dataset is returned. Use the
        query parameters

        `version_id` or `environment` to target a specific version of the
        Dataset.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Dataset.
      display-name: Get Dataset
      request:
        name: DatasetsGetRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific Version ID of the Dataset to retrieve.
          environment:
            type: optional<string>
            docs: An environment tag to retrieve a deployed Version from.
          include_datapoints:
            type: optional<boolean>
            docs: >-
              If set to `true`, include all Datapoints in the response. Defaults
              to `false`. Consider using the paginated List Datapoints endpoint
              instead.
      response:
        docs: Successful Response
        type: root.DatasetResponse
      errors:
        - root.DatasetsGetRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              datapoints_count: 1
    delete:
      path: /datasets/{id}
      method: DELETE
      auth: true
      docs: Delete the Dataset with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Dataset.
      display-name: Delete Dataset
      errors:
        - root.DatasetsDeleteRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
    update:
      path: /datasets/{id}
      method: PATCH
      auth: true
      docs: Update the Dataset with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Dataset.
      display-name: Update Dataset
      request:
        name: UpdateDatasetRequest
        body:
          properties:
            name:
              type: optional<string>
              docs: Name of the Dataset, which is used as a unique identifier.
        content-type: application/json
      response:
        docs: Successful Response
        type: root.DatasetResponse
      errors:
        - root.DatasetsUpdateRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              datapoints_count: 1
    listdatapoints:
      path: /datasets/{id}/datapoints
      method: GET
      auth: true
      docs: List all Datapoints for the Dataset with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Dataset.
      display-name: List Datapoints
      request:
        name: DatasetsListDatapointsRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific Version ID of the Dataset to retrieve.
          environment:
            type: optional<string>
            docs: An environment tag to retrieve a deployed Version from.
          page:
            type: optional<integer>
            docs: Page number for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Datapoints to fetch.
            validation:
              min: 0
      response:
        docs: Successful Response
        type: root.PaginatedDataDatapointResponse
      errors:
        - root.DatasetsListDatapointsRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              records:
                - id: id
              page: 1
              size: 1
              total: 1
    listversions:
      path: /datasets/{id}/versions
      method: GET
      auth: true
      docs: Get a list of the versions for a Dataset.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Dataset.
      display-name: List Versions
      request:
        name: DatasetsListVersionsRequest
        query-parameters:
          status:
            type: optional<root.VersionStatus>
            docs: >-
              Filter versions by status: 'uncommitted', 'committed'. If no
              status is provided, all versions are returned.
          environment:
            type: optional<string>
            docs: >-
              Filter versions by environment tag. If no environment is provided,
              all versions are returned.
          evaluation_aggregates: optional<boolean>
      response:
        docs: Successful Response
        type: root.ListDatasets
      errors:
        - root.DatasetsListVersionsRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  datapoints_count: 1
    commit:
      path: /datasets/{id}/versions/{version_id}/commit
      method: POST
      auth: true
      docs: Commit the Dataset Version with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Dataset.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Dataset.
      display-name: Commit
      request:
        body:
          type: root.CommitRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.DatasetResponse
      errors:
        - root.DatasetsCommitRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          request:
            commit_message: commit_message
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              datapoints_count: 1
    deploy:
      path: /datasets/{id}/versions/{version_id}/deploy
      method: POST
      auth: true
      docs: |-
        Deploy Dataset to Environment.

        Set the deployed Version for the specified Environment.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Dataset.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Dataset.
      display-name: Deploy
      request:
        name: DeployDatasetsIdVersionsVersionIdDeployPostRequest
        query-parameters:
          environment_id:
            type: string
            docs: Unique identifier for the Environment to deploy the Version to.
      response:
        docs: Successful Response
        type: root.DatasetResponse
      errors:
        - >-
          root.DeployDatasetsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          query-parameters:
            environment_id: environment_id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              datapoints_count: 1
  source:
    openapi: ../openapi.yml
  display-name: Datasets
docs: >+
  Datasets are collections of input-output pairs that you can use within
  Humanloop for Evaluations.


  #### What is a Dataset?


  A Dataset is a collection of unique Datapoints. These Datapoints contain
  `inputs` and `target` fields. The `inputs`

  are used to populate a Prompt's template and the `target` can be referenced by
  Evaluators to evaluate the quality of

  the generated output.


  Note that Humanloop automatically deduplicates Datapoints. If you try to add a
  Datapoint that already exists, it will

  be ignored. If you intentionally want to add a duplicate Datapoint, you can
  add a unique identifier to the Datapoint's

  inputs such as `{_dedupe_id: <unique ID>}`.


  #### Creating Dataset versions


  Datasets have immutable versions. To add/remove Datapoint to/from an existing
  version, use the **Create** endpoint

  and specify `action` as `"add"` or `"remove"` respectively. You may also
  specify the `version_id` or `environment`

  query parameters to identify the existing version to base the new version on.
  If neither is provided, the version

  deployed to the default Environment will be used.

",
    },
    "evaluations.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "docs": "Evaluations help you measure the performance of your Prompts, Tools and LLM Evaluators.

An Evaluation consists of a Dataset, Evaluatees (i.e. Versions to evaluate), and Evaluators.
When an Evaluation is created, Humanloop will start generating Logs, iterating through Datapoints in the Dataset,
for each Evaluatee. The Evaluators will then be run on these Logs.

Aggregate stats can be viewed in the Humanloop app or retrieved with the **Get Evaluation Stats** endpoint.

Note that when an Evaluation is created, Humanloop will attempt to reuse any existing Logs for each Datapoint-Evaluatee
pair. This means that you can create multiple Evaluations without generating new Logs unnecessarily.

",
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "display-name": "Evaluations",
          "endpoints": {
            "create": {
              "auth": true,
              "display-name": "Create Evaluation",
              "docs": "Create an Evaluation.

Create a new Evaluation by specifying the Dataset, Evaluatees, and Evaluators.
Humanloop will automatically start generating Logs and running Evaluators.

To keep updated on the progress of the Evaluation, you can poll the Evaluation
and check its status.",
              "errors": [
                "root.EvaluationsCreateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "request": {
                    "dataset": {
                      "version_id": "version_id",
                    },
                    "evaluatees": [
                      {
                        "version_id": "version_id",
                      },
                    ],
                    "evaluators": [
                      {
                        "version_id": "version_id",
                      },
                    ],
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "dataset": {
                        "created_at": "2024-01-15T09:30:00Z",
                        "datapoints_count": 1,
                        "id": "id",
                        "last_used_at": "2024-01-15T09:30:00Z",
                        "name": "name",
                        "status": "uncommitted",
                        "updated_at": "2024-01-15T09:30:00Z",
                        "version_id": "version_id",
                      },
                      "evaluatees": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "model": "model",
                            "name": "name",
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "evaluators": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "name": "name",
                            "spec": {
                              "arguments_type": "target_free",
                              "evaluator_type": "human",
                              "return_type": "boolean",
                            },
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "id": "id",
                      "status": "pending",
                      "updated_at": "2024-01-15T09:30:00Z",
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/evaluations",
              "request": {
                "body": {
                  "type": "root.CreateEvaluationRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluationResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "delete": {
              "auth": true,
              "display-name": "Delete Evaluation",
              "docs": "Delete an Evaluation.

Remove an Evaluation from Humanloop. The Logs and Versions used in the Evaluation
will not be deleted.",
              "errors": [
                "root.EvaluationsDeleteRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                },
              ],
              "method": "DELETE",
              "pagination": undefined,
              "path": "/evaluations/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluation.",
                  "type": "string",
                },
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "get": {
              "auth": true,
              "display-name": "Get Evaluation",
              "docs": "Get an Evaluation.

Retrieve the Evaluation with the given ID.",
              "errors": [
                "root.EvaluationsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "dataset": {
                        "created_at": "2024-01-15T09:30:00Z",
                        "datapoints_count": 1,
                        "id": "id",
                        "last_used_at": "2024-01-15T09:30:00Z",
                        "name": "name",
                        "status": "uncommitted",
                        "updated_at": "2024-01-15T09:30:00Z",
                        "version_id": "version_id",
                      },
                      "evaluatees": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "model": "model",
                            "name": "name",
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "evaluators": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "name": "name",
                            "spec": {
                              "arguments_type": "target_free",
                              "evaluator_type": "human",
                              "return_type": "boolean",
                            },
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "id": "id",
                      "status": "pending",
                      "updated_at": "2024-01-15T09:30:00Z",
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/evaluations/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluation.",
                  "type": "string",
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluationResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "getstats": {
              "auth": true,
              "display-name": "Get Evaluation Stats",
              "docs": "Get Evaluation Stats.

Retrieve aggregate stats for the specified Evaluation.
This includes the number of generated Logs for every evaluatee and Evaluator metrics
(such as the mean and percentiles for numeric Evaluators for every evaluatee).",
              "errors": [
                "root.EvaluationsGetStatsRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "overall_stats": {
                        "num_datapoints": 1,
                        "total_evaluator_logs": 1,
                        "total_logs": 1,
                      },
                      "version_stats": [
                        {
                          "evaluator_version_stats": [
                            {
                              "evaluator_version_id": "evaluator_version_id",
                              "mean": 0,
                              "num_errors": 1,
                              "num_judgments": 1,
                              "num_nulls": 1,
                              "percentiles": {
                                "0": -2.5,
                                "100": 2.5,
                                "25": -0.6745,
                                "50": 0,
                                "75": 0.6745,
                              },
                              "std": 1,
                              "total_logs": 1,
                            },
                          ],
                          "num_logs": 1,
                          "version_id": "version_id",
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/evaluations/{id}/stats",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluation.",
                  "type": "string",
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluationStats",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "list": {
              "auth": true,
              "display-name": "List Evaluations for File",
              "docs": "List Evaluations for the given File.

Retrieve a list of Evaluations that evaluate versions of the specified File.",
              "errors": [
                "root.EvaluationsListRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "query-parameters": {
                    "file_id": "file_id",
                  },
                  "response": {
                    "body": {
                      "page": 1,
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "dataset": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "datapoints_count": 1,
                            "id": "id",
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "name": "name",
                            "status": "uncommitted",
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                          },
                          "evaluatees": [
                            {
                              "orchestrated": true,
                              "version": {
                                "created_at": "2024-01-15T09:30:00Z",
                                "id": "id",
                                "inputs": [
                                  {
                                    "name": "name",
                                  },
                                ],
                                "last_used_at": "2024-01-15T09:30:00Z",
                                "model": "model",
                                "name": "name",
                                "status": "uncommitted",
                                "total_logs_count": 1,
                                "updated_at": "2024-01-15T09:30:00Z",
                                "version_id": "version_id",
                                "version_logs_count": 1,
                              },
                            },
                          ],
                          "evaluators": [
                            {
                              "orchestrated": true,
                              "version": {
                                "created_at": "2024-01-15T09:30:00Z",
                                "id": "id",
                                "inputs": [
                                  {
                                    "name": "name",
                                  },
                                ],
                                "last_used_at": "2024-01-15T09:30:00Z",
                                "name": "name",
                                "spec": {
                                  "arguments_type": "target_free",
                                  "evaluator_type": "human",
                                  "return_type": "boolean",
                                },
                                "status": "uncommitted",
                                "total_logs_count": 1,
                                "updated_at": "2024-01-15T09:30:00Z",
                                "version_id": "version_id",
                                "version_logs_count": 1,
                              },
                            },
                          ],
                          "id": "id",
                          "status": "pending",
                          "updated_at": "2024-01-15T09:30:00Z",
                        },
                      ],
                      "size": 1,
                      "total": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/evaluations",
              "request": {
                "name": "EvaluationsListRequest",
                "query-parameters": {
                  "file_id": {
                    "docs": "Filter by File ID. If provided, only Evaluation for the specified File will be returned.",
                    "type": "string",
                  },
                  "page": {
                    "docs": "Page number for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Evaluations to fetch.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 0,
                      "multipleOf": undefined,
                    },
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PaginatedDataEvaluationResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "update": {
              "auth": true,
              "display-name": "Update Evaluation",
              "docs": "Update an Evaluation.

Update the setup of an Evaluation by specifying the Dataset, Evaluatees, and Evaluators.",
              "errors": [
                "root.EvaluationsUpdateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {
                    "dataset": {
                      "version_id": "version_id",
                    },
                    "evaluatees": [
                      {
                        "version_id": "version_id",
                      },
                    ],
                    "evaluators": [
                      {
                        "version_id": "version_id",
                      },
                    ],
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "dataset": {
                        "created_at": "2024-01-15T09:30:00Z",
                        "datapoints_count": 1,
                        "id": "id",
                        "last_used_at": "2024-01-15T09:30:00Z",
                        "name": "name",
                        "status": "uncommitted",
                        "updated_at": "2024-01-15T09:30:00Z",
                        "version_id": "version_id",
                      },
                      "evaluatees": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "model": "model",
                            "name": "name",
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "evaluators": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "name": "name",
                            "spec": {
                              "arguments_type": "target_free",
                              "evaluator_type": "human",
                              "return_type": "boolean",
                            },
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "id": "id",
                      "status": "pending",
                      "updated_at": "2024-01-15T09:30:00Z",
                    },
                  },
                },
              ],
              "method": "PATCH",
              "pagination": undefined,
              "path": "/evaluations/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluation.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "type": "root.CreateEvaluationRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluationResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "updatestatus": {
              "auth": true,
              "display-name": "Update Status",
              "docs": "Update the status of an Evaluation.

Can be used to cancel a running Evaluation, or mark an Evaluation that uses external or human evaluators
as completed.",
              "errors": [
                "root.EvaluationsUpdateStatusRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {
                    "status": "pending",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "dataset": {
                        "created_at": "2024-01-15T09:30:00Z",
                        "datapoints_count": 1,
                        "id": "id",
                        "last_used_at": "2024-01-15T09:30:00Z",
                        "name": "name",
                        "status": "uncommitted",
                        "updated_at": "2024-01-15T09:30:00Z",
                        "version_id": "version_id",
                      },
                      "evaluatees": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "model": "model",
                            "name": "name",
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "evaluators": [
                        {
                          "orchestrated": true,
                          "version": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "name": "name",
                            "spec": {
                              "arguments_type": "target_free",
                              "evaluator_type": "human",
                              "return_type": "boolean",
                            },
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "id": "id",
                      "status": "pending",
                      "updated_at": "2024-01-15T09:30:00Z",
                    },
                  },
                },
              ],
              "method": "PATCH",
              "pagination": undefined,
              "path": "/evaluations/{id}/status",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluation.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "status": {
                      "type": "root.EvaluationStatus",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "BodyEvaluationsUpdateStatus",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluationResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yml",
          },
        },
      },
      "rawContents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    list:
      path: /evaluations
      method: GET
      auth: true
      docs: >-
        List Evaluations for the given File.


        Retrieve a list of Evaluations that evaluate versions of the specified
        File.
      source:
        openapi: ../openapi.yml
      display-name: List Evaluations for File
      request:
        name: EvaluationsListRequest
        query-parameters:
          file_id:
            type: string
            docs: >-
              Filter by File ID. If provided, only Evaluation for the specified
              File will be returned.
          page:
            type: optional<integer>
            docs: Page number for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Evaluations to fetch.
            validation:
              min: 0
      response:
        docs: Successful Response
        type: root.PaginatedDataEvaluationResponse
      errors:
        - root.EvaluationsListRequestUnprocessableEntityError
      examples:
        - query-parameters:
            file_id: file_id
          response:
            body:
              records:
                - id: id
                  dataset:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    datapoints_count: 1
                  evaluatees:
                    - version:
                        id: id
                        name: name
                        version_id: version_id
                        created_at: '2024-01-15T09:30:00Z'
                        updated_at: '2024-01-15T09:30:00Z'
                        status: uncommitted
                        last_used_at: '2024-01-15T09:30:00Z'
                        model: model
                        version_logs_count: 1
                        total_logs_count: 1
                        inputs:
                          - name: name
                      orchestrated: true
                  evaluators:
                    - version:
                        id: id
                        name: name
                        version_id: version_id
                        created_at: '2024-01-15T09:30:00Z'
                        updated_at: '2024-01-15T09:30:00Z'
                        status: uncommitted
                        last_used_at: '2024-01-15T09:30:00Z'
                        spec:
                          evaluator_type: human
                          arguments_type: target_free
                          return_type: boolean
                        version_logs_count: 1
                        total_logs_count: 1
                        inputs:
                          - name: name
                      orchestrated: true
                  status: pending
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
              page: 1
              size: 1
              total: 1
    create:
      path: /evaluations
      method: POST
      auth: true
      docs: >-
        Create an Evaluation.


        Create a new Evaluation by specifying the Dataset, Evaluatees, and
        Evaluators.

        Humanloop will automatically start generating Logs and running
        Evaluators.


        To keep updated on the progress of the Evaluation, you can poll the
        Evaluation

        and check its status.
      source:
        openapi: ../openapi.yml
      display-name: Create Evaluation
      request:
        body:
          type: root.CreateEvaluationRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.EvaluationResponse
      errors:
        - root.EvaluationsCreateRequestUnprocessableEntityError
      examples:
        - request:
            dataset:
              version_id: version_id
            evaluatees:
              - version_id: version_id
            evaluators:
              - version_id: version_id
          response:
            body:
              id: id
              dataset:
                id: id
                name: name
                version_id: version_id
                created_at: '2024-01-15T09:30:00Z'
                updated_at: '2024-01-15T09:30:00Z'
                status: uncommitted
                last_used_at: '2024-01-15T09:30:00Z'
                datapoints_count: 1
              evaluatees:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    model: model
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              evaluators:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    spec:
                      evaluator_type: human
                      arguments_type: target_free
                      return_type: boolean
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              status: pending
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
    get:
      path: /evaluations/{id}
      method: GET
      auth: true
      docs: |-
        Get an Evaluation.

        Retrieve the Evaluation with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluation.
      display-name: Get Evaluation
      response:
        docs: Successful Response
        type: root.EvaluationResponse
      errors:
        - root.EvaluationsGetRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              id: id
              dataset:
                id: id
                name: name
                version_id: version_id
                created_at: '2024-01-15T09:30:00Z'
                updated_at: '2024-01-15T09:30:00Z'
                status: uncommitted
                last_used_at: '2024-01-15T09:30:00Z'
                datapoints_count: 1
              evaluatees:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    model: model
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              evaluators:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    spec:
                      evaluator_type: human
                      arguments_type: target_free
                      return_type: boolean
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              status: pending
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
    delete:
      path: /evaluations/{id}
      method: DELETE
      auth: true
      docs: >-
        Delete an Evaluation.


        Remove an Evaluation from Humanloop. The Logs and Versions used in the
        Evaluation

        will not be deleted.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluation.
      display-name: Delete Evaluation
      errors:
        - root.EvaluationsDeleteRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
    update:
      path: /evaluations/{id}
      method: PATCH
      auth: true
      docs: >-
        Update an Evaluation.


        Update the setup of an Evaluation by specifying the Dataset, Evaluatees,
        and Evaluators.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluation.
      display-name: Update Evaluation
      request:
        body:
          type: root.CreateEvaluationRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.EvaluationResponse
      errors:
        - root.EvaluationsUpdateRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request:
            dataset:
              version_id: version_id
            evaluatees:
              - version_id: version_id
            evaluators:
              - version_id: version_id
          response:
            body:
              id: id
              dataset:
                id: id
                name: name
                version_id: version_id
                created_at: '2024-01-15T09:30:00Z'
                updated_at: '2024-01-15T09:30:00Z'
                status: uncommitted
                last_used_at: '2024-01-15T09:30:00Z'
                datapoints_count: 1
              evaluatees:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    model: model
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              evaluators:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    spec:
                      evaluator_type: human
                      arguments_type: target_free
                      return_type: boolean
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              status: pending
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
    updatestatus:
      path: /evaluations/{id}/status
      method: PATCH
      auth: true
      docs: >-
        Update the status of an Evaluation.


        Can be used to cancel a running Evaluation, or mark an Evaluation that
        uses external or human evaluators

        as completed.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluation.
      display-name: Update Status
      request:
        name: BodyEvaluationsUpdateStatus
        body:
          properties:
            status:
              type: root.EvaluationStatus
        content-type: application/json
      response:
        docs: Successful Response
        type: root.EvaluationResponse
      errors:
        - root.EvaluationsUpdateStatusRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request:
            status: pending
          response:
            body:
              id: id
              dataset:
                id: id
                name: name
                version_id: version_id
                created_at: '2024-01-15T09:30:00Z'
                updated_at: '2024-01-15T09:30:00Z'
                status: uncommitted
                last_used_at: '2024-01-15T09:30:00Z'
                datapoints_count: 1
              evaluatees:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    model: model
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              evaluators:
                - version:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    spec:
                      evaluator_type: human
                      arguments_type: target_free
                      return_type: boolean
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  orchestrated: true
              status: pending
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
    getstats:
      path: /evaluations/{id}/stats
      method: GET
      auth: true
      docs: >-
        Get Evaluation Stats.


        Retrieve aggregate stats for the specified Evaluation.

        This includes the number of generated Logs for every evaluatee and
        Evaluator metrics

        (such as the mean and percentiles for numeric Evaluators for every
        evaluatee).
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluation.
      display-name: Get Evaluation Stats
      response:
        docs: Successful Response
        type: root.EvaluationStats
      errors:
        - root.EvaluationsGetStatsRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              overall_stats:
                num_datapoints: 1
                total_logs: 1
                total_evaluator_logs: 1
              version_stats:
                - version_id: version_id
                  num_logs: 1
                  evaluator_version_stats:
                    - evaluator_version_id: evaluator_version_id
                      total_logs: 1
                      num_judgments: 1
                      num_nulls: 1
                      num_errors: 1
                      mean: 0
                      std: 1
                      percentiles:
                        '0': -2.5
                        '25': -0.6745
                        '50': 0
                        '75': 0.6745
                        '100': 2.5
  source:
    openapi: ../openapi.yml
  display-name: Evaluations
docs: >+
  Evaluations help you measure the performance of your Prompts, Tools and LLM
  Evaluators.


  An Evaluation consists of a Dataset, Evaluatees (i.e. Versions to evaluate),
  and Evaluators.

  When an Evaluation is created, Humanloop will start generating Logs, iterating
  through Datapoints in the Dataset,

  for each Evaluatee. The Evaluators will then be run on these Logs.


  Aggregate stats can be viewed in the Humanloop app or retrieved with the **Get
  Evaluation Stats** endpoint.


  Note that when an Evaluation is created, Humanloop will attempt to reuse any
  existing Logs for each Datapoint-Evaluatee

  pair. This means that you can create multiple Evaluations without generating
  new Logs unnecessarily.

",
    },
    "evaluators.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "endpoints": {
            "commit": {
              "auth": true,
              "display-name": "Commit",
              "docs": "Commit the Evaluator Version with the given ID.",
              "errors": [
                "root.EvaluatorsCommitRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "request": {
                    "commit_message": "commit_message",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "spec": {
                        "arguments_type": "target_free",
                        "evaluator_type": "human",
                        "return_type": "boolean",
                      },
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/evaluators/{id}/versions/{version_id}/commit",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Evaluator.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "type": "root.CommitRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluatorResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "create": {
              "auth": true,
              "display-name": "Create Evaluator",
              "docs": "Create an Evaluator.

Evaluators have immutable versions. When you call this endpoint
with the same Evaluator name but different spec, a new version of
the Evaluator will be created.

If you provide a commit message, then the new version will be committed;
otherwise it will be uncommitted. If you try to commit an already committed version,
an exception will be raised.",
              "errors": [
                "root.EvaluatorsCreateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "request": {
                    "spec": {
                      "arguments_type": "target_free",
                      "evaluator_type": "human",
                      "return_type": "boolean",
                    },
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "spec": {
                        "arguments_type": "target_free",
                        "evaluator_type": "human",
                        "return_type": "boolean",
                      },
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/evaluators",
              "request": {
                "body": {
                  "properties": {
                    "commit_message": {
                      "docs": "Message describing the changes made.",
                      "type": "optional<string>",
                    },
                    "directory_id": {
                      "docs": "Unique identifier for the Directory of the Evaluator.",
                      "type": "optional<string>",
                    },
                    "name": {
                      "docs": "Name of the Evaluator, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                    "spec": {
                      "display-name": "Spec",
                      "type": "Spec",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "EvaluatorRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluatorResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "debug": {
              "auth": true,
              "display-name": "Debug",
              "docs": "Run a synchronous evaluator execution on a collection of datapoints.",
              "errors": [
                "root.DebugEvaluatorsDebugPostRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "request": {
                    "evaluator": {
                      "arguments_type": "target_free",
                      "evaluator_type": "human",
                      "return_type": "boolean",
                    },
                    "file_id": "file_id",
                  },
                  "response": {
                    "body": [
                      {
                        "log": {
                          "config": {
                            "id": "config",
                            "name": "config",
                            "status": "config",
                            "type": "generic",
                          },
                          "evaluation_results": [
                            {
                              "created_at": "2024-01-15T09:30:00Z",
                              "evaluator_id": "evaluator_id",
                              "evaluator_version_id": "evaluator_version_id",
                              "id": "id",
                              "log_id": "log_id",
                              "updated_at": "2024-01-15T09:30:00Z",
                            },
                          ],
                          "id": "id",
                          "observability_status": "pending",
                          "updated_at": "2024-01-15T09:30:00Z",
                        },
                        "log_id": "log_id",
                      },
                    ],
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/evaluators/debug",
              "request": {
                "body": {
                  "properties": {
                    "datapoint_ids": {
                      "docs": "The IDs of the evaluation datapoints on which to run the draft evaluator. ",
                      "type": "optional<list<string>>",
                    },
                    "evaluator": {
                      "display-name": "Evaluator",
                      "type": "Evaluator",
                    },
                    "evaluator_version_id": {
                      "docs": "The ID of the Evaluator Version being debugged if it already exists and is being edited.",
                      "type": "optional<string>",
                    },
                    "file_id": {
                      "docs": "The ID of the Dataset that the datapoints belong to.",
                      "type": "string",
                    },
                    "log_ids": {
                      "docs": "The IDs of the logs on which to run the draft evaluator.Provide one of `log_ids` or `datapoint_ids`.",
                      "type": "optional<list<string>>",
                    },
                    "prompt_version_id": {
                      "docs": "The ID of the Prompt Version to use generate datapoints for the evaluation datapoints. Only required if `datapoint` is provided; has no effect otherwise.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "RunSyncEvaluationRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "list<root.EvaluationDebugResultResponse>",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "delete": {
              "auth": true,
              "display-name": "Delete Evaluator",
              "docs": "Delete the Evaluator with the given ID.",
              "errors": [
                "root.EvaluatorsDeleteRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                },
              ],
              "method": "DELETE",
              "pagination": undefined,
              "path": "/evaluators/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluator.",
                  "type": "string",
                },
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "deploy": {
              "auth": true,
              "display-name": "Deploy",
              "docs": "Deploy Evaluator to Environment.

Set the deployed Version for the specified Environment. This Evaluator Version
will be used for calls made to the Evaluator in this Environment.",
              "errors": [
                "root.DeployEvaluatorsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "query-parameters": {
                    "environment_id": "environment_id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "spec": {
                        "arguments_type": "target_free",
                        "evaluator_type": "human",
                        "return_type": "boolean",
                      },
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/evaluators/{id}/versions/{version_id}/deploy",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluator.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Evaluator.",
                  "type": "string",
                },
              },
              "request": {
                "name": "DeployEvaluatorsIdVersionsVersionIdDeployPostRequest",
                "query-parameters": {
                  "environment_id": {
                    "docs": "Unique identifier for the Environment to deploy the Version to.",
                    "type": "string",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluatorResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "get": {
              "auth": true,
              "display-name": "Get Evaluator",
              "docs": "Retrieve the Evaluator with the given ID.

By default the deployed version of the Evaluator is returned. Use the query parameters
`version_id` or `environment` to target a specific version of the Evaluator.",
              "errors": [
                "root.EvaluatorsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "spec": {
                        "arguments_type": "target_free",
                        "evaluator_type": "human",
                        "return_type": "boolean",
                      },
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/evaluators/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluator.",
                  "type": "string",
                },
              },
              "request": {
                "name": "EvaluatorsGetRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag to retrieve a deployed Version from.",
                    "type": "optional<string>",
                  },
                  "version_id": {
                    "docs": "A specific Version Id  of the Evaluator to retrieve.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluatorResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "list": {
              "auth": true,
              "display-name": "List ",
              "docs": "Get a list of Evaluators.",
              "errors": [
                "root.EvaluatorsListRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "response": {
                    "body": {
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "id": "id",
                          "inputs": [
                            {
                              "name": "name",
                            },
                          ],
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "name": "name",
                          "spec": {
                            "arguments_type": "target_free",
                            "evaluator_type": "human",
                            "return_type": "boolean",
                          },
                          "status": "uncommitted",
                          "total_logs_count": 1,
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                          "version_logs_count": 1,
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/evaluators",
              "request": {
                "name": "EvaluatorsListRequest",
                "query-parameters": {
                  "name": {
                    "docs": "Case-insensitive filter for Evaluator name.",
                    "type": "optional<string>",
                  },
                  "order": {
                    "docs": "Direction to sort by.",
                    "type": "optional<root.SortOrder>",
                  },
                  "page": {
                    "docs": "Page offset for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Evaluators to fetch.",
                    "type": "optional<integer>",
                  },
                  "sort_by": {
                    "docs": "Field to sort Evaluators by",
                    "type": "optional<root.ProjectSortBy>",
                  },
                  "user_filter": {
                    "docs": "Case-insensitive filter for users in the Evaluator. This filter matches against both email address and name of users.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ListEvaluators",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listdefault": {
              "auth": true,
              "display-name": "List Default Evaluators",
              "docs": "Get a list of default evaluators for the organization.",
              "errors": [
                "root.EvaluatorsListDefaultRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "response": {
                    "body": [
                      {
                        "created_at": "2024-01-15T09:30:00Z",
                        "id": "id",
                        "inputs": [
                          {
                            "name": "name",
                          },
                        ],
                        "last_used_at": "2024-01-15T09:30:00Z",
                        "name": "name",
                        "spec": {
                          "arguments_type": "target_free",
                          "evaluator_type": "human",
                          "return_type": "boolean",
                        },
                        "status": "uncommitted",
                        "total_logs_count": 1,
                        "updated_at": "2024-01-15T09:30:00Z",
                        "version_id": "version_id",
                        "version_logs_count": 1,
                      },
                    ],
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/evaluators/default",
              "response": {
                "docs": "Successful Response",
                "type": "list<root.EvaluatorResponse>",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listversions": {
              "auth": true,
              "display-name": "List Versions",
              "docs": "Get a list of all the versions of an Evaluator.",
              "errors": [
                "root.EvaluatorsListVersionsRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "id": "id",
                          "inputs": [
                            {
                              "name": "name",
                            },
                          ],
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "name": "name",
                          "spec": {
                            "arguments_type": "target_free",
                            "evaluator_type": "human",
                            "return_type": "boolean",
                          },
                          "status": "uncommitted",
                          "total_logs_count": 1,
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                          "version_logs_count": 1,
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/evaluators/{id}/versions",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for the Evaluator.",
                  "type": "string",
                },
              },
              "request": {
                "name": "EvaluatorsListVersionsRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "Filter versions by environment tag. If no environment is provided, all versions are returned.",
                    "type": "optional<string>",
                  },
                  "evaluation_aggregates": "optional<boolean>",
                  "status": {
                    "docs": "Filter versions by status: 'uncommitted', 'committed'. If no status is provided, all versions are returned.",
                    "type": "optional<root.VersionStatus>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ListEvaluators",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "update": {
              "auth": true,
              "display-name": "Update Evaluator",
              "docs": "Update the Evaluator with the given ID.",
              "errors": [
                "root.EvaluatorsUpdateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "spec": {
                        "arguments_type": "target_free",
                        "evaluator_type": "human",
                        "return_type": "boolean",
                      },
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "PATCH",
              "pagination": undefined,
              "path": "/evaluators/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Evaluator.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "directory_id": {
                      "docs": "Unique identifier for the Directory of the Evaluator.",
                      "type": "optional<string>",
                    },
                    "name": {
                      "docs": "Name of the Evaluator, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "UpdateEvaluatorRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.EvaluatorResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yml",
          },
        },
        "types": {
          "Evaluator": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "evaluator_type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": {
              "human": {
                "type": "root.HumanEvaluatorRequest",
              },
              "llm": {
                "type": "root.LLMEvaluatorRequest",
              },
              "python": {
                "type": "root.CodeEvaluatorRequest",
              },
            },
          },
          "Spec": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "evaluator_type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": {
              "human": {
                "type": "root.HumanEvaluatorRequest",
              },
              "llm": {
                "type": "root.LLMEvaluatorRequest",
              },
              "python": {
                "type": "root.CodeEvaluatorRequest",
              },
            },
          },
        },
      },
      "rawContents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    list:
      path: /evaluators
      method: GET
      auth: true
      docs: Get a list of Evaluators.
      source:
        openapi: ../openapi.yml
      display-name: 'List '
      request:
        name: EvaluatorsListRequest
        query-parameters:
          page:
            type: optional<integer>
            docs: Page offset for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Evaluators to fetch.
          name:
            type: optional<string>
            docs: Case-insensitive filter for Evaluator name.
          user_filter:
            type: optional<string>
            docs: >-
              Case-insensitive filter for users in the Evaluator. This filter
              matches against both email address and name of users.
          sort_by:
            type: optional<root.ProjectSortBy>
            docs: Field to sort Evaluators by
          order:
            type: optional<root.SortOrder>
            docs: Direction to sort by.
      response:
        docs: Successful Response
        type: root.ListEvaluators
      errors:
        - root.EvaluatorsListRequestUnprocessableEntityError
      examples:
        - response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  spec:
                    evaluator_type: human
                    arguments_type: target_free
                    return_type: boolean
                  version_logs_count: 1
                  total_logs_count: 1
                  inputs:
                    - name: name
    create:
      path: /evaluators
      method: POST
      auth: true
      docs: >-
        Create an Evaluator.


        Evaluators have immutable versions. When you call this endpoint

        with the same Evaluator name but different spec, a new version of

        the Evaluator will be created.


        If you provide a commit message, then the new version will be committed;

        otherwise it will be uncommitted. If you try to commit an already
        committed version,

        an exception will be raised.
      source:
        openapi: ../openapi.yml
      display-name: Create Evaluator
      request:
        name: EvaluatorRequest
        body:
          properties:
            name:
              type: optional<string>
              docs: Name of the Evaluator, which is used as a unique identifier.
            directory_id:
              type: optional<string>
              docs: Unique identifier for the Directory of the Evaluator.
            commit_message:
              type: optional<string>
              docs: Message describing the changes made.
            spec:
              display-name: Spec
              type: Spec
        content-type: application/json
      response:
        docs: Successful Response
        type: root.EvaluatorResponse
      errors:
        - root.EvaluatorsCreateRequestUnprocessableEntityError
      examples:
        - request:
            spec:
              evaluator_type: human
              arguments_type: target_free
              return_type: boolean
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              spec:
                evaluator_type: human
                arguments_type: target_free
                return_type: boolean
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    get:
      path: /evaluators/{id}
      method: GET
      auth: true
      docs: >-
        Retrieve the Evaluator with the given ID.


        By default the deployed version of the Evaluator is returned. Use the
        query parameters

        `version_id` or `environment` to target a specific version of the
        Evaluator.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluator.
      display-name: Get Evaluator
      request:
        name: EvaluatorsGetRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific Version Id  of the Evaluator to retrieve.
          environment:
            type: optional<string>
            docs: An environment tag to retrieve a deployed Version from.
      response:
        docs: Successful Response
        type: root.EvaluatorResponse
      errors:
        - root.EvaluatorsGetRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              spec:
                evaluator_type: human
                arguments_type: target_free
                return_type: boolean
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    delete:
      path: /evaluators/{id}
      method: DELETE
      auth: true
      docs: Delete the Evaluator with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluator.
      display-name: Delete Evaluator
      errors:
        - root.EvaluatorsDeleteRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
    update:
      path: /evaluators/{id}
      method: PATCH
      auth: true
      docs: Update the Evaluator with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluator.
      display-name: Update Evaluator
      request:
        name: UpdateEvaluatorRequest
        body:
          properties:
            name:
              type: optional<string>
              docs: Name of the Evaluator, which is used as a unique identifier.
            directory_id:
              type: optional<string>
              docs: Unique identifier for the Directory of the Evaluator.
        content-type: application/json
      response:
        docs: Successful Response
        type: root.EvaluatorResponse
      errors:
        - root.EvaluatorsUpdateRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              spec:
                evaluator_type: human
                arguments_type: target_free
                return_type: boolean
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    listversions:
      path: /evaluators/{id}/versions
      method: GET
      auth: true
      docs: Get a list of all the versions of an Evaluator.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for the Evaluator.
      display-name: List Versions
      request:
        name: EvaluatorsListVersionsRequest
        query-parameters:
          status:
            type: optional<root.VersionStatus>
            docs: >-
              Filter versions by status: 'uncommitted', 'committed'. If no
              status is provided, all versions are returned.
          environment:
            type: optional<string>
            docs: >-
              Filter versions by environment tag. If no environment is provided,
              all versions are returned.
          evaluation_aggregates: optional<boolean>
      response:
        docs: Successful Response
        type: root.ListEvaluators
      errors:
        - root.EvaluatorsListVersionsRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  spec:
                    evaluator_type: human
                    arguments_type: target_free
                    return_type: boolean
                  version_logs_count: 1
                  total_logs_count: 1
                  inputs:
                    - name: name
    deploy:
      path: /evaluators/{id}/versions/{version_id}/deploy
      method: POST
      auth: true
      docs: >-
        Deploy Evaluator to Environment.


        Set the deployed Version for the specified Environment. This Evaluator
        Version

        will be used for calls made to the Evaluator in this Environment.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Evaluator.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Evaluator.
      display-name: Deploy
      request:
        name: DeployEvaluatorsIdVersionsVersionIdDeployPostRequest
        query-parameters:
          environment_id:
            type: string
            docs: Unique identifier for the Environment to deploy the Version to.
      response:
        docs: Successful Response
        type: root.EvaluatorResponse
      errors:
        - >-
          root.DeployEvaluatorsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          query-parameters:
            environment_id: environment_id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              spec:
                evaluator_type: human
                arguments_type: target_free
                return_type: boolean
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    commit:
      path: /evaluators/{id}/versions/{version_id}/commit
      method: POST
      auth: true
      docs: Commit the Evaluator Version with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Evaluator.
      display-name: Commit
      request:
        body:
          type: root.CommitRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.EvaluatorResponse
      errors:
        - root.EvaluatorsCommitRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          request:
            commit_message: commit_message
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              spec:
                evaluator_type: human
                arguments_type: target_free
                return_type: boolean
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    listdefault:
      path: /evaluators/default
      method: GET
      auth: true
      docs: Get a list of default evaluators for the organization.
      source:
        openapi: ../openapi.yml
      display-name: List Default Evaluators
      response:
        docs: Successful Response
        type: list<root.EvaluatorResponse>
      errors:
        - root.EvaluatorsListDefaultRequestUnprocessableEntityError
      examples:
        - response:
            body:
              - id: id
                name: name
                version_id: version_id
                created_at: '2024-01-15T09:30:00Z'
                updated_at: '2024-01-15T09:30:00Z'
                status: uncommitted
                last_used_at: '2024-01-15T09:30:00Z'
                spec:
                  evaluator_type: human
                  arguments_type: target_free
                  return_type: boolean
                version_logs_count: 1
                total_logs_count: 1
                inputs:
                  - name: name
    debug:
      path: /evaluators/debug
      method: POST
      auth: true
      docs: Run a synchronous evaluator execution on a collection of datapoints.
      source:
        openapi: ../openapi.yml
      display-name: Debug
      request:
        name: RunSyncEvaluationRequest
        body:
          properties:
            file_id:
              type: string
              docs: The ID of the Dataset that the datapoints belong to.
            evaluator:
              display-name: Evaluator
              type: Evaluator
            evaluator_version_id:
              type: optional<string>
              docs: >-
                The ID of the Evaluator Version being debugged if it already
                exists and is being edited.
            log_ids:
              type: optional<list<string>>
              docs: >-
                The IDs of the logs on which to run the draft evaluator.Provide
                one of `log_ids` or `datapoint_ids`.
            datapoint_ids:
              type: optional<list<string>>
              docs: >-
                The IDs of the evaluation datapoints on which to run the draft
                evaluator. 
            prompt_version_id:
              type: optional<string>
              docs: >-
                The ID of the Prompt Version to use generate datapoints for the
                evaluation datapoints. Only required if `datapoint` is provided;
                has no effect otherwise.
        content-type: application/json
      response:
        docs: Successful Response
        type: list<root.EvaluationDebugResultResponse>
      errors:
        - root.DebugEvaluatorsDebugPostRequestUnprocessableEntityError
      examples:
        - request:
            file_id: file_id
            evaluator:
              evaluator_type: human
              arguments_type: target_free
              return_type: boolean
          response:
            body:
              - log_id: log_id
                log:
                  id: id
                  config:
                    type: generic
                    id: config
                    status: config
                    name: config
                  evaluation_results:
                    - id: id
                      evaluator_id: evaluator_id
                      evaluator_version_id: evaluator_version_id
                      log_id: log_id
                      updated_at: '2024-01-15T09:30:00Z'
                      created_at: '2024-01-15T09:30:00Z'
                  observability_status: pending
                  updated_at: '2024-01-15T09:30:00Z'
  source:
    openapi: ../openapi.yml
types:
  Spec:
    discriminant: evaluator_type
    base-properties: {}
    union:
      llm:
        type: root.LLMEvaluatorRequest
      python:
        type: root.CodeEvaluatorRequest
      human:
        type: root.HumanEvaluatorRequest
    source:
      openapi: ../openapi.yml
  Evaluator:
    discriminant: evaluator_type
    base-properties: {}
    union:
      llm:
        type: root.LLMEvaluatorRequest
      python:
        type: root.CodeEvaluatorRequest
      human:
        type: root.HumanEvaluatorRequest
    source:
      openapi: ../openapi.yml
",
    },
    "logs.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "docs": "Logs contain the inputs and outputs of each time a Prompt, Tool or Evaluator is called.

Humanloop automatically records the inputs and outputs when you Call a Prompt or Tool and saves a Log.
Evaluator Logs are also created when an Evaluator is run on a Log.

You can manually create Logs through the API.

...


",
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "display-name": "Logs",
          "endpoints": {
            "delete": {
              "auth": true,
              "display-name": "Delete",
              "docs": "Delete Logs with the given IDs.",
              "errors": [
                "root.LogsDeleteRequestUnprocessableEntityError",
              ],
              "method": "DELETE",
              "pagination": undefined,
              "path": "/logs",
              "request": {
                "name": "LogsDeleteRequest",
                "query-parameters": {
                  "id": {
                    "allow-multiple": true,
                    "docs": "Unique identifiers for the Logs to delete.",
                    "type": "optional<string>",
                  },
                },
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "get": {
              "auth": true,
              "display-name": "Get Log",
              "docs": "Retrieve the Log with the given ID.",
              "errors": [
                "root.LogsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "id": "id",
                      "prompt": {
                        "created_at": "2024-01-15T09:30:00Z",
                        "id": "id",
                        "inputs": [
                          {
                            "name": "name",
                          },
                        ],
                        "last_used_at": "2024-01-15T09:30:00Z",
                        "model": "model",
                        "name": "name",
                        "status": "uncommitted",
                        "total_logs_count": 1,
                        "updated_at": "2024-01-15T09:30:00Z",
                        "version_id": "version_id",
                        "version_logs_count": 1,
                      },
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/logs/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Log.",
                  "type": "string",
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PromptLogResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listLogsForFile": {
              "auth": true,
              "display-name": "List",
              "docs": "List Logs.",
              "errors": [
                "root.ListLogsForFileLogsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "query-parameters": {
                    "file_id": "file_id",
                  },
                  "response": {
                    "body": {
                      "page": 1,
                      "records": [
                        {
                          "id": "id",
                          "prompt": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "model": "model",
                            "name": "name",
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "size": 1,
                      "total": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/logs",
              "request": {
                "name": "ListLogsForFileLogsGetRequest",
                "query-parameters": {
                  "end_date": {
                    "docs": "If provided, only Logs created before the specified date will be returned.",
                    "type": "optional<datetime>",
                  },
                  "file_id": {
                    "docs": "Unique identifier for the File to list Logs for.",
                    "type": "string",
                  },
                  "metadata_search": {
                    "docs": "If provided, only Logs that contain the provided string in its metadata will be returned.",
                    "type": "optional<string>",
                  },
                  "page": {
                    "docs": "Page number for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "search": {
                    "docs": "If provided, only Logs that contain the provided string in its inputs and output will be returned.",
                    "type": "optional<string>",
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Logs to fetch.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 0,
                      "multipleOf": undefined,
                    },
                  },
                  "start_date": {
                    "docs": "If provided, only Logs created after the specified date will be returned.",
                    "type": "optional<datetime>",
                  },
                  "version_id": {
                    "docs": "If provided, only Logs belonging to the specified Version will be returned.",
                    "type": "optional<string>",
                  },
                  "version_status": {
                    "docs": "If provided, only Logs belonging to Versions with the specified status will be returned.",
                    "type": "optional<root.VersionStatus>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PaginatedDataPromptLogResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yml",
          },
        },
      },
      "rawContents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    listLogsForFile:
      path: /logs
      method: GET
      auth: true
      docs: List Logs.
      source:
        openapi: ../openapi.yml
      display-name: List
      request:
        name: ListLogsForFileLogsGetRequest
        query-parameters:
          file_id:
            type: string
            docs: Unique identifier for the File to list Logs for.
          page:
            type: optional<integer>
            docs: Page number for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Logs to fetch.
            validation:
              min: 0
          version_id:
            type: optional<string>
            docs: >-
              If provided, only Logs belonging to the specified Version will be
              returned.
          version_status:
            type: optional<root.VersionStatus>
            docs: >-
              If provided, only Logs belonging to Versions with the specified
              status will be returned.
          search:
            type: optional<string>
            docs: >-
              If provided, only Logs that contain the provided string in its
              inputs and output will be returned.
          metadata_search:
            type: optional<string>
            docs: >-
              If provided, only Logs that contain the provided string in its
              metadata will be returned.
          start_date:
            type: optional<datetime>
            docs: >-
              If provided, only Logs created after the specified date will be
              returned.
          end_date:
            type: optional<datetime>
            docs: >-
              If provided, only Logs created before the specified date will be
              returned.
      response:
        docs: Successful Response
        type: root.PaginatedDataPromptLogResponse
      errors:
        - root.ListLogsForFileLogsGetRequestUnprocessableEntityError
      examples:
        - query-parameters:
            file_id: file_id
          response:
            body:
              records:
                - prompt:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    model: model
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  id: id
              page: 1
              size: 1
              total: 1
    delete:
      path: /logs
      method: DELETE
      auth: true
      docs: Delete Logs with the given IDs.
      source:
        openapi: ../openapi.yml
      display-name: Delete
      request:
        name: LogsDeleteRequest
        query-parameters:
          id:
            type: optional<string>
            allow-multiple: true
            docs: Unique identifiers for the Logs to delete.
      errors:
        - root.LogsDeleteRequestUnprocessableEntityError
    get:
      path: /logs/{id}
      method: GET
      auth: true
      docs: Retrieve the Log with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Log.
      display-name: Get Log
      response:
        docs: Successful Response
        type: root.PromptLogResponse
      errors:
        - root.LogsGetRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              prompt:
                id: id
                name: name
                version_id: version_id
                created_at: '2024-01-15T09:30:00Z'
                updated_at: '2024-01-15T09:30:00Z'
                status: uncommitted
                last_used_at: '2024-01-15T09:30:00Z'
                model: model
                version_logs_count: 1
                total_logs_count: 1
                inputs:
                  - name: name
              id: id
  source:
    openapi: ../openapi.yml
  display-name: Logs
docs: >+
  Logs contain the inputs and outputs of each time a Prompt, Tool or Evaluator
  is called.


  Humanloop automatically records the inputs and outputs when you Call a Prompt
  or Tool and saves a Log.

  Evaluator Logs are also created when an Evaluator is run on a Log.


  You can manually create Logs through the API.


  ...


",
    },
    "prompts.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "docs": "Prompts define how a large language model behaves.

#### What is a Prompt?

A Prompt on Humanloop encapsulates the instructions and other configuration for how a large language model should
perform a specific task.

Prompts have immutable versions that you can **Commit** and **Deploy**.
To use a Prompt, you can **Call** it to create a generation and you can **Log** generations manually.

#### Referencing a Prompt version

You can perform actions on a specific Prompt version by specifying either the `version_id`
or `environment` query parameter in the request. If you provide a `version_id`, Humanloop will
use the specified version of the Prompt. If you provide an `environment`, Humanloop will use the
version of the Prompt that is currently deployed to that Environment.
If you do not provide either a `version_id` or `environment`, Humanloop will use the Prompt version
that is deployed to the default Environment.

",
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "display-name": "Prompts",
          "endpoints": {
            "call": {
              "auth": true,
              "display-name": "Call",
              "docs": "Call a Prompt.

Calling a Prompt subsequently calls the model provider before logging
the data to Humanloop.

You can use query parameters version_id, or environment, to target
an existing version of the Prompt. Otherwise the default deployed version will be chosen.

Instead of targeting an existing version explicitly, you can instead pass in
Prompt details in the request body. In this case, we will check if the details correspond
to an existing version of the Prompt, if not we will create a new version. This is helpful
in the case where you are storing or deriving your Prompt details in code.",
              "errors": [
                "root.PromptsCallRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "id": "id",
                      "logs": [
                        {
                          "index": 1,
                        },
                      ],
                      "prompt": {
                        "created_at": "2024-01-15T09:30:00Z",
                        "id": "id",
                        "inputs": [
                          {
                            "name": "name",
                          },
                        ],
                        "last_used_at": "2024-01-15T09:30:00Z",
                        "model": "model",
                        "name": "name",
                        "status": "uncommitted",
                        "total_logs_count": 1,
                        "updated_at": "2024-01-15T09:30:00Z",
                        "version_id": "version_id",
                        "version_logs_count": 1,
                      },
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/prompts/{id}/call",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "batches": {
                      "docs": "Array of Batch Ids that this log is part of. Batches are used to group Logs together for offline Evaluations",
                      "type": "optional<list<string>>",
                    },
                    "environment": {
                      "docs": "The name of the Environment the Log is associated to.",
                      "name": "promptCallRequestEnvironment",
                      "type": "optional<string>",
                    },
                    "inputs": {
                      "docs": "The inputs passed to the prompt template.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "logprobs": {
                      "docs": "Include the log probabilities of the top n tokens in the provider_response",
                      "type": "optional<integer>",
                    },
                    "messages": {
                      "docs": "The messages passed to the to provider chat endpoint.",
                      "type": "optional<list<root.ChatMessage>>",
                    },
                    "metadata": {
                      "docs": "Any additional metadata to record.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "num_samples": {
                      "default": 1,
                      "docs": "The number of generations.",
                      "type": "optional<integer>",
                    },
                    "parent_id": {
                      "docs": "Unique identifier for the parent Log in a Session. Should only be provided if `session_id` is provided. If provided, the Log will be nested under the parent Log within the Session.",
                      "type": "optional<string>",
                    },
                    "prompt": {
                      "docs": "Details of your Prompt. A new Prompt version will be created if the provided details are new.",
                      "type": "optional<root.PromptKernelRequest>",
                    },
                    "provider_api_keys": {
                      "docs": "API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.",
                      "type": "optional<root.ProviderApiKeys>",
                    },
                    "return_inputs": {
                      "default": true,
                      "docs": "Whether to return the inputs in the response. If false, the response will contain an empty dictionary under inputs. This is useful for reducing the size of the response. Defaults to true.",
                      "type": "optional<boolean>",
                    },
                    "save": {
                      "default": true,
                      "docs": "Whether the request/response payloads will be stored on Humanloop.",
                      "type": "optional<boolean>",
                    },
                    "session_id": {
                      "docs": "Unique identifier for the Session to associate the Log to. Allows you to record multiple Logs to a Session (using an ID kept by your internal systems) by passing the same `session_id` in subsequent log requests. ",
                      "type": "optional<string>",
                    },
                    "source": {
                      "docs": "Identifies where the model was called from.",
                      "type": "optional<string>",
                    },
                    "source_datapoint_id": {
                      "docs": "Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.",
                      "type": "optional<string>",
                    },
                    "stream": {
                      "default": false,
                      "docs": "If true, tokens will be sent as data-only server-sent events. If num_samples > 1, samples are streamed back independently.",
                      "type": "optional<boolean>",
                    },
                    "suffix": {
                      "docs": "The suffix that comes after a completion of inserted text. Useful for completions that act like inserts.",
                      "type": "optional<string>",
                    },
                    "tool_choice": {
                      "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
                      "type": "optional<PromptCallRequestToolChoice>",
                    },
                    "user": {
                      "docs": "End-user ID related to the Log.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "PromptCallRequest",
                "path-parameters": undefined,
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag of the deployed version to log to.",
                    "type": "optional<string>",
                  },
                  "version_id": {
                    "docs": "A specific version Id of the Prompt to log to.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "PromptsCallResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "commit": {
              "auth": true,
              "display-name": "Commit",
              "docs": "Commit the Prompt Version with the given ID.",
              "errors": [
                "root.PromptsCommitRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "request": {
                    "commit_message": "commit_message",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "model": "model",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/prompts/{id}/versions/{version_id}/commit",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Prompt.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "type": "root.CommitRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PromptResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "create": {
              "auth": true,
              "display-name": "Create Prompt",
              "docs": "Create a Prompt.

When you call this endpoint with the same Prompt name but different parameters,
a new version of the Prompt will be created.

If you provide a commit message, then the new version will be committed;
otherwise it will be uncommitted. If you try to commit an already committed version,
an exception will be raised.",
              "errors": [
                "root.PromptsCreateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "request": {
                    "model": "model",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "model": "model",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/prompts",
              "request": {
                "body": {
                  "properties": {
                    "commit_message": {
                      "docs": "Message describing the changes made.",
                      "type": "optional<string>",
                    },
                    "directory_id": {
                      "docs": "Unique identifier for the Directory of the Prompt. ",
                      "type": "optional<string>",
                    },
                    "endpoint": {
                      "docs": "The provider model endpoint used.",
                      "type": "optional<root.ModelEndpoints>",
                    },
                    "frequency_penalty": {
                      "default": 0,
                      "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.",
                      "type": "optional<double>",
                    },
                    "linked_tools": {
                      "docs": "The IDs of the Tools in your organization that the model can choose to call if Tool calling is supported. The default deployed version of that tool is called.",
                      "type": "optional<list<string>>",
                    },
                    "max_tokens": {
                      "default": -1,
                      "docs": "The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt",
                      "type": "optional<integer>",
                    },
                    "model": {
                      "docs": "The model instance used, e.g. `gpt-4`. See [supported models](https://humanloop.com/docs/supported-models)",
                      "type": "string",
                    },
                    "name": {
                      "docs": "Name of the Prompt, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                    "other": {
                      "docs": "Other parameter values to be passed to the provider call.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "presence_penalty": {
                      "default": 0,
                      "docs": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.",
                      "type": "optional<double>",
                    },
                    "provider": {
                      "docs": "The company providing the underlying model service.",
                      "type": "optional<root.ModelProviders>",
                    },
                    "response_format": {
                      "docs": "The format of the response. Only `{"type": "json_object"}` is currently supported for chat.",
                      "type": "optional<root.ResponseFormat>",
                    },
                    "seed": {
                      "docs": "If specified, model will make a best effort to sample deterministically, but it is not guaranteed.",
                      "type": "optional<integer>",
                    },
                    "stop": {
                      "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
                      "type": "optional<PromptRequestStop>",
                    },
                    "temperature": {
                      "default": 1,
                      "docs": "What sampling temperature to use when making a generation. Higher values means the model will be more creative.",
                      "type": "optional<double>",
                    },
                    "template": {
                      "docs": "For chat endpoint, provide a Chat template. For completion endpoint, provide a Prompt template. Input variables within the template should be specified with double curly bracket syntax: {{INPUT_NAME}}.",
                      "type": "optional<Template>",
                    },
                    "tools": {
                      "docs": "The tool specification that the model can choose to call if Tool calling is supported.",
                      "type": "optional<list<root.ToolFunction>>",
                    },
                    "top_p": {
                      "default": 1,
                      "docs": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.",
                      "type": "optional<double>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "PromptRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PromptResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "delete": {
              "auth": true,
              "display-name": "Delete Prompt",
              "docs": "Delete the Prompt with the given ID.",
              "errors": [
                "root.PromptsDeleteRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                },
              ],
              "method": "DELETE",
              "pagination": undefined,
              "path": "/prompts/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "deploy": {
              "auth": true,
              "display-name": "Deploy",
              "docs": "Deploy Prompt to Environment.

Set the deployed Version for the specified Environment. This Prompt Version
will be used for calls made to the Prompt in this Environment.",
              "errors": [
                "root.DeployPromptsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "query-parameters": {
                    "environment_id": "environment_id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "model": "model",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/prompts/{id}/versions/{version_id}/deploy",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Prompt.",
                  "type": "string",
                },
              },
              "request": {
                "name": "DeployPromptsIdVersionsVersionIdDeployPostRequest",
                "query-parameters": {
                  "environment_id": {
                    "docs": "Unique identifier for the Environment to deploy the Version to.",
                    "type": "string",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PromptResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "get": {
              "auth": true,
              "display-name": "Get Prompt",
              "docs": "Retrieve the Prompt with the given ID.

By default the deployed version of the Prompt is returned. Use the query parameters
`version_id` or `environment` to target a specific version of the Prompt.",
              "errors": [
                "root.PromptsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "model": "model",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/prompts/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
              },
              "request": {
                "name": "PromptsGetRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag to retrieve a deployed Version from.",
                    "type": "optional<string>",
                  },
                  "version_id": {
                    "docs": "A specific Version Id  of the Prompt to retrieve.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PromptResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "list": {
              "auth": true,
              "display-name": "List ",
              "docs": "Get a list of Prompts.",
              "errors": [
                "root.PromptsListRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "response": {
                    "body": {
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "id": "id",
                          "inputs": [
                            {
                              "name": "name",
                            },
                          ],
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "model": "model",
                          "name": "name",
                          "status": "uncommitted",
                          "total_logs_count": 1,
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                          "version_logs_count": 1,
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/prompts",
              "request": {
                "name": "PromptsListRequest",
                "query-parameters": {
                  "name": {
                    "docs": "Case-insensitive filter for Prompt name.",
                    "type": "optional<string>",
                  },
                  "order": {
                    "docs": "Direction to sort by.",
                    "type": "optional<root.SortOrder>",
                  },
                  "page": {
                    "docs": "Page number for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Prompts to fetch.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 0,
                      "multipleOf": undefined,
                    },
                  },
                  "sort_by": {
                    "docs": "Field to sort Prompts by",
                    "type": "optional<root.ProjectSortBy>",
                  },
                  "user_filter": {
                    "docs": "Case-insensitive filter for users in the Prompt. This filter matches against both email address and name of users.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ListPrompts",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listversions": {
              "auth": true,
              "display-name": "List Versions",
              "docs": "Get a list of all the versions of a Prompt.",
              "errors": [
                "root.PromptsListVersionsRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "id": "id",
                          "inputs": [
                            {
                              "name": "name",
                            },
                          ],
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "model": "model",
                          "name": "name",
                          "status": "uncommitted",
                          "total_logs_count": 1,
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                          "version_logs_count": 1,
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/prompts/{id}/versions",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
              },
              "request": {
                "name": "PromptsListVersionsRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "Filter versions by environment tag. If no environment is provided, all versions are returned.",
                    "type": "optional<string>",
                  },
                  "evaluation_aggregates": "optional<boolean>",
                  "status": {
                    "docs": "Filter versions by status: 'uncommitted', 'committed'. If no status is provided, all versions are returned.",
                    "type": "optional<root.VersionStatus>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ListPrompts",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "log": {
              "auth": true,
              "display-name": "Log",
              "docs": "Log to a Prompt.

You can use query parameters version_id, or environment, to target
an existing version of the Prompt. Otherwise the default deployed version will be chosen.

Instead of targeting an existing version explicitly, you can instead pass in
Prompt details in the request body. In this case, we will check if the details correspond
to an existing version of the Prompt, if not we will create a new version. This is helpful
in the case where you are storing or deriving your Prompt details in code.",
              "errors": [
                "root.PromptsLogRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "id": "id",
                      "prompt_id": "prompt_id",
                      "version_id": "version_id",
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/prompts/{id}/log",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "batches": {
                      "docs": "Array of Batch Ids that this log is part of. Batches are used to group Logs together for offline Evaluations",
                      "type": "optional<list<string>>",
                    },
                    "created_at": {
                      "docs": "User defined timestamp for when the log was created. ",
                      "type": "optional<datetime>",
                    },
                    "environment": {
                      "docs": "The name of the Environment the Log is associated to.",
                      "name": "promptLogRequestEnvironment",
                      "type": "optional<string>",
                    },
                    "error": {
                      "docs": "Error message if the log is an error.",
                      "type": "optional<string>",
                    },
                    "finish_reason": {
                      "docs": "Reason the generation finished.",
                      "type": "optional<string>",
                    },
                    "inputs": {
                      "docs": "The inputs passed to the prompt template.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "messages": {
                      "docs": "The messages passed to the to provider chat endpoint.",
                      "type": "optional<list<root.ChatMessage>>",
                    },
                    "metadata": {
                      "docs": "Any additional metadata to record.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "output": {
                      "docs": "Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.",
                      "type": "optional<string>",
                    },
                    "output_cost": {
                      "docs": "Cost in dollars associated to the tokens in the output.",
                      "type": "optional<double>",
                    },
                    "output_message": {
                      "docs": "The message returned by the provider.",
                      "type": "optional<root.ChatMessage>",
                    },
                    "output_tokens": {
                      "docs": "Number of tokens in the output generated by the model.",
                      "type": "optional<integer>",
                    },
                    "parent_id": {
                      "docs": "Unique identifier for the parent Log in a Session. Should only be provided if `session_id` is provided. If provided, the Log will be nested under the parent Log within the Session.",
                      "type": "optional<string>",
                    },
                    "prompt": {
                      "docs": "Details of your Prompt. A new Prompt version will be created if the provided details are new.",
                      "type": "optional<root.PromptKernelRequest>",
                    },
                    "prompt_cost": {
                      "docs": "Cost in dollars associated to the tokens in the prompt.",
                      "type": "optional<double>",
                    },
                    "prompt_tokens": {
                      "docs": "Number of tokens in the prompt used to generate the output.",
                      "type": "optional<integer>",
                    },
                    "provider_latency": {
                      "docs": "Duration of the logged event in seconds.",
                      "type": "optional<double>",
                    },
                    "provider_request": {
                      "docs": "Raw request sent to provider.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "provider_response": {
                      "docs": "Raw response received the provider.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "raw_output": {
                      "docs": "Raw output from the provider.",
                      "type": "optional<string>",
                    },
                    "save": {
                      "default": true,
                      "docs": "Whether the request/response payloads will be stored on Humanloop.",
                      "type": "optional<boolean>",
                    },
                    "session_id": {
                      "docs": "Unique identifier for the Session to associate the Log to. Allows you to record multiple Logs to a Session (using an ID kept by your internal systems) by passing the same `session_id` in subsequent log requests. ",
                      "type": "optional<string>",
                    },
                    "source": {
                      "docs": "Identifies where the model was called from.",
                      "type": "optional<string>",
                    },
                    "source_datapoint_id": {
                      "docs": "Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.",
                      "type": "optional<string>",
                    },
                    "tool_choice": {
                      "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
                      "type": "optional<PromptLogRequestToolChoice>",
                    },
                    "user": {
                      "docs": "End-user ID related to the Log.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "PromptLogRequest",
                "path-parameters": undefined,
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag of the deployed version to log to.",
                    "type": "optional<string>",
                  },
                  "version_id": {
                    "docs": "A specific version Id of the Prompt to log to.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.CreatePromptLogResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "update": {
              "auth": true,
              "display-name": "Update Prompt",
              "docs": "Update the Prompt with the given ID.",
              "errors": [
                "root.PromptsUpdateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "model": "model",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "PATCH",
              "pagination": undefined,
              "path": "/prompts/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Prompt.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "directory_id": {
                      "docs": "Unique identifier for the Directory of the Prompt. ",
                      "type": "optional<string>",
                    },
                    "name": {
                      "docs": "Name of the Prompt, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "UpdatePromptRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PromptResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "updateEvaluators": {
              "auth": true,
              "display-name": "Update Evaluators",
              "docs": "Activate and deactivate Evaluators for the Prompt.

An activated Evaluator will automatically be run on all new Logs
within the Prompt for monitoring purposes.",
              "errors": [
                "root.UpdateEvaluatorsPromptsIdEvaluatorsPostRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "model": "model",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/prompts/{id}/evaluators",
              "path-parameters": {
                "id": "string",
              },
              "request": {
                "body": {
                  "type": "root.EvaluatorActivationDeactivationRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PromptResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yml",
          },
        },
        "types": {
          "PromptCallRequestToolChoice": {
            "discriminated": false,
            "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "literal<"none">",
              "literal<"auto">",
              "literal<"required">",
              {
                "type": "root.ToolChoice",
              },
            ],
          },
          "PromptLogRequestToolChoice": {
            "discriminated": false,
            "docs": "Controls how the model uses tools. The following options are supported: 
- `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. 
- `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. 
- `'required'` means the model can decide to call one or more of the provided tools. 
- `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "literal<"none">",
              "literal<"auto">",
              "literal<"required">",
              {
                "type": "root.ToolChoice",
              },
            ],
          },
          "PromptRequestStop": {
            "discriminated": false,
            "docs": "The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<string>",
            ],
          },
          "PromptsCallResponse": {
            "discriminated": false,
            "docs": undefined,
            "encoding": undefined,
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              {
                "type": "root.PromptCallResponse",
              },
              {
                "type": "root.PromptCallStreamResponse",
              },
            ],
          },
          "Template": {
            "discriminated": false,
            "docs": "For chat endpoint, provide a Chat template. For completion endpoint, provide a Prompt template. Input variables within the template should be specified with double curly bracket syntax: {{INPUT_NAME}}.",
            "encoding": undefined,
            "inline": true,
            "source": {
              "openapi": "../openapi.yml",
            },
            "union": [
              "string",
              "list<root.ChatMessage>",
            ],
          },
        },
      },
      "rawContents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    list:
      path: /prompts
      method: GET
      auth: true
      docs: Get a list of Prompts.
      source:
        openapi: ../openapi.yml
      display-name: 'List '
      request:
        name: PromptsListRequest
        query-parameters:
          page:
            type: optional<integer>
            docs: Page number for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Prompts to fetch.
            validation:
              min: 0
          name:
            type: optional<string>
            docs: Case-insensitive filter for Prompt name.
          user_filter:
            type: optional<string>
            docs: >-
              Case-insensitive filter for users in the Prompt. This filter
              matches against both email address and name of users.
          sort_by:
            type: optional<root.ProjectSortBy>
            docs: Field to sort Prompts by
          order:
            type: optional<root.SortOrder>
            docs: Direction to sort by.
      response:
        docs: Successful Response
        type: root.ListPrompts
      errors:
        - root.PromptsListRequestUnprocessableEntityError
      examples:
        - response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  model: model
                  version_logs_count: 1
                  total_logs_count: 1
                  inputs:
                    - name: name
    create:
      path: /prompts
      method: POST
      auth: true
      docs: >-
        Create a Prompt.


        When you call this endpoint with the same Prompt name but different
        parameters,

        a new version of the Prompt will be created.


        If you provide a commit message, then the new version will be committed;

        otherwise it will be uncommitted. If you try to commit an already
        committed version,

        an exception will be raised.
      source:
        openapi: ../openapi.yml
      display-name: Create Prompt
      request:
        name: PromptRequest
        body:
          properties:
            name:
              type: optional<string>
              docs: Name of the Prompt, which is used as a unique identifier.
            directory_id:
              type: optional<string>
              docs: 'Unique identifier for the Directory of the Prompt. '
            model:
              type: string
              docs: >-
                The model instance used, e.g. `gpt-4`. See [supported
                models](https://humanloop.com/docs/supported-models)
            endpoint:
              type: optional<root.ModelEndpoints>
              docs: The provider model endpoint used.
            template:
              type: optional<Template>
              docs: >-
                For chat endpoint, provide a Chat template. For completion
                endpoint, provide a Prompt template. Input variables within the
                template should be specified with double curly bracket syntax:
                {{INPUT_NAME}}.
            provider:
              type: optional<root.ModelProviders>
              docs: The company providing the underlying model service.
            max_tokens:
              type: optional<integer>
              docs: >-
                The maximum number of tokens to generate. Provide max_tokens=-1
                to dynamically calculate the maximum number of tokens to
                generate given the length of the prompt
              default: -1
            temperature:
              type: optional<double>
              docs: >-
                What sampling temperature to use when making a generation.
                Higher values means the model will be more creative.
              default: 1
            top_p:
              type: optional<double>
              docs: >-
                An alternative to sampling with temperature, called nucleus
                sampling, where the model considers the results of the tokens
                with top_p probability mass.
              default: 1
            stop:
              type: optional<PromptRequestStop>
              docs: >-
                The string (or list of strings) after which the model will stop
                generating. The returned text will not contain the stop
                sequence.
            presence_penalty:
              type: optional<double>
              docs: >-
                Number between -2.0 and 2.0. Positive values penalize new tokens
                based on whether they appear in the generation so far.
              default: 0
            frequency_penalty:
              type: optional<double>
              docs: >-
                Number between -2.0 and 2.0. Positive values penalize new tokens
                based on how frequently they appear in the generation so far.
              default: 0
            other:
              type: optional<map<string, unknown>>
              docs: Other parameter values to be passed to the provider call.
            seed:
              type: optional<integer>
              docs: >-
                If specified, model will make a best effort to sample
                deterministically, but it is not guaranteed.
            response_format:
              type: optional<root.ResponseFormat>
              docs: >-
                The format of the response. Only `{"type": "json_object"}` is
                currently supported for chat.
            tools:
              type: optional<list<root.ToolFunction>>
              docs: >-
                The tool specification that the model can choose to call if Tool
                calling is supported.
            linked_tools:
              type: optional<list<string>>
              docs: >-
                The IDs of the Tools in your organization that the model can
                choose to call if Tool calling is supported. The default
                deployed version of that tool is called.
            commit_message:
              type: optional<string>
              docs: Message describing the changes made.
        content-type: application/json
      response:
        docs: Successful Response
        type: root.PromptResponse
      errors:
        - root.PromptsCreateRequestUnprocessableEntityError
      examples:
        - request:
            model: model
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              model: model
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    get:
      path: /prompts/{id}
      method: GET
      auth: true
      docs: >-
        Retrieve the Prompt with the given ID.


        By default the deployed version of the Prompt is returned. Use the query
        parameters

        `version_id` or `environment` to target a specific version of the
        Prompt.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
      display-name: Get Prompt
      request:
        name: PromptsGetRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific Version Id  of the Prompt to retrieve.
          environment:
            type: optional<string>
            docs: An environment tag to retrieve a deployed Version from.
      response:
        docs: Successful Response
        type: root.PromptResponse
      errors:
        - root.PromptsGetRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              model: model
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    delete:
      path: /prompts/{id}
      method: DELETE
      auth: true
      docs: Delete the Prompt with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
      display-name: Delete Prompt
      errors:
        - root.PromptsDeleteRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
    update:
      path: /prompts/{id}
      method: PATCH
      auth: true
      docs: Update the Prompt with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
      display-name: Update Prompt
      request:
        name: UpdatePromptRequest
        body:
          properties:
            name:
              type: optional<string>
              docs: Name of the Prompt, which is used as a unique identifier.
            directory_id:
              type: optional<string>
              docs: 'Unique identifier for the Directory of the Prompt. '
        content-type: application/json
      response:
        docs: Successful Response
        type: root.PromptResponse
      errors:
        - root.PromptsUpdateRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              model: model
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    listversions:
      path: /prompts/{id}/versions
      method: GET
      auth: true
      docs: Get a list of all the versions of a Prompt.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
      display-name: List Versions
      request:
        name: PromptsListVersionsRequest
        query-parameters:
          status:
            type: optional<root.VersionStatus>
            docs: >-
              Filter versions by status: 'uncommitted', 'committed'. If no
              status is provided, all versions are returned.
          environment:
            type: optional<string>
            docs: >-
              Filter versions by environment tag. If no environment is provided,
              all versions are returned.
          evaluation_aggregates: optional<boolean>
      response:
        docs: Successful Response
        type: root.ListPrompts
      errors:
        - root.PromptsListVersionsRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  model: model
                  version_logs_count: 1
                  total_logs_count: 1
                  inputs:
                    - name: name
    deploy:
      path: /prompts/{id}/versions/{version_id}/deploy
      method: POST
      auth: true
      docs: >-
        Deploy Prompt to Environment.


        Set the deployed Version for the specified Environment. This Prompt
        Version

        will be used for calls made to the Prompt in this Environment.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Prompt.
      display-name: Deploy
      request:
        name: DeployPromptsIdVersionsVersionIdDeployPostRequest
        query-parameters:
          environment_id:
            type: string
            docs: Unique identifier for the Environment to deploy the Version to.
      response:
        docs: Successful Response
        type: root.PromptResponse
      errors:
        - >-
          root.DeployPromptsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          query-parameters:
            environment_id: environment_id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              model: model
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    commit:
      path: /prompts/{id}/versions/{version_id}/commit
      method: POST
      auth: true
      docs: Commit the Prompt Version with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Prompt.
      display-name: Commit
      request:
        body:
          type: root.CommitRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.PromptResponse
      errors:
        - root.PromptsCommitRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          request:
            commit_message: commit_message
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              model: model
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    log:
      path: /prompts/{id}/log
      method: POST
      auth: true
      docs: >-
        Log to a Prompt.


        You can use query parameters version_id, or environment, to target

        an existing version of the Prompt. Otherwise the default deployed
        version will be chosen.


        Instead of targeting an existing version explicitly, you can instead
        pass in

        Prompt details in the request body. In this case, we will check if the
        details correspond

        to an existing version of the Prompt, if not we will create a new
        version. This is helpful

        in the case where you are storing or deriving your Prompt details in
        code.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
      display-name: Log
      request:
        name: PromptLogRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific version Id of the Prompt to log to.
          environment:
            type: optional<string>
            docs: An environment tag of the deployed version to log to.
        body:
          properties:
            output_message:
              type: optional<root.ChatMessage>
              docs: The message returned by the provider.
            prompt_tokens:
              type: optional<integer>
              docs: Number of tokens in the prompt used to generate the output.
            output_tokens:
              type: optional<integer>
              docs: Number of tokens in the output generated by the model.
            prompt_cost:
              type: optional<double>
              docs: Cost in dollars associated to the tokens in the prompt.
            output_cost:
              type: optional<double>
              docs: Cost in dollars associated to the tokens in the output.
            finish_reason:
              type: optional<string>
              docs: Reason the generation finished.
            prompt:
              type: optional<root.PromptKernelRequest>
              docs: >-
                Details of your Prompt. A new Prompt version will be created if
                the provided details are new.
            messages:
              type: optional<list<root.ChatMessage>>
              docs: The messages passed to the to provider chat endpoint.
            tool_choice:
              type: optional<PromptLogRequestToolChoice>
              docs: >-
                Controls how the model uses tools. The following options are
                supported: 

                - `'none'` means the model will not call any tool and instead
                generates a message; this is the default when no tools are
                provided as part of the Prompt. 

                - `'auto'` means the model can decide to call one or more of the
                provided tools; this is the default when tools are provided as
                part of the Prompt. 

                - `'required'` means the model can decide to call one or more of
                the provided tools. 

                - `{'type': 'function', 'function': {name': <TOOL_NAME>}}`
                forces the model to use the named function.
            output:
              type: optional<string>
              docs: >-
                Generated output from your model for the provided inputs. Can be
                `None` if logging an error, or if creating a parent Log with the
                intention to populate it later.
            raw_output:
              type: optional<string>
              docs: Raw output from the provider.
            created_at:
              type: optional<datetime>
              docs: 'User defined timestamp for when the log was created. '
            error:
              type: optional<string>
              docs: Error message if the log is an error.
            provider_latency:
              type: optional<double>
              docs: Duration of the logged event in seconds.
            provider_request:
              type: optional<map<string, unknown>>
              docs: Raw request sent to provider.
            provider_response:
              type: optional<map<string, unknown>>
              docs: Raw response received the provider.
            session_id:
              type: optional<string>
              docs: >-
                Unique identifier for the Session to associate the Log to.
                Allows you to record multiple Logs to a Session (using an ID
                kept by your internal systems) by passing the same `session_id`
                in subsequent log requests. 
            parent_id:
              type: optional<string>
              docs: >-
                Unique identifier for the parent Log in a Session. Should only
                be provided if `session_id` is provided. If provided, the Log
                will be nested under the parent Log within the Session.
            inputs:
              type: optional<map<string, unknown>>
              docs: The inputs passed to the prompt template.
            source:
              type: optional<string>
              docs: Identifies where the model was called from.
            metadata:
              type: optional<map<string, unknown>>
              docs: Any additional metadata to record.
            save:
              type: optional<boolean>
              docs: >-
                Whether the request/response payloads will be stored on
                Humanloop.
              default: true
            source_datapoint_id:
              type: optional<string>
              docs: >-
                Unique identifier for the Datapoint that this Log is derived
                from. This can be used by Humanloop to associate Logs to
                Evaluations. If provided, Humanloop will automatically associate
                this Log to Evaluations that require a Log for this
                Datapoint-Version pair.
            batches:
              type: optional<list<string>>
              docs: >-
                Array of Batch Ids that this log is part of. Batches are used to
                group Logs together for offline Evaluations
            user:
              type: optional<string>
              docs: End-user ID related to the Log.
            environment:
              type: optional<string>
              docs: The name of the Environment the Log is associated to.
              name: promptLogRequestEnvironment
        content-type: application/json
      response:
        docs: Successful Response
        type: root.CreatePromptLogResponse
      errors:
        - root.PromptsLogRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              prompt_id: prompt_id
              version_id: version_id
    call:
      path: /prompts/{id}/call
      method: POST
      auth: true
      docs: >-
        Call a Prompt.


        Calling a Prompt subsequently calls the model provider before logging

        the data to Humanloop.


        You can use query parameters version_id, or environment, to target

        an existing version of the Prompt. Otherwise the default deployed
        version will be chosen.


        Instead of targeting an existing version explicitly, you can instead
        pass in

        Prompt details in the request body. In this case, we will check if the
        details correspond

        to an existing version of the Prompt, if not we will create a new
        version. This is helpful

        in the case where you are storing or deriving your Prompt details in
        code.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Prompt.
      display-name: Call
      request:
        name: PromptCallRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific version Id of the Prompt to log to.
          environment:
            type: optional<string>
            docs: An environment tag of the deployed version to log to.
        body:
          properties:
            prompt:
              type: optional<root.PromptKernelRequest>
              docs: >-
                Details of your Prompt. A new Prompt version will be created if
                the provided details are new.
            messages:
              type: optional<list<root.ChatMessage>>
              docs: The messages passed to the to provider chat endpoint.
            tool_choice:
              type: optional<PromptCallRequestToolChoice>
              docs: >-
                Controls how the model uses tools. The following options are
                supported: 

                - `'none'` means the model will not call any tool and instead
                generates a message; this is the default when no tools are
                provided as part of the Prompt. 

                - `'auto'` means the model can decide to call one or more of the
                provided tools; this is the default when tools are provided as
                part of the Prompt. 

                - `'required'` means the model can decide to call one or more of
                the provided tools. 

                - `{'type': 'function', 'function': {name': <TOOL_NAME>}}`
                forces the model to use the named function.
            session_id:
              type: optional<string>
              docs: >-
                Unique identifier for the Session to associate the Log to.
                Allows you to record multiple Logs to a Session (using an ID
                kept by your internal systems) by passing the same `session_id`
                in subsequent log requests. 
            parent_id:
              type: optional<string>
              docs: >-
                Unique identifier for the parent Log in a Session. Should only
                be provided if `session_id` is provided. If provided, the Log
                will be nested under the parent Log within the Session.
            inputs:
              type: optional<map<string, unknown>>
              docs: The inputs passed to the prompt template.
            source:
              type: optional<string>
              docs: Identifies where the model was called from.
            metadata:
              type: optional<map<string, unknown>>
              docs: Any additional metadata to record.
            save:
              type: optional<boolean>
              docs: >-
                Whether the request/response payloads will be stored on
                Humanloop.
              default: true
            source_datapoint_id:
              type: optional<string>
              docs: >-
                Unique identifier for the Datapoint that this Log is derived
                from. This can be used by Humanloop to associate Logs to
                Evaluations. If provided, Humanloop will automatically associate
                this Log to Evaluations that require a Log for this
                Datapoint-Version pair.
            batches:
              type: optional<list<string>>
              docs: >-
                Array of Batch Ids that this log is part of. Batches are used to
                group Logs together for offline Evaluations
            user:
              type: optional<string>
              docs: End-user ID related to the Log.
            environment:
              type: optional<string>
              docs: The name of the Environment the Log is associated to.
              name: promptCallRequestEnvironment
            provider_api_keys:
              type: optional<root.ProviderApiKeys>
              docs: >-
                API keys required by each provider to make API calls. The API
                keys provided here are not stored by Humanloop. If not specified
                here, Humanloop will fall back to the key saved to your
                organization.
            num_samples:
              type: optional<integer>
              docs: The number of generations.
              default: 1
            stream:
              type: optional<boolean>
              docs: >-
                If true, tokens will be sent as data-only server-sent events. If
                num_samples > 1, samples are streamed back independently.
              default: false
            return_inputs:
              type: optional<boolean>
              docs: >-
                Whether to return the inputs in the response. If false, the
                response will contain an empty dictionary under inputs. This is
                useful for reducing the size of the response. Defaults to true.
              default: true
            logprobs:
              type: optional<integer>
              docs: >-
                Include the log probabilities of the top n tokens in the
                provider_response
            suffix:
              type: optional<string>
              docs: >-
                The suffix that comes after a completion of inserted text.
                Useful for completions that act like inserts.
        content-type: application/json
      response:
        docs: Successful Response
        type: PromptsCallResponse
      errors:
        - root.PromptsCallRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              prompt:
                id: id
                name: name
                version_id: version_id
                created_at: '2024-01-15T09:30:00Z'
                updated_at: '2024-01-15T09:30:00Z'
                status: uncommitted
                last_used_at: '2024-01-15T09:30:00Z'
                model: model
                version_logs_count: 1
                total_logs_count: 1
                inputs:
                  - name: name
              id: id
              logs:
                - index: 1
    updateEvaluators:
      path: /prompts/{id}/evaluators
      method: POST
      auth: true
      docs: |-
        Activate and deactivate Evaluators for the Prompt.

        An activated Evaluator will automatically be run on all new Logs
        within the Prompt for monitoring purposes.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id: string
      display-name: Update Evaluators
      request:
        body:
          type: root.EvaluatorActivationDeactivationRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.PromptResponse
      errors:
        - >-
          root.UpdateEvaluatorsPromptsIdEvaluatorsPostRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              model: model
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
  source:
    openapi: ../openapi.yml
  display-name: Prompts
docs: >+
  Prompts define how a large language model behaves.


  #### What is a Prompt?


  A Prompt on Humanloop encapsulates the instructions and other configuration
  for how a large language model should

  perform a specific task.


  Prompts have immutable versions that you can **Commit** and **Deploy**.

  To use a Prompt, you can **Call** it to create a generation and you can
  **Log** generations manually.


  #### Referencing a Prompt version


  You can perform actions on a specific Prompt version by specifying either the
  `version_id`

  or `environment` query parameter in the request. If you provide a
  `version_id`, Humanloop will

  use the specified version of the Prompt. If you provide an `environment`,
  Humanloop will use the

  version of the Prompt that is currently deployed to that Environment.

  If you do not provide either a `version_id` or `environment`, Humanloop will
  use the Prompt version

  that is deployed to the default Environment.

types:
  Template:
    discriminated: false
    docs: >-
      For chat endpoint, provide a Chat template. For completion endpoint,
      provide a Prompt template. Input variables within the template should be
      specified with double curly bracket syntax: {{INPUT_NAME}}.
    union:
      - string
      - list<root.ChatMessage>
    source:
      openapi: ../openapi.yml
    inline: true
  PromptRequestStop:
    discriminated: false
    docs: >-
      The string (or list of strings) after which the model will stop
      generating. The returned text will not contain the stop sequence.
    union:
      - string
      - list<string>
    source:
      openapi: ../openapi.yml
    inline: true
  PromptLogRequestToolChoice:
    discriminated: false
    docs: >-
      Controls how the model uses tools. The following options are supported: 

      - `'none'` means the model will not call any tool and instead generates a
      message; this is the default when no tools are provided as part of the
      Prompt. 

      - `'auto'` means the model can decide to call one or more of the provided
      tools; this is the default when tools are provided as part of the Prompt. 

      - `'required'` means the model can decide to call one or more of the
      provided tools. 

      - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the
      model to use the named function.
    union:
      - literal<"none">
      - literal<"auto">
      - literal<"required">
      - type: root.ToolChoice
    source:
      openapi: ../openapi.yml
    inline: true
  PromptCallRequestToolChoice:
    discriminated: false
    docs: >-
      Controls how the model uses tools. The following options are supported: 

      - `'none'` means the model will not call any tool and instead generates a
      message; this is the default when no tools are provided as part of the
      Prompt. 

      - `'auto'` means the model can decide to call one or more of the provided
      tools; this is the default when tools are provided as part of the Prompt. 

      - `'required'` means the model can decide to call one or more of the
      provided tools. 

      - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the
      model to use the named function.
    union:
      - literal<"none">
      - literal<"auto">
      - literal<"required">
      - type: root.ToolChoice
    source:
      openapi: ../openapi.yml
    inline: true
  PromptsCallResponse:
    discriminated: false
    union:
      - type: root.PromptCallResponse
      - type: root.PromptCallStreamResponse
    source:
      openapi: ../openapi.yml
",
    },
    "sessions.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "docs": "Sessions are groups of Logs that track sequences of LLM actions.

Sessions enable you to trace through related Logs across different Files. For
example, a Session can contain a Prompt Log recording an LLM generation, a Tool
Log recording a retrieval step, and Evaluator Logs measuring the quality of the
generated text.

Logs within a Session may be nested within each other. When Evaluators are run
for monitoring, the Evaluator Logs are added to the Session that the evaluated
Log is in, nested within the evaluated Log.

",
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "display-name": "Sessions",
          "endpoints": {
            "delete": {
              "auth": true,
              "display-name": "Delete",
              "docs": "Delete the Session with the given ID.",
              "errors": [
                "root.SessionsDeleteRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                },
              ],
              "method": "DELETE",
              "pagination": undefined,
              "path": "/sessions/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Session.",
                  "type": "string",
                },
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "get": {
              "auth": true,
              "display-name": "Get",
              "docs": "Retrieve the Session with the given ID.",
              "errors": [
                "root.SessionsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "logs": [
                        {
                          "id": "id",
                          "prompt": {
                            "created_at": "2024-01-15T09:30:00Z",
                            "id": "id",
                            "inputs": [
                              {
                                "name": "name",
                              },
                            ],
                            "last_used_at": "2024-01-15T09:30:00Z",
                            "model": "model",
                            "name": "name",
                            "status": "uncommitted",
                            "total_logs_count": 1,
                            "updated_at": "2024-01-15T09:30:00Z",
                            "version_id": "version_id",
                            "version_logs_count": 1,
                          },
                        },
                      ],
                      "updated_at": "2024-01-15T09:30:00Z",
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/sessions/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Session.",
                  "type": "string",
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.SessionResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "list": {
              "auth": true,
              "display-name": "List ",
              "docs": "Get a list of Sessions.",
              "errors": [
                "root.SessionsListRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "response": {
                    "body": {
                      "page": 1,
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "id": "id",
                          "logs": [
                            {
                              "id": "id",
                              "prompt": {
                                "created_at": "2024-01-15T09:30:00Z",
                                "id": "id",
                                "inputs": [
                                  {
                                    "name": "name",
                                  },
                                ],
                                "last_used_at": "2024-01-15T09:30:00Z",
                                "model": "model",
                                "name": "name",
                                "status": "uncommitted",
                                "total_logs_count": 1,
                                "updated_at": "2024-01-15T09:30:00Z",
                                "version_id": "version_id",
                                "version_logs_count": 1,
                              },
                            },
                          ],
                          "updated_at": "2024-01-15T09:30:00Z",
                        },
                      ],
                      "size": 1,
                      "total": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/sessions",
              "request": {
                "name": "SessionsListRequest",
                "query-parameters": {
                  "file_id": {
                    "docs": "Unique identifier for File to return Sessions for. Sessions that contain any Logs associated to this File will be returned.",
                    "type": "optional<string>",
                  },
                  "page": {
                    "docs": "Page number for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Sessions to fetch.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 0,
                      "multipleOf": undefined,
                    },
                  },
                  "version_id": {
                    "docs": "Unique identifier for Version to return Sessions for. Sessions that contain any Logs associated to this Version will be returned.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.PaginatedDataSessionResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yml",
          },
        },
      },
      "rawContents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    get:
      path: /sessions/{id}
      method: GET
      auth: true
      docs: Retrieve the Session with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Session.
      display-name: Get
      response:
        docs: Successful Response
        type: root.SessionResponse
      errors:
        - root.SessionsGetRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              id: id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              logs:
                - prompt:
                    id: id
                    name: name
                    version_id: version_id
                    created_at: '2024-01-15T09:30:00Z'
                    updated_at: '2024-01-15T09:30:00Z'
                    status: uncommitted
                    last_used_at: '2024-01-15T09:30:00Z'
                    model: model
                    version_logs_count: 1
                    total_logs_count: 1
                    inputs:
                      - name: name
                  id: id
    delete:
      path: /sessions/{id}
      method: DELETE
      auth: true
      docs: Delete the Session with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Session.
      display-name: Delete
      errors:
        - root.SessionsDeleteRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
    list:
      path: /sessions
      method: GET
      auth: true
      docs: Get a list of Sessions.
      source:
        openapi: ../openapi.yml
      display-name: 'List '
      request:
        name: SessionsListRequest
        query-parameters:
          file_id:
            type: optional<string>
            docs: >-
              Unique identifier for File to return Sessions for. Sessions that
              contain any Logs associated to this File will be returned.
          version_id:
            type: optional<string>
            docs: >-
              Unique identifier for Version to return Sessions for. Sessions
              that contain any Logs associated to this Version will be returned.
          page:
            type: optional<integer>
            docs: Page number for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Sessions to fetch.
            validation:
              min: 0
      response:
        docs: Successful Response
        type: root.PaginatedDataSessionResponse
      errors:
        - root.SessionsListRequestUnprocessableEntityError
      examples:
        - response:
            body:
              records:
                - id: id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  logs:
                    - prompt:
                        id: id
                        name: name
                        version_id: version_id
                        created_at: '2024-01-15T09:30:00Z'
                        updated_at: '2024-01-15T09:30:00Z'
                        status: uncommitted
                        last_used_at: '2024-01-15T09:30:00Z'
                        model: model
                        version_logs_count: 1
                        total_logs_count: 1
                        inputs:
                          - name: name
                      id: id
              page: 1
              size: 1
              total: 1
  source:
    openapi: ../openapi.yml
  display-name: Sessions
docs: >+
  Sessions are groups of Logs that track sequences of LLM actions.


  Sessions enable you to trace through related Logs across different Files. For

  example, a Session can contain a Prompt Log recording an LLM generation, a
  Tool

  Log recording a retrieval step, and Evaluator Logs measuring the quality of
  the

  generated text.


  Logs within a Session may be nested within each other. When Evaluators are run

  for monitoring, the Evaluator Logs are added to the Session that the evaluated

  Log is in, nested within the evaluated Log.

",
    },
    "tools.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "endpoints": {
            "commit": {
              "auth": true,
              "display-name": "Commit",
              "docs": "Commit the Tool Version with the given ID.",
              "errors": [
                "root.ToolsCommitRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "request": {
                    "commit_message": "commit_message",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/tools/{id}/versions/{version_id}/commit",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Tool.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Tool.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "type": "root.CommitRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ToolResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "create": {
              "auth": true,
              "display-name": "Create Tool",
              "docs": "Create a Tool.

Tools have immutable versions. When you call this endpoint
with the same Tool name but different parameters, a new version of
the Tool will be created.

If you provide a commit message, then the new version will be committed;
otherwise it will be uncommitted. If you try to commit an already committed version,
an exception will be raised.",
              "errors": [
                "root.ToolsCreateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "request": {},
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/tools",
              "request": {
                "body": {
                  "properties": {
                    "commit_message": {
                      "docs": "Message describing the changes made.",
                      "type": "optional<string>",
                    },
                    "directory_id": {
                      "docs": "Unique identifier for the Directory of the Prompt. ",
                      "type": "optional<string>",
                    },
                    "function": {
                      "docs": "Callable function specification of the Tool shown to the model for tool calling.",
                      "type": "optional<root.ToolFunction>",
                    },
                    "name": {
                      "docs": "Name of the Tool, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                    "setup_values": {
                      "docs": "Values needed to setup the Tool, defined in JSON Schema format: https://json-schema.org/",
                      "type": "optional<map<string, unknown>>",
                    },
                    "source_code": {
                      "docs": "Code source of the Tool.",
                      "type": "optional<string>",
                    },
                    "tool_type": {
                      "docs": "Type of Tool.",
                      "type": "optional<root.ToolType>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "ToolRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ToolResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "delete": {
              "auth": true,
              "display-name": "Delete Tool",
              "docs": "Delete the Tool with the given ID.",
              "errors": [
                "root.ToolsDeleteRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                },
              ],
              "method": "DELETE",
              "pagination": undefined,
              "path": "/tools/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Tool.",
                  "type": "string",
                },
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "deploy": {
              "auth": true,
              "display-name": "Deploy",
              "docs": "Deploy Tool to Environment.

Set the deployed Version for the specified Environment. This Tool Version
will be used for calls made to the Tool in this Environment.",
              "errors": [
                "root.DeployToolsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                    "version_id": "version_id",
                  },
                  "query-parameters": {
                    "environment_id": "environment_id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/tools/{id}/versions/{version_id}/deploy",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Tool.",
                  "type": "string",
                },
                "version_id": {
                  "docs": "Unique identifier for the specific version of the Tool.",
                  "type": "string",
                },
              },
              "request": {
                "name": "DeployToolsIdVersionsVersionIdDeployPostRequest",
                "query-parameters": {
                  "environment_id": {
                    "docs": "Unique identifier for the Environment to deploy the Version to.",
                    "type": "string",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ToolResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "get": {
              "auth": true,
              "display-name": "Get Tool",
              "docs": "Retrieve the Tool with the given ID.

By default the deployed version of the Tool is returned. Use the query parameters
`version_id` or `environment` to target a specific version of the Tool.",
              "errors": [
                "root.ToolsGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/tools/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Tool.",
                  "type": "string",
                },
              },
              "request": {
                "name": "ToolsGetRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag to retrieve a deployed Version from.",
                    "type": "optional<string>",
                  },
                  "version_id": {
                    "docs": "A specific Version Id  of the Tool to retrieve.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ToolResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "list": {
              "auth": true,
              "display-name": "List ",
              "docs": "Get a list of Tools.",
              "errors": [
                "root.ToolsListRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "response": {
                    "body": {
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "id": "id",
                          "inputs": [
                            {
                              "name": "name",
                            },
                          ],
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "name": "name",
                          "status": "uncommitted",
                          "total_logs_count": 1,
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                          "version_logs_count": 1,
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/tools",
              "request": {
                "name": "ToolsListRequest",
                "query-parameters": {
                  "name": {
                    "docs": "Case-insensitive filter for Tool name.",
                    "type": "optional<string>",
                  },
                  "order": {
                    "docs": "Direction to sort by.",
                    "type": "optional<root.SortOrder>",
                  },
                  "page": {
                    "docs": "Page offset for pagination.",
                    "type": "optional<integer>",
                    "validation": {
                      "exclusiveMax": undefined,
                      "exclusiveMin": undefined,
                      "max": undefined,
                      "min": 1,
                      "multipleOf": undefined,
                    },
                  },
                  "size": {
                    "docs": "Page size for pagination. Number of Tools to fetch.",
                    "type": "optional<integer>",
                  },
                  "sort_by": {
                    "docs": "Field to sort Tools by",
                    "type": "optional<root.ProjectSortBy>",
                  },
                  "user_filter": {
                    "docs": "Case-insensitive filter for users in the Tool. This filter matches against both email address and name of users.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ListTools",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listTemplates": {
              "auth": true,
              "display-name": "List Templates",
              "docs": undefined,
              "errors": [
                "root.ListTemplatesToolsTemplatesGetRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "response": {
                    "body": [
                      {
                        "description": "description",
                        "name": "name",
                      },
                    ],
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/tools/templates",
              "request": {
                "name": "ListTemplatesToolsTemplatesGetRequest",
                "query-parameters": {
                  "tool_type": {
                    "docs": "Type of tool to return the template",
                    "type": "optional<root.ToolType>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "list<root.ToolTemplateResponse>",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "listversions": {
              "auth": true,
              "display-name": "List Versions",
              "docs": "Get a list of all the versions of a Tool.",
              "errors": [
                "root.ToolsListVersionsRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "records": [
                        {
                          "created_at": "2024-01-15T09:30:00Z",
                          "id": "id",
                          "inputs": [
                            {
                              "name": "name",
                            },
                          ],
                          "last_used_at": "2024-01-15T09:30:00Z",
                          "name": "name",
                          "status": "uncommitted",
                          "total_logs_count": 1,
                          "updated_at": "2024-01-15T09:30:00Z",
                          "version_id": "version_id",
                          "version_logs_count": 1,
                        },
                      ],
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/tools/{id}/versions",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for the Tool.",
                  "type": "string",
                },
              },
              "request": {
                "name": "ToolsListVersionsRequest",
                "query-parameters": {
                  "environment": {
                    "docs": "Filter versions by environment tag. If no environment is provided, all versions are returned.",
                    "type": "optional<string>",
                  },
                  "evaluation_aggregates": "optional<boolean>",
                  "status": {
                    "docs": "Filter versions by status: 'uncommitted', 'committed'. If no status is provided, all versions are returned.",
                    "type": "optional<root.VersionStatus>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ListTools",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "log": {
              "auth": true,
              "display-name": "Log",
              "docs": "Log to a Tool.

You can use query parameters version_id, or environment, to target
an existing version of the Tool. Otherwise the default deployed version will be chosen.

Instead of targeting an existing version explicitly, you can instead pass in
Tool details in the request body. In this case, we will check if the details correspond
to an existing version of the Tool, if not we will create a new version. This is helpful
in the case where you are storing or deriving your Tool details in code.",
              "errors": [
                "root.ToolsLogRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "id": "id",
                      "tool_id": "tool_id",
                      "version_id": "version_id",
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/tools/{id}/log",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Tool.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "batches": {
                      "docs": "Array of Batch Ids that this log is part of. Batches are used to group Logs together for offline Evaluations",
                      "type": "optional<list<string>>",
                    },
                    "created_at": {
                      "docs": "User defined timestamp for when the log was created. ",
                      "type": "optional<datetime>",
                    },
                    "environment": {
                      "docs": "The name of the Environment the Log is associated to.",
                      "name": "toolLogRequestEnvironment",
                      "type": "optional<string>",
                    },
                    "error": {
                      "docs": "Error message if the log is an error.",
                      "type": "optional<string>",
                    },
                    "inputs": {
                      "docs": "The inputs passed to the prompt template.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "metadata": {
                      "docs": "Any additional metadata to record.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "output": {
                      "docs": "Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.",
                      "type": "optional<string>",
                    },
                    "parent_id": {
                      "docs": "Unique identifier for the parent Log in a Session. Should only be provided if `session_id` is provided. If provided, the Log will be nested under the parent Log within the Session.",
                      "type": "optional<string>",
                    },
                    "provider_latency": {
                      "docs": "Duration of the logged event in seconds.",
                      "type": "optional<double>",
                    },
                    "provider_request": {
                      "docs": "Raw request sent to provider.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "provider_response": {
                      "docs": "Raw response received the provider.",
                      "type": "optional<map<string, unknown>>",
                    },
                    "raw_output": {
                      "docs": "Raw output from the provider.",
                      "type": "optional<string>",
                    },
                    "save": {
                      "default": true,
                      "docs": "Whether the request/response payloads will be stored on Humanloop.",
                      "type": "optional<boolean>",
                    },
                    "session_id": {
                      "docs": "Unique identifier for the Session to associate the Log to. Allows you to record multiple Logs to a Session (using an ID kept by your internal systems) by passing the same `session_id` in subsequent log requests. ",
                      "type": "optional<string>",
                    },
                    "source": {
                      "docs": "Identifies where the model was called from.",
                      "type": "optional<string>",
                    },
                    "source_datapoint_id": {
                      "docs": "Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.",
                      "type": "optional<string>",
                    },
                    "tool": {
                      "docs": "Details of your Tool. A new Tool version will be created if the provided details are new.",
                      "type": "optional<root.ToolKernelRequest>",
                    },
                    "user": {
                      "docs": "End-user ID related to the Log.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "ToolLogRequest",
                "path-parameters": undefined,
                "query-parameters": {
                  "environment": {
                    "docs": "An environment tag of the deployed version to log to.",
                    "type": "optional<string>",
                  },
                  "version_id": {
                    "docs": "A specific version Id of the Tool to log to.",
                    "type": "optional<string>",
                  },
                },
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.CreateToolLogResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "update": {
              "auth": true,
              "display-name": "Update Tool",
              "docs": "Update the Tool with the given ID.",
              "errors": [
                "root.ToolsUpdateRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "PATCH",
              "pagination": undefined,
              "path": "/tools/{id}",
              "path-parameters": {
                "id": {
                  "docs": "Unique identifier for Tool.",
                  "type": "string",
                },
              },
              "request": {
                "body": {
                  "properties": {
                    "directory_id": {
                      "docs": "Unique identifier for the Directory of the Prompt. ",
                      "type": "optional<string>",
                    },
                    "name": {
                      "docs": "Name of the Tool, which is used as a unique identifier.",
                      "type": "optional<string>",
                    },
                  },
                },
                "content-type": "application/json",
                "headers": undefined,
                "name": "UpdateToolRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ToolResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
            "updateEvaluators": {
              "auth": true,
              "display-name": "Update Evaluators",
              "docs": "Activate and deactivate Evaluators for the Tool.

An activated Evaluator will automatically be run on all new Logs
within the Tool for monitoring purposes.",
              "errors": [
                "root.UpdateEvaluatorsToolsIdEvaluatorsPostRequestUnprocessableEntityError",
              ],
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "request": {},
                  "response": {
                    "body": {
                      "created_at": "2024-01-15T09:30:00Z",
                      "id": "id",
                      "inputs": [
                        {
                          "name": "name",
                        },
                      ],
                      "last_used_at": "2024-01-15T09:30:00Z",
                      "name": "name",
                      "status": "uncommitted",
                      "total_logs_count": 1,
                      "updated_at": "2024-01-15T09:30:00Z",
                      "version_id": "version_id",
                      "version_logs_count": 1,
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/tools/{id}/evaluators",
              "path-parameters": {
                "id": "string",
              },
              "request": {
                "body": {
                  "type": "root.EvaluatorActivationDeactivationRequest",
                },
                "content-type": "application/json",
              },
              "response": {
                "docs": "Successful Response",
                "type": "root.ToolResponse",
              },
              "source": {
                "openapi": "../openapi.yml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yml",
          },
        },
      },
      "rawContents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    list:
      path: /tools
      method: GET
      auth: true
      docs: Get a list of Tools.
      source:
        openapi: ../openapi.yml
      display-name: 'List '
      request:
        name: ToolsListRequest
        query-parameters:
          page:
            type: optional<integer>
            docs: Page offset for pagination.
            validation:
              min: 1
          size:
            type: optional<integer>
            docs: Page size for pagination. Number of Tools to fetch.
          name:
            type: optional<string>
            docs: Case-insensitive filter for Tool name.
          user_filter:
            type: optional<string>
            docs: >-
              Case-insensitive filter for users in the Tool. This filter matches
              against both email address and name of users.
          sort_by:
            type: optional<root.ProjectSortBy>
            docs: Field to sort Tools by
          order:
            type: optional<root.SortOrder>
            docs: Direction to sort by.
      response:
        docs: Successful Response
        type: root.ListTools
      errors:
        - root.ToolsListRequestUnprocessableEntityError
      examples:
        - response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  version_logs_count: 1
                  total_logs_count: 1
                  inputs:
                    - name: name
    create:
      path: /tools
      method: POST
      auth: true
      docs: >-
        Create a Tool.


        Tools have immutable versions. When you call this endpoint

        with the same Tool name but different parameters, a new version of

        the Tool will be created.


        If you provide a commit message, then the new version will be committed;

        otherwise it will be uncommitted. If you try to commit an already
        committed version,

        an exception will be raised.
      source:
        openapi: ../openapi.yml
      display-name: Create Tool
      request:
        name: ToolRequest
        body:
          properties:
            function:
              type: optional<root.ToolFunction>
              docs: >-
                Callable function specification of the Tool shown to the model
                for tool calling.
            source_code:
              type: optional<string>
              docs: Code source of the Tool.
            setup_values:
              type: optional<map<string, unknown>>
              docs: >-
                Values needed to setup the Tool, defined in JSON Schema format:
                https://json-schema.org/
            name:
              type: optional<string>
              docs: Name of the Tool, which is used as a unique identifier.
            directory_id:
              type: optional<string>
              docs: 'Unique identifier for the Directory of the Prompt. '
            tool_type:
              type: optional<root.ToolType>
              docs: Type of Tool.
            commit_message:
              type: optional<string>
              docs: Message describing the changes made.
        content-type: application/json
      response:
        docs: Successful Response
        type: root.ToolResponse
      errors:
        - root.ToolsCreateRequestUnprocessableEntityError
      examples:
        - request: {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    get:
      path: /tools/{id}
      method: GET
      auth: true
      docs: >-
        Retrieve the Tool with the given ID.


        By default the deployed version of the Tool is returned. Use the query
        parameters

        `version_id` or `environment` to target a specific version of the Tool.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Tool.
      display-name: Get Tool
      request:
        name: ToolsGetRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific Version Id  of the Tool to retrieve.
          environment:
            type: optional<string>
            docs: An environment tag to retrieve a deployed Version from.
      response:
        docs: Successful Response
        type: root.ToolResponse
      errors:
        - root.ToolsGetRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    delete:
      path: /tools/{id}
      method: DELETE
      auth: true
      docs: Delete the Tool with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Tool.
      display-name: Delete Tool
      errors:
        - root.ToolsDeleteRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
    update:
      path: /tools/{id}
      method: PATCH
      auth: true
      docs: Update the Tool with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Tool.
      display-name: Update Tool
      request:
        name: UpdateToolRequest
        body:
          properties:
            name:
              type: optional<string>
              docs: Name of the Tool, which is used as a unique identifier.
            directory_id:
              type: optional<string>
              docs: 'Unique identifier for the Directory of the Prompt. '
        content-type: application/json
      response:
        docs: Successful Response
        type: root.ToolResponse
      errors:
        - root.ToolsUpdateRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    listversions:
      path: /tools/{id}/versions
      method: GET
      auth: true
      docs: Get a list of all the versions of a Tool.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for the Tool.
      display-name: List Versions
      request:
        name: ToolsListVersionsRequest
        query-parameters:
          status:
            type: optional<root.VersionStatus>
            docs: >-
              Filter versions by status: 'uncommitted', 'committed'. If no
              status is provided, all versions are returned.
          environment:
            type: optional<string>
            docs: >-
              Filter versions by environment tag. If no environment is provided,
              all versions are returned.
          evaluation_aggregates: optional<boolean>
      response:
        docs: Successful Response
        type: root.ListTools
      errors:
        - root.ToolsListVersionsRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          response:
            body:
              records:
                - id: id
                  name: name
                  version_id: version_id
                  created_at: '2024-01-15T09:30:00Z'
                  updated_at: '2024-01-15T09:30:00Z'
                  status: uncommitted
                  last_used_at: '2024-01-15T09:30:00Z'
                  version_logs_count: 1
                  total_logs_count: 1
                  inputs:
                    - name: name
    deploy:
      path: /tools/{id}/versions/{version_id}/deploy
      method: POST
      auth: true
      docs: >-
        Deploy Tool to Environment.


        Set the deployed Version for the specified Environment. This Tool
        Version

        will be used for calls made to the Tool in this Environment.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Tool.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Tool.
      display-name: Deploy
      request:
        name: DeployToolsIdVersionsVersionIdDeployPostRequest
        query-parameters:
          environment_id:
            type: string
            docs: Unique identifier for the Environment to deploy the Version to.
      response:
        docs: Successful Response
        type: root.ToolResponse
      errors:
        - >-
          root.DeployToolsIdVersionsVersionIdDeployPostRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          query-parameters:
            environment_id: environment_id
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    commit:
      path: /tools/{id}/versions/{version_id}/commit
      method: POST
      auth: true
      docs: Commit the Tool Version with the given ID.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Tool.
        version_id:
          type: string
          docs: Unique identifier for the specific version of the Tool.
      display-name: Commit
      request:
        body:
          type: root.CommitRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.ToolResponse
      errors:
        - root.ToolsCommitRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
            version_id: version_id
          request:
            commit_message: commit_message
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    log:
      path: /tools/{id}/log
      method: POST
      auth: true
      docs: >-
        Log to a Tool.


        You can use query parameters version_id, or environment, to target

        an existing version of the Tool. Otherwise the default deployed version
        will be chosen.


        Instead of targeting an existing version explicitly, you can instead
        pass in

        Tool details in the request body. In this case, we will check if the
        details correspond

        to an existing version of the Tool, if not we will create a new version.
        This is helpful

        in the case where you are storing or deriving your Tool details in code.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id:
          type: string
          docs: Unique identifier for Tool.
      display-name: Log
      request:
        name: ToolLogRequest
        query-parameters:
          version_id:
            type: optional<string>
            docs: A specific version Id of the Tool to log to.
          environment:
            type: optional<string>
            docs: An environment tag of the deployed version to log to.
        body:
          properties:
            output:
              type: optional<string>
              docs: >-
                Generated output from your model for the provided inputs. Can be
                `None` if logging an error, or if creating a parent Log with the
                intention to populate it later.
            raw_output:
              type: optional<string>
              docs: Raw output from the provider.
            created_at:
              type: optional<datetime>
              docs: 'User defined timestamp for when the log was created. '
            error:
              type: optional<string>
              docs: Error message if the log is an error.
            provider_latency:
              type: optional<double>
              docs: Duration of the logged event in seconds.
            provider_request:
              type: optional<map<string, unknown>>
              docs: Raw request sent to provider.
            provider_response:
              type: optional<map<string, unknown>>
              docs: Raw response received the provider.
            session_id:
              type: optional<string>
              docs: >-
                Unique identifier for the Session to associate the Log to.
                Allows you to record multiple Logs to a Session (using an ID
                kept by your internal systems) by passing the same `session_id`
                in subsequent log requests. 
            parent_id:
              type: optional<string>
              docs: >-
                Unique identifier for the parent Log in a Session. Should only
                be provided if `session_id` is provided. If provided, the Log
                will be nested under the parent Log within the Session.
            inputs:
              type: optional<map<string, unknown>>
              docs: The inputs passed to the prompt template.
            source:
              type: optional<string>
              docs: Identifies where the model was called from.
            metadata:
              type: optional<map<string, unknown>>
              docs: Any additional metadata to record.
            save:
              type: optional<boolean>
              docs: >-
                Whether the request/response payloads will be stored on
                Humanloop.
              default: true
            source_datapoint_id:
              type: optional<string>
              docs: >-
                Unique identifier for the Datapoint that this Log is derived
                from. This can be used by Humanloop to associate Logs to
                Evaluations. If provided, Humanloop will automatically associate
                this Log to Evaluations that require a Log for this
                Datapoint-Version pair.
            batches:
              type: optional<list<string>>
              docs: >-
                Array of Batch Ids that this log is part of. Batches are used to
                group Logs together for offline Evaluations
            user:
              type: optional<string>
              docs: End-user ID related to the Log.
            environment:
              type: optional<string>
              docs: The name of the Environment the Log is associated to.
              name: toolLogRequestEnvironment
            tool:
              type: optional<root.ToolKernelRequest>
              docs: >-
                Details of your Tool. A new Tool version will be created if the
                provided details are new.
        content-type: application/json
      response:
        docs: Successful Response
        type: root.CreateToolLogResponse
      errors:
        - root.ToolsLogRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              tool_id: tool_id
              version_id: version_id
    updateEvaluators:
      path: /tools/{id}/evaluators
      method: POST
      auth: true
      docs: |-
        Activate and deactivate Evaluators for the Tool.

        An activated Evaluator will automatically be run on all new Logs
        within the Tool for monitoring purposes.
      source:
        openapi: ../openapi.yml
      path-parameters:
        id: string
      display-name: Update Evaluators
      request:
        body:
          type: root.EvaluatorActivationDeactivationRequest
        content-type: application/json
      response:
        docs: Successful Response
        type: root.ToolResponse
      errors:
        - >-
          root.UpdateEvaluatorsToolsIdEvaluatorsPostRequestUnprocessableEntityError
      examples:
        - path-parameters:
            id: id
          request: {}
          response:
            body:
              id: id
              name: name
              version_id: version_id
              created_at: '2024-01-15T09:30:00Z'
              updated_at: '2024-01-15T09:30:00Z'
              status: uncommitted
              last_used_at: '2024-01-15T09:30:00Z'
              version_logs_count: 1
              total_logs_count: 1
              inputs:
                - name: name
    listTemplates:
      path: /tools/templates
      method: GET
      auth: true
      source:
        openapi: ../openapi.yml
      display-name: List Templates
      request:
        name: ListTemplatesToolsTemplatesGetRequest
        query-parameters:
          tool_type:
            type: optional<root.ToolType>
            docs: Type of tool to return the template
      response:
        docs: Successful Response
        type: list<root.ToolTemplateResponse>
      errors:
        - root.ListTemplatesToolsTemplatesGetRequestUnprocessableEntityError
      examples:
        - response:
            body:
              - name: name
                description: description
  source:
    openapi: ../openapi.yml
",
    },
  },
  "packageMarkers": {},
  "rootApiFile": {
    "contents": {
      "auth": "APIKeyHeader",
      "auth-schemes": {
        "APIKeyHeader": {
          "header": "X-API-KEY",
          "name": "apiKey",
          "type": "string",
        },
      },
      "default-environment": "Default",
      "display-name": "Humanloop API",
      "environments": {
        "Default": "https://api.humanloop.com/v5",
      },
      "error-discrimination": {
        "strategy": "status-code",
      },
      "name": "api",
    },
    "defaultUrl": undefined,
    "rawContents": "name: api
error-discrimination:
  strategy: status-code
display-name: Humanloop API
environments:
  Default: https://api.humanloop.com/v5
default-environment: Default
auth-schemes:
  APIKeyHeader:
    header: X-API-KEY
    name: apiKey
    type: string
auth: APIKeyHeader
",
  },
}