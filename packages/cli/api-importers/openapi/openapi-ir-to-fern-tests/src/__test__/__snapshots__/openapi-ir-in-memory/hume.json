{
  "type": "openapi",
  "value": {
    "openapi": "3.0.0",
    "info": {
      "title": "Hume AI Batch API",
      "description": "The Batch API provides access to Hume models through an asynchronous job-based interface. You can submit a job to have many different files processed in parallel. The status of a job can then be checked with the job ID. Email notifications are available to alert on completed jobs.",
      "version": "0.1.0"
    },
    "servers": [
      {
        "url": "https://api.hume.ai"
      }
    ],
    "tags": [
      {
        "name": "Start Job"
      },
      {
        "name": "Get Job Predictions"
      },
      {
        "name": "List Jobs"
      }
    ],
    "paths": {
      "/v0/batch/jobs": {
        "post": {
          "tags": [
            "Start Job"
          ],
          "summary": "Start Job",
          "description": "Start a new batch job.",
          "requestBody": {
            "content": {
              "multipart/form-data": {
                "schema": {
                  "type": "object",
                  "required": [
                    "file"
                  ],
                  "properties": {
                    "json": {
                      "allOf": [
                        {
                          "$ref": "#/components/schemas/BaseRequest"
                        },
                        {
                          "default": {
                            "callback_url": null,
                            "models": {
                              "burst": {},
                              "face": {
                                "descriptions": null,
                                "facs": null,
                                "fps_pred": 3,
                                "identify_faces": false,
                                "min_face_size": 60,
                                "prob_threshold": 0.99,
                                "save_faces": false
                              },
                              "facemesh": {},
                              "language": {
                                "granularity": "word",
                                "identify_speakers": false,
                                "sentiment": null,
                                "toxicity": null
                              },
                              "ner": {
                                "identify_speakers": false
                              },
                              "prosody": {
                                "granularity": "utterance",
                                "identify_speakers": false,
                                "window": null
                              }
                            },
                            "notify": false,
                            "urls": []
                          }
                        }
                      ]
                    },
                    "file": {
                      "type": "array",
                      "description": "Local media files (see recommended input filetypes) to be processed.\n\nIf you wish to supply more than 100 files, consider providing them as an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`).",
                      "items": {
                        "type": "string",
                        "format": "binary"
                      },
                      "maxItems": 100
                    }
                  }
                }
              },
              "application/json; charset=utf-8": {
                "schema": {
                  "$ref": "#/components/schemas/BaseRequest"
                }
              }
            },
            "required": true
          },
          "responses": {
            "200": {
              "description": "",
              "content": {
                "application/json; charset=utf-8": {
                  "schema": {
                    "$ref": "#/components/schemas/JobId"
                  }
                }
              }
            }
          },
          "security": [
            {
              "Authentication": []
            }
          ],
          "operationId": "start_job"
        },
        "get": {
          "tags": [
            "List Jobs"
          ],
          "summary": "List Jobs",
          "description": "Sort and filter jobs.",
          "parameters": [
            {
              "name": "limit",
              "schema": {
                "type": "integer",
                "format": "uint16",
                "default": 50
              },
              "in": "query",
              "description": "The maximum number of jobs to include in the response.",
              "required": false,
              "deprecated": false,
              "explode": true
            },
            {
              "name": "status",
              "schema": {
                "type": "array",
                "default": [
                  "FAILED",
                  "COMPLETED",
                  "IN_PROGRESS",
                  "QUEUED"
                ],
                "items": {
                  "$ref": "#/components/schemas/Status"
                }
              },
              "in": "query",
              "description": "Include only jobs with these statuses.",
              "required": false,
              "deprecated": false,
              "explode": true
            },
            {
              "name": "when",
              "schema": {
                "allOf": [
                  {
                    "$ref": "#/components/schemas/When"
                  },
                  {
                    "default": "created_before"
                  }
                ]
              },
              "in": "query",
              "description": "Include only jobs that were created before or after `timestamp_ms`.",
              "required": false,
              "deprecated": false,
              "explode": true
            },
            {
              "name": "timestamp_ms",
              "schema": {
                "type": "integer",
                "format": "int64",
                "default": null
              },
              "in": "query",
              "description": "Defaults to the current date and time. See `when`.",
              "required": false,
              "deprecated": false,
              "explode": true
            },
            {
              "name": "sort_by",
              "schema": {
                "allOf": [
                  {
                    "$ref": "#/components/schemas/SortBy"
                  },
                  {
                    "default": "created"
                  }
                ]
              },
              "in": "query",
              "description": "The job timestamp to sort by.",
              "required": false,
              "deprecated": false,
              "explode": true
            },
            {
              "name": "direction",
              "schema": {
                "allOf": [
                  {
                    "$ref": "#/components/schemas/Direction"
                  },
                  {
                    "default": "asc"
                  }
                ]
              },
              "in": "query",
              "description": "The sort direction.",
              "required": false,
              "deprecated": false,
              "explode": true
            }
          ],
          "responses": {
            "200": {
              "description": "",
              "content": {
                "application/json; charset=utf-8": {
                  "schema": {
                    "type": "array",
                    "items": {
                      "$ref": "#/components/schemas/Job_Request"
                    }
                  }
                }
              }
            }
          },
          "security": [
            {
              "Authentication": []
            }
          ],
          "operationId": "list_jobs"
        }
      },
      "/v0/batch/jobs/{id}/predictions": {
        "get": {
          "tags": [
            "Get Job Predictions"
          ],
          "summary": "Get Job Predictions",
          "description": "Get the JSON predictions of a completed job.",
          "parameters": [
            {
              "name": "id",
              "schema": {
                "type": "string",
                "format": "uuid"
              },
              "in": "path",
              "required": true,
              "deprecated": false,
              "explode": true
            }
          ],
          "responses": {
            "200": {
              "description": "",
              "content": {
                "application/json; charset=utf-8": {
                  "schema": {
                    "type": "array",
                    "items": {
                      "$ref": "#/components/schemas/SourceResult"
                    }
                  }
                }
              }
            }
          },
          "security": [
            {
              "Authentication": []
            }
          ],
          "operationId": "get_job_predictions"
        }
      },
      "/v0/batch/jobs/{id}/artifacts": {
        "get": {
          "tags": [
            "Get Job Predictions"
          ],
          "summary": "Get Job Artifacts",
          "description": "Get the artifacts ZIP of a completed job.",
          "parameters": [
            {
              "name": "id",
              "schema": {
                "type": "string",
                "format": "uuid"
              },
              "in": "path",
              "required": true,
              "deprecated": false,
              "explode": true
            }
          ],
          "responses": {
            "200": {
              "description": "",
              "content": {
                "application/octet-stream": {
                  "schema": {
                    "type": "string",
                    "format": "binary"
                  }
                }
              },
              "headers": {
                "Content-Disposition": {
                  "description": "Indicate if the content is expected to be displayed inline in the browser, that is, as a Web page or as part of a Web page, or as an attachment, that is downloaded and saved locally.",
                  "required": true,
                  "deprecated": false,
                  "schema": {
                    "type": "string"
                  }
                }
              }
            }
          },
          "security": [
            {
              "Authentication": []
            }
          ],
          "operationId": "get_job_artifacts"
        }
      },
      "/v0/batch/jobs/{id}": {
        "get": {
          "tags": [
            "Get Job Predictions"
          ],
          "summary": "Get Job Details",
          "description": "Get the request details and state of a given job.",
          "parameters": [
            {
              "name": "id",
              "schema": {
                "type": "string",
                "format": "uuid"
              },
              "in": "path",
              "required": true,
              "deprecated": false,
              "explode": true
            }
          ],
          "responses": {
            "200": {
              "description": "",
              "content": {
                "application/json; charset=utf-8": {
                  "schema": {
                    "$ref": "#/components/schemas/Job_Request"
                  }
                }
              }
            }
          },
          "security": [
            {
              "Authentication": []
            }
          ],
          "operationId": "get_job"
        }
      }
    },
    "components": {
      "schemas": {
        "BaseRequest": {
          "type": "object",
          "properties": {
            "models": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Models"
                },
                {
                  "description": "If this field is not explicitly set, then all models will be run by default.",
                  "default": {
                    "burst": {},
                    "face": {
                      "descriptions": null,
                      "facs": null,
                      "fps_pred": 3,
                      "identify_faces": false,
                      "min_face_size": 60,
                      "prob_threshold": 0.99,
                      "save_faces": false
                    },
                    "facemesh": {},
                    "language": {
                      "granularity": "word",
                      "identify_speakers": false,
                      "sentiment": null,
                      "toxicity": null
                    },
                    "ner": {
                      "identify_speakers": false
                    },
                    "prosody": {
                      "granularity": "utterance",
                      "identify_speakers": false,
                      "window": null
                    }
                  }
                }
              ]
            },
            "transcription": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Transcription"
                },
                {
                  "description": "To disable transcription, explicitly set this field to `null`."
                }
              ]
            },
            "urls": {
              "type": "array",
              "description": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`) of media files.\n\nIf you wish to supply more than 100 URLs, consider providing them as an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`).",
              "default": [],
              "items": {
                "type": "string",
                "format": "url"
              },
              "maxItems": 100
            },
            "callback_url": {
              "type": "string",
              "format": "url",
              "description": "If provided, a `POST` request will be made to the URL with the generated predictions on completion or the error message on failure."
            },
            "notify": {
              "type": "boolean",
              "description": "Whether to send an email notification to the user upon job failure.",
              "default": false
            }
          }
        },
        "Bcp47Tag": {
          "type": "string",
          "enum": [
            "zh",
            "da",
            "nl",
            "en",
            "en-AU",
            "en-IN",
            "en-NZ",
            "en-GB",
            "fr",
            "fr-CA",
            "de",
            "hi",
            "hi-Latn",
            "id",
            "it",
            "ja",
            "ko",
            "no",
            "pl",
            "pt",
            "pt-BR",
            "pt-PT",
            "ru",
            "es",
            "es-419",
            "sv",
            "ta",
            "tr",
            "uk"
          ]
        },
        "BoundingBox": {
          "type": "object",
          "description": "A bounding box around a face.",
          "required": [
            "x",
            "y",
            "w",
            "h"
          ],
          "properties": {
            "x": {
              "type": "number",
              "format": "double",
              "description": "x-coordinate of bounding box top left corner."
            },
            "y": {
              "type": "number",
              "format": "double",
              "description": "y-coordinate of bounding box top left corner."
            },
            "w": {
              "type": "number",
              "format": "double",
              "description": "Bounding box width."
            },
            "h": {
              "type": "number",
              "format": "double",
              "description": "Bounding box height."
            }
          }
        },
        "BurstPrediction": {
          "type": "object",
          "required": [
            "time",
            "emotions",
            "descriptions"
          ],
          "properties": {
            "time": {
              "$ref": "#/components/schemas/TimeInterval"
            },
            "emotions": {
              "type": "array",
              "title": "Emotions Scores",
              "description": "A high-dimensional embedding in emotion space.",
              "items": {
                "$ref": "#/components/schemas/EmotionScore"
              }
            },
            "descriptions": {
              "type": "array",
              "title": "Descriptions Scores",
              "description": "Modality-specific descriptive features and their scores.",
              "items": {
                "$ref": "#/components/schemas/DescriptionsScore"
              }
            }
          }
        },
        "Completed": {
          "type": "object",
          "required": [
            "created_timestamp_ms",
            "started_timestamp_ms",
            "ended_timestamp_ms",
            "num_predictions",
            "num_errors"
          ],
          "properties": {
            "created_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job was created (Unix timestamp in milliseconds)."
            },
            "started_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job started (Unix timestamp in milliseconds)."
            },
            "ended_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job ended (Unix timestamp in milliseconds)."
            },
            "num_predictions": {
              "type": "integer",
              "format": "int32",
              "description": "The number of predictions that were generated by this job."
            },
            "num_errors": {
              "type": "integer",
              "format": "int32",
              "description": "The number of errors that occurred while running this job."
            }
          }
        },
        "DescriptionsScore": {
          "type": "object",
          "required": [
            "name",
            "score"
          ],
          "properties": {
            "name": {
              "type": "string",
              "description": "Name of the descriptive feature being expressed."
            },
            "score": {
              "type": "string",
              "description": "Embedding value for the descriptive feature being expressed."
            }
          }
        },
        "Direction": {
          "type": "string",
          "enum": [
            "asc",
            "desc"
          ]
        },
        "EmotionScore": {
          "type": "object",
          "required": [
            "name",
            "score"
          ],
          "properties": {
            "name": {
              "type": "string",
              "description": "Name of the emotion being expressed."
            },
            "score": {
              "type": "string",
              "description": "Embedding value for the emotion being expressed."
            }
          }
        },
        "Empty": {
          "type": "object",
          "description": "To include predictions for this model type, set this field to `{}`. It is currently not configurable further."
        },
        "Error": {
          "type": "object",
          "required": [
            "message",
            "file"
          ],
          "properties": {
            "message": {
              "type": "string",
              "title": "Error Message",
              "description": "An error message."
            },
            "file": {
              "type": "string",
              "title": "File",
              "description": "A file path relative to the top level source URL or file."
            }
          }
        },
        "Face": {
          "type": "object",
          "properties": {
            "fps_pred": {
              "type": "number",
              "format": "double",
              "description": "Number of frames per second to process. Other frames will be omitted from the response. Set to `0` to process every frame.",
              "default": 3
            },
            "prob_threshold": {
              "type": "number",
              "format": "double",
              "description": "Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response.",
              "default": 0.99,
              "maximum": 1,
              "minimum": 0
            },
            "identify_faces": {
              "type": "boolean",
              "description": "Whether to return identifiers for faces across frames. If `true`, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If `false`, all faces will be tagged with an `unknown` ID.",
              "default": false
            },
            "min_face_size": {
              "type": "integer",
              "format": "uint64",
              "description": "Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response.",
              "default": 60
            },
            "facs": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Empty"
                },
                {
                  "default": null
                }
              ]
            },
            "descriptions": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Empty"
                },
                {
                  "default": null
                }
              ]
            },
            "save_faces": {
              "type": "boolean",
              "description": "Whether to extract and save the detected faces in the artifacts zip created by each job.",
              "default": false
            }
          }
        },
        "FacePrediction": {
          "type": "object",
          "required": [
            "frame",
            "time",
            "prob",
            "box",
            "emotions"
          ],
          "properties": {
            "frame": {
              "type": "integer",
              "format": "uint64",
              "description": "Frame number"
            },
            "time": {
              "type": "number",
              "format": "double",
              "description": "Time in seconds when face detection occurred."
            },
            "prob": {
              "type": "number",
              "format": "double",
              "description": "The predicted probability that a detected face was actually a face."
            },
            "box": {
              "$ref": "#/components/schemas/BoundingBox"
            },
            "emotions": {
              "type": "array",
              "title": "Emotions Scores",
              "description": "A high-dimensional embedding in emotion space.",
              "items": {
                "$ref": "#/components/schemas/EmotionScore"
              }
            },
            "facs": {
              "type": "array",
              "title": "FACS 2.0 Scores",
              "description": "FACS 2.0 features and their scores.",
              "items": {
                "$ref": "#/components/schemas/FacsScore"
              }
            },
            "descriptions": {
              "type": "array",
              "title": "Descriptions Scores",
              "description": "Modality-specific descriptive features and their scores.",
              "items": {
                "$ref": "#/components/schemas/DescriptionsScore"
              }
            }
          }
        },
        "FacemeshPrediction": {
          "type": "object",
          "required": [
            "emotions"
          ],
          "properties": {
            "emotions": {
              "type": "array",
              "title": "Emotions Scores",
              "description": "A high-dimensional embedding in emotion space.",
              "items": {
                "$ref": "#/components/schemas/EmotionScore"
              }
            }
          }
        },
        "FacsScore": {
          "type": "object",
          "required": [
            "name",
            "score"
          ],
          "properties": {
            "name": {
              "type": "string",
              "description": "Name of the FACS 2.0 feature being expressed."
            },
            "score": {
              "type": "string",
              "description": "Embedding value for the FACS 2.0 feature being expressed."
            }
          }
        },
        "Failed": {
          "type": "object",
          "required": [
            "created_timestamp_ms",
            "started_timestamp_ms",
            "ended_timestamp_ms",
            "message"
          ],
          "properties": {
            "created_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job was created (Unix timestamp in milliseconds)."
            },
            "started_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job started (Unix timestamp in milliseconds)."
            },
            "ended_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job ended (Unix timestamp in milliseconds)."
            },
            "message": {
              "type": "string",
              "title": "Error Message",
              "description": "An error message."
            }
          }
        },
        "File": {
          "type": "object",
          "required": [
            "md5sum"
          ],
          "properties": {
            "filename": {
              "type": "string",
              "description": "The name of the file."
            },
            "content_type": {
              "type": "string",
              "description": "The content type of the file."
            },
            "md5sum": {
              "type": "string",
              "description": "The MD5 checksum of the file."
            }
          }
        },
        "Granularity": {
          "type": "string",
          "description": "The granularity at which to generate predictions. `utterance` corresponds to a natural pause or break in conversation, while `conversational_turn` corresponds to a change in speaker.",
          "enum": [
            "word",
            "sentence",
            "utterance",
            "conversational_turn"
          ]
        },
        "GroupedPredictions_BurstPrediction": {
          "type": "object",
          "required": [
            "id",
            "predictions"
          ],
          "properties": {
            "id": {
              "type": "string",
              "description": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals."
            },
            "predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/BurstPrediction"
              }
            }
          }
        },
        "GroupedPredictions_FacePrediction": {
          "type": "object",
          "required": [
            "id",
            "predictions"
          ],
          "properties": {
            "id": {
              "type": "string",
              "description": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals."
            },
            "predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/FacePrediction"
              }
            }
          }
        },
        "GroupedPredictions_FacemeshPrediction": {
          "type": "object",
          "required": [
            "id",
            "predictions"
          ],
          "properties": {
            "id": {
              "type": "string",
              "description": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals."
            },
            "predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/FacemeshPrediction"
              }
            }
          }
        },
        "GroupedPredictions_LanguagePrediction": {
          "type": "object",
          "required": [
            "id",
            "predictions"
          ],
          "properties": {
            "id": {
              "type": "string",
              "description": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals."
            },
            "predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/LanguagePrediction"
              }
            }
          }
        },
        "GroupedPredictions_NerPrediction": {
          "type": "object",
          "required": [
            "id",
            "predictions"
          ],
          "properties": {
            "id": {
              "type": "string",
              "description": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals."
            },
            "predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/NerPrediction"
              }
            }
          }
        },
        "GroupedPredictions_ProsodyPrediction": {
          "type": "object",
          "required": [
            "id",
            "predictions"
          ],
          "properties": {
            "id": {
              "type": "string",
              "description": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals."
            },
            "predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/ProsodyPrediction"
              }
            }
          }
        },
        "InProgress": {
          "type": "object",
          "required": [
            "created_timestamp_ms",
            "started_timestamp_ms"
          ],
          "properties": {
            "created_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job was created (Unix timestamp in milliseconds)."
            },
            "started_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job started (Unix timestamp in milliseconds)."
            }
          }
        },
        "Job_Request": {
          "type": "object",
          "required": [
            "user_id",
            "job_id",
            "request",
            "state"
          ],
          "properties": {
            "user_id": {
              "type": "string",
              "format": "uuid",
              "description": "Your user ID."
            },
            "job_id": {
              "type": "string",
              "format": "uuid",
              "description": "The ID associated with this job."
            },
            "request": {
              "$ref": "#/components/schemas/Request"
            },
            "state": {
              "$ref": "#/components/schemas/State"
            }
          }
        },
        "JobId": {
          "type": "object",
          "required": [
            "job_id"
          ],
          "properties": {
            "job_id": {
              "type": "string",
              "format": "uuid",
              "description": "The ID of the started job."
            }
          }
        },
        "Language": {
          "type": "object",
          "properties": {
            "granularity": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Granularity"
                },
                {
                  "default": "word"
                }
              ]
            },
            "identify_speakers": {
              "type": "boolean",
              "title": "Identify Speakers",
              "description": "Whether to return identifiers for speakers over time. If `true`, unique identifiers will be assigned to spoken words to differentiate different speakers. If `false`, all speakers will be tagged with an `unknown` ID.",
              "default": false
            },
            "sentiment": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Empty"
                },
                {
                  "default": null
                }
              ]
            },
            "toxicity": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Empty"
                },
                {
                  "default": null
                }
              ]
            }
          }
        },
        "LanguagePrediction": {
          "type": "object",
          "required": [
            "text",
            "position",
            "emotions"
          ],
          "properties": {
            "text": {
              "type": "string",
              "title": "Text",
              "description": "A segment of text (like a word or a sentence)."
            },
            "position": {
              "$ref": "#/components/schemas/PositionInterval"
            },
            "time": {
              "$ref": "#/components/schemas/TimeInterval"
            },
            "confidence": {
              "type": "number",
              "format": "double",
              "title": "Confidence",
              "description": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence in this text."
            },
            "speaker_confidence": {
              "type": "number",
              "format": "double",
              "title": "Speaker Confidence",
              "description": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence that this text was spoken by this speaker."
            },
            "emotions": {
              "type": "array",
              "title": "Emotions Scores",
              "description": "A high-dimensional embedding in emotion space.",
              "items": {
                "$ref": "#/components/schemas/EmotionScore"
              }
            },
            "sentiment": {
              "type": "array",
              "title": "Sentiment Scores",
              "description": "Sentiment predictions returned as a distribution. This model predicts the probability that a given text could be interpreted as having each sentiment level from `1` (negative) to `9` (positive).\n\nCompared to returning one estimate of sentiment, this enables a more nuanced analysis of a text's meaning. For example, a text with very neutral sentiment would have an average rating of `5`. But also a text that could be interpreted as having very positive sentiment or very negative sentiment would also have an average rating of `5`. The average sentiment is less informative than the distribution over sentiment, so this API returns a value for each sentiment level.",
              "items": {
                "$ref": "#/components/schemas/SentimentScore"
              }
            },
            "toxicity": {
              "type": "array",
              "title": "Toxicity Scores",
              "description": "Toxicity predictions returned as probabilities that the text can be classified into the following categories: `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`.",
              "items": {
                "$ref": "#/components/schemas/ToxicityScore"
              }
            }
          }
        },
        "Models": {
          "type": "object",
          "properties": {
            "face": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Face"
                },
                {
                  "description": "Facial Expression:\nAnalyzes human facial expressions in images and videos. Results will be provided per frame for video files.\nRecommended input filetypes: `.png`, `.jpeg`, `.mp4`"
                }
              ]
            },
            "burst": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Empty"
                },
                {
                  "description": "Vocal Burst:\nVocal bursts, also called non-verbal exclamations, are any sounds you make that express emotion and aren't words.\nRecommended input filetypes: `.wav`, `.mp3`, `.mp4`"
                }
              ]
            },
            "prosody": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Prosody"
                },
                {
                  "description": "Speech Prosody:\nSpeech prosody includes the intonation, stress, and rhythm of spoken word.\nRecommended input filetypes: `.wav`, `.mp3`, `.mp4`"
                }
              ]
            },
            "language": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Language"
                },
                {
                  "description": "Language:\nAnalyzes passages of text. This also supports audio and video files by transcribing and then directly analyzing the transcribed text.\nRecommended input filetypes: `.txt`, `.mp3`, `.wav`, `.mp4`"
                }
              ]
            },
            "ner": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Ner"
                },
                {
                  "description": "NER (Named-entity Recognition):\nIdentifies real-world objects and concepts in passages of text. This also supports audio and video files by transcribing and then directly analyzing the transcribed text.\nRecommended input filetypes: `.txt`, `.mp3`, `.wav`, `.mp4`"
                }
              ]
            },
            "facemesh": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Empty"
                },
                {
                  "description": "MediaPipe Facemesh:\nProcesses anonymized facial landmarks detected using Google's MediaPipe library\nRecommended input filetypes: `.json`"
                }
              ]
            }
          }
        },
        "ModelsPredictions": {
          "type": "object",
          "properties": {
            "face": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Predictions_optional_Null_FacePrediction"
                },
                {
                  "description": "Response for the facial expression emotion model."
                }
              ]
            },
            "burst": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Predictions_optional_Null_BurstPrediction"
                },
                {
                  "description": "Response for the vocal burst emotion model."
                }
              ]
            },
            "prosody": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Predictions_optional_TranscriptionMetadata_ProsodyPrediction"
                },
                {
                  "description": "Response for the speech prosody emotion model."
                }
              ]
            },
            "language": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Predictions_optional_TranscriptionMetadata_LanguagePrediction"
                },
                {
                  "description": "Response for the language emotion model."
                }
              ]
            },
            "ner": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Predictions_optional_TranscriptionMetadata_NerPrediction"
                },
                {
                  "description": "Response for the NER emotion model."
                }
              ]
            },
            "facemesh": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Predictions_optional_Null_FacemeshPrediction"
                },
                {
                  "description": "Response for the facemesh emotion model."
                }
              ]
            }
          }
        },
        "Ner": {
          "type": "object",
          "properties": {
            "identify_speakers": {
              "type": "boolean",
              "title": "Identify Speakers",
              "description": "Whether to return identifiers for speakers over time. If `true`, unique identifiers will be assigned to spoken words to differentiate different speakers. If `false`, all speakers will be tagged with an `unknown` ID.",
              "default": false
            }
          }
        },
        "NerPrediction": {
          "type": "object",
          "required": [
            "entity",
            "position",
            "entity_confidence",
            "support",
            "uri",
            "link_word",
            "emotions"
          ],
          "properties": {
            "entity": {
              "type": "string",
              "description": "The recognized topic or entity."
            },
            "position": {
              "$ref": "#/components/schemas/PositionInterval"
            },
            "entity_confidence": {
              "type": "number",
              "format": "double",
              "description": "Our NER model's relative confidence in the recognized topic or entity."
            },
            "support": {
              "type": "number",
              "format": "double",
              "description": "A measure of how often the entity is linked to by other entities."
            },
            "uri": {
              "type": "string",
              "description": "A URL which provides more information about the recognized topic or entity."
            },
            "link_word": {
              "type": "string",
              "description": "The specific word to which the emotion predictions are linked."
            },
            "time": {
              "$ref": "#/components/schemas/TimeInterval"
            },
            "confidence": {
              "type": "number",
              "format": "double",
              "title": "Confidence",
              "description": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence in this text."
            },
            "speaker_confidence": {
              "type": "number",
              "format": "double",
              "title": "Speaker Confidence",
              "description": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence that this text was spoken by this speaker."
            },
            "emotions": {
              "type": "array",
              "title": "Emotions Scores",
              "description": "A high-dimensional embedding in emotion space.",
              "items": {
                "$ref": "#/components/schemas/EmotionScore"
              }
            }
          }
        },
        "Null": {
          "type": "object",
          "description": "No associated metadata for this model. Value will be `null`."
        },
        "PositionInterval": {
          "type": "object",
          "description": "Position of a segment of text within a larger document, measured in characters. Uses zero-based indexing. The beginning index is inclusive and the end index is exclusive.",
          "required": [
            "begin",
            "end"
          ],
          "properties": {
            "begin": {
              "type": "integer",
              "format": "uint64",
              "description": "The index of the first character in the text segment, inclusive."
            },
            "end": {
              "type": "integer",
              "format": "uint64",
              "description": "The index of the last character in the text segment, exclusive."
            }
          }
        },
        "Prediction": {
          "type": "object",
          "required": [
            "file",
            "models"
          ],
          "properties": {
            "file": {
              "type": "string",
              "title": "File",
              "description": "A file path relative to the top level source URL or file."
            },
            "models": {
              "$ref": "#/components/schemas/ModelsPredictions"
            }
          }
        },
        "Predictions_optional_Null_BurstPrediction": {
          "type": "object",
          "required": [
            "grouped_predictions"
          ],
          "properties": {
            "metadata": {
              "$ref": "#/components/schemas/Null"
            },
            "grouped_predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/GroupedPredictions_BurstPrediction"
              }
            }
          }
        },
        "Predictions_optional_Null_FacePrediction": {
          "type": "object",
          "required": [
            "grouped_predictions"
          ],
          "properties": {
            "metadata": {
              "$ref": "#/components/schemas/Null"
            },
            "grouped_predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/GroupedPredictions_FacePrediction"
              }
            }
          }
        },
        "Predictions_optional_Null_FacemeshPrediction": {
          "type": "object",
          "required": [
            "grouped_predictions"
          ],
          "properties": {
            "metadata": {
              "$ref": "#/components/schemas/Null"
            },
            "grouped_predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/GroupedPredictions_FacemeshPrediction"
              }
            }
          }
        },
        "Predictions_optional_TranscriptionMetadata_LanguagePrediction": {
          "type": "object",
          "required": [
            "grouped_predictions"
          ],
          "properties": {
            "metadata": {
              "$ref": "#/components/schemas/TranscriptionMetadata"
            },
            "grouped_predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/GroupedPredictions_LanguagePrediction"
              }
            }
          }
        },
        "Predictions_optional_TranscriptionMetadata_NerPrediction": {
          "type": "object",
          "required": [
            "grouped_predictions"
          ],
          "properties": {
            "metadata": {
              "$ref": "#/components/schemas/TranscriptionMetadata"
            },
            "grouped_predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/GroupedPredictions_NerPrediction"
              }
            }
          }
        },
        "Predictions_optional_TranscriptionMetadata_ProsodyPrediction": {
          "type": "object",
          "required": [
            "grouped_predictions"
          ],
          "properties": {
            "metadata": {
              "$ref": "#/components/schemas/TranscriptionMetadata"
            },
            "grouped_predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/GroupedPredictions_ProsodyPrediction"
              }
            }
          }
        },
        "Prosody": {
          "type": "object",
          "description": "NOTE: the `granularity` field is ignored if transcription is not enabled or if the `window` field has been set.",
          "properties": {
            "granularity": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Granularity"
                },
                {
                  "default": "utterance"
                }
              ]
            },
            "identify_speakers": {
              "type": "boolean",
              "title": "Identify Speakers",
              "description": "Whether to return identifiers for speakers over time. If `true`, unique identifiers will be assigned to spoken words to differentiate different speakers. If `false`, all speakers will be tagged with an `unknown` ID.",
              "default": false
            },
            "window": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Window"
                },
                {
                  "default": null
                }
              ]
            }
          }
        },
        "ProsodyPrediction": {
          "type": "object",
          "required": [
            "time",
            "emotions"
          ],
          "properties": {
            "text": {
              "type": "string",
              "title": "Text",
              "description": "A segment of text (like a word or a sentence)."
            },
            "time": {
              "$ref": "#/components/schemas/TimeInterval"
            },
            "confidence": {
              "type": "number",
              "format": "double",
              "title": "Confidence",
              "description": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence in this text."
            },
            "speaker_confidence": {
              "type": "number",
              "format": "double",
              "title": "Speaker Confidence",
              "description": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence that this text was spoken by this speaker."
            },
            "emotions": {
              "type": "array",
              "title": "Emotions Scores",
              "description": "A high-dimensional embedding in emotion space.",
              "items": {
                "$ref": "#/components/schemas/EmotionScore"
              }
            }
          }
        },
        "Queued": {
          "type": "object",
          "required": [
            "created_timestamp_ms"
          ],
          "properties": {
            "created_timestamp_ms": {
              "type": "integer",
              "format": "int64",
              "description": "When this job was created (Unix timestamp in milliseconds)."
            }
          }
        },
        "Request": {
          "type": "object",
          "required": [
            "files"
          ],
          "properties": {
            "models": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Models"
                },
                {
                  "description": "If this field is not explicitly set, then all models will be run by default.",
                  "default": {
                    "burst": {},
                    "face": {
                      "descriptions": null,
                      "facs": null,
                      "fps_pred": 3,
                      "identify_faces": false,
                      "min_face_size": 60,
                      "prob_threshold": 0.99,
                      "save_faces": false
                    },
                    "facemesh": {},
                    "language": {
                      "granularity": "word",
                      "identify_speakers": false,
                      "sentiment": null,
                      "toxicity": null
                    },
                    "ner": {
                      "identify_speakers": false
                    },
                    "prosody": {
                      "granularity": "utterance",
                      "identify_speakers": false,
                      "window": null
                    }
                  }
                }
              ]
            },
            "transcription": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Transcription"
                },
                {
                  "description": "To disable transcription, explicitly set this field to `null`."
                }
              ]
            },
            "urls": {
              "type": "array",
              "description": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`) of media files.\n\nIf you wish to supply more than 100 URLs, consider providing them as an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`).",
              "default": [],
              "items": {
                "type": "string",
                "format": "url"
              },
              "maxItems": 100
            },
            "callback_url": {
              "type": "string",
              "format": "url",
              "description": "If provided, a `POST` request will be made to the URL with the generated predictions on completion or the error message on failure."
            },
            "notify": {
              "type": "boolean",
              "description": "Whether to send an email notification to the user upon job completion/failure.",
              "default": false
            },
            "files": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/File"
              }
            }
          }
        },
        "Results": {
          "type": "object",
          "required": [
            "predictions",
            "errors"
          ],
          "properties": {
            "predictions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/Prediction"
              }
            },
            "errors": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/Error"
              }
            }
          }
        },
        "SentimentScore": {
          "type": "object",
          "required": [
            "name",
            "score"
          ],
          "properties": {
            "name": {
              "type": "string",
              "description": "Level of sentiment, ranging from `1` (negative) to `9` (positive)"
            },
            "score": {
              "type": "string",
              "description": "Prediction for this level of sentiment"
            }
          }
        },
        "SortBy": {
          "type": "string",
          "enum": [
            "created",
            "started",
            "ended"
          ]
        },
        "Source": {
          "type": "object",
          "oneOf": [
            {
              "$ref": "#/components/schemas/Source_Url"
            },
            {
              "$ref": "#/components/schemas/Source_File"
            }
          ],
          "discriminator": {
            "propertyName": "type",
            "mapping": {
              "url": "#/components/schemas/Source_Url",
              "file": "#/components/schemas/Source_File"
            }
          }
        },
        "SourceResult": {
          "type": "object",
          "required": [
            "source"
          ],
          "properties": {
            "source": {
              "$ref": "#/components/schemas/Source"
            },
            "results": {
              "$ref": "#/components/schemas/Results"
            },
            "error": {
              "type": "string",
              "title": "Error Message",
              "description": "An error message."
            }
          }
        },
        "Source_File": {
          "allOf": [
            {
              "type": "object",
              "required": [
                "type"
              ],
              "properties": {
                "type": {
                  "type": "string",
                  "example": "file"
                }
              }
            },
            {
              "$ref": "#/components/schemas/File"
            }
          ]
        },
        "Source_Url": {
          "allOf": [
            {
              "type": "object",
              "required": [
                "type"
              ],
              "properties": {
                "type": {
                  "type": "string",
                  "example": "url"
                }
              }
            },
            {
              "$ref": "#/components/schemas/Url"
            }
          ]
        },
        "State": {
          "type": "object",
          "oneOf": [
            {
              "$ref": "#/components/schemas/State_Queued"
            },
            {
              "$ref": "#/components/schemas/State_InProgress"
            },
            {
              "$ref": "#/components/schemas/State_Completed"
            },
            {
              "$ref": "#/components/schemas/State_Failed"
            }
          ],
          "discriminator": {
            "propertyName": "status",
            "mapping": {
              "QUEUED": "#/components/schemas/State_Queued",
              "IN_PROGRESS": "#/components/schemas/State_InProgress",
              "COMPLETED": "#/components/schemas/State_Completed",
              "FAILED": "#/components/schemas/State_Failed"
            }
          }
        },
        "State_Completed": {
          "allOf": [
            {
              "type": "object",
              "required": [
                "status"
              ],
              "properties": {
                "status": {
                  "type": "string",
                  "example": "COMPLETED"
                }
              }
            },
            {
              "$ref": "#/components/schemas/Completed"
            }
          ]
        },
        "State_Failed": {
          "allOf": [
            {
              "type": "object",
              "required": [
                "status"
              ],
              "properties": {
                "status": {
                  "type": "string",
                  "example": "FAILED"
                }
              }
            },
            {
              "$ref": "#/components/schemas/Failed"
            }
          ]
        },
        "State_InProgress": {
          "allOf": [
            {
              "type": "object",
              "required": [
                "status"
              ],
              "properties": {
                "status": {
                  "type": "string",
                  "example": "IN_PROGRESS"
                }
              }
            },
            {
              "$ref": "#/components/schemas/InProgress"
            }
          ]
        },
        "State_Queued": {
          "allOf": [
            {
              "type": "object",
              "required": [
                "status"
              ],
              "properties": {
                "status": {
                  "type": "string",
                  "example": "QUEUED"
                }
              }
            },
            {
              "$ref": "#/components/schemas/Queued"
            }
          ]
        },
        "Status": {
          "type": "string",
          "enum": [
            "QUEUED",
            "IN_PROGRESS",
            "COMPLETED",
            "FAILED"
          ]
        },
        "TimeInterval": {
          "type": "object",
          "description": "A time range with a beginning and end, measured in seconds.",
          "required": [
            "begin",
            "end"
          ],
          "properties": {
            "begin": {
              "type": "number",
              "format": "double",
              "description": "Beginning of time range in seconds."
            },
            "end": {
              "type": "number",
              "format": "double",
              "description": "End of time range in seconds."
            }
          }
        },
        "ToxicityScore": {
          "type": "object",
          "required": [
            "name",
            "score"
          ],
          "properties": {
            "name": {
              "type": "string",
              "description": "Category of toxicity."
            },
            "score": {
              "type": "string",
              "description": "Prediction for this category of toxicity"
            }
          }
        },
        "Transcription": {
          "type": "object",
          "properties": {
            "language": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Bcp47Tag"
                },
                {
                  "description": "By default, we use an automated language detection method for our Speech Prosody, Language, and NER models. However, if you know what language is being spoken in your media samples, you can specify it via its BCP-47 tag and potentially obtain more accurate results.\n\nYou can specify any of the following languages:\n- Chinese: `zh`\n- Danish: `da`\n- Dutch: `nl`\n- English: `en`\n- English (Australia): `en-AU`\n- English (India): `en-IN`\n- English (New Zealand): `en-NZ`\n- English (United Kingdom): `en-GB`\n- French: `fr`\n- French (Canada): `fr-CA`\n- German: `de`\n- Hindi: `hi`\n- Hindi (Roman Script): `hi-Latn`\n- Indonesian: `id`\n- Italian: `it`\n- Japanese: `ja`\n- Korean: `ko`\n- Norwegian: `no`\n- Polish: `pl`\n- Portuguese: `pt`\n- Portuguese (Brazil): `pt-BR`\n- Portuguese (Portugal): `pt-PT`\n- Russian: `ru`\n- Spanish: `es`\n- Spanish (Latin America): `es-419`\n- Swedish: `sv`\n- Tamil: `ta`\n- Turkish: `tr`\n- Ukrainian: `uk`",
                  "default": null
                }
              ]
            }
          }
        },
        "TranscriptionMetadata": {
          "type": "object",
          "description": "Transcription metadata for your media file.",
          "required": [
            "confidence"
          ],
          "properties": {
            "confidence": {
              "type": "number",
              "format": "double",
              "description": "Value between `0.0` and `1.0` indicating our transcription model’s relative confidence in the transcription of your media file."
            },
            "detected_language": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Bcp47Tag"
                },
                {
                  "description": "The BCP-47 language tag for the dominant language identified in your media file."
                }
              ]
            }
          }
        },
        "Url": {
          "type": "object",
          "required": [
            "url"
          ],
          "properties": {
            "url": {
              "type": "string",
              "description": "The URL of the source media file."
            }
          }
        },
        "When": {
          "type": "string",
          "enum": [
            "created_before",
            "created_after"
          ]
        },
        "Window": {
          "type": "object",
          "properties": {
            "length": {
              "type": "number",
              "format": "double",
              "description": "The length of the sliding window.",
              "default": 4,
              "minimum": 0.5
            },
            "step": {
              "type": "number",
              "format": "double",
              "description": "The step size of the sliding window.",
              "default": 1,
              "minimum": 0.5
            }
          }
        }
      },
      "securitySchemes": {
        "Authentication": {
          "type": "apiKey",
          "name": "X-Hume-Api-Key",
          "in": "header"
        }
      }
    },
    "x-readme": {
      "explorer-enabled": true,
      "proxy-enabled": true,
      "samples-enabled": true
    }
  }
}