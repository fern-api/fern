{
  "absoluteFilePath": "/DUMMY_PATH",
  "importedDefinitions": {},
  "namedDefinitionFiles": {
    "__package__.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "service": {
          "auth": false,
          "base-path": "",
          "endpoints": {
            "Get Job Predictions": {
              "auth": true,
              "display-name": "Get Job Predictions",
              "docs": "Get the JSON predictions of a completed job.",
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": [
                      {
                        "error": "error",
                        "results": {
                          "errors": [
                            {
                              "file": "file",
                              "message": "message",
                            },
                          ],
                          "predictions": [
                            {
                              "file": "file",
                              "models": {},
                            },
                          ],
                        },
                        "source": {
                          "content_type": "source",
                          "filename": "source",
                          "md5sum": "source",
                          "type": "file",
                        },
                      },
                    ],
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/v0/batch/jobs/{id}/predictions",
              "path-parameters": {
                "id": "string",
              },
              "response": {
                "docs": "",
                "status-code": 200,
                "type": "list<SourceResult>",
              },
              "source": {
                "openapi": "../openapi.yaml",
              },
            },
            "List Jobs": {
              "auth": true,
              "display-name": "List Jobs",
              "docs": "Sort and filter jobs.",
              "examples": [
                {
                  "response": {
                    "body": [
                      {
                        "job_id": "job_id",
                        "request": {
                          "callback_url": "callback_url",
                          "files": [
                            {
                              "md5sum": "md5sum",
                            },
                          ],
                          "notify": true,
                          "urls": [
                            "urls",
                          ],
                        },
                        "state": {
                          "created_timestamp_ms": 1000000,
                          "ended_timestamp_ms": 1000000,
                          "message": "state",
                          "started_timestamp_ms": 1000000,
                          "status": "FAILED",
                        },
                        "user_id": "user_id",
                      },
                    ],
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/v0/batch/jobs",
              "request": {
                "name": "ListJobsRequest",
                "query-parameters": {
                  "direction": {
                    "docs": "The sort direction.",
                    "type": "optional<Direction>",
                  },
                  "limit": {
                    "default": 50,
                    "docs": "The maximum number of jobs to include in the response.",
                    "type": "optional<integer>",
                  },
                  "sort_by": {
                    "docs": "The job timestamp to sort by.",
                    "type": "optional<SortBy>",
                  },
                  "status": {
                    "allow-multiple": true,
                    "docs": "Include only jobs with these statuses.",
                    "type": "optional<Status>",
                  },
                  "timestamp_ms": {
                    "docs": "Defaults to the current date and time. See `when`.",
                    "type": "optional<long>",
                  },
                  "when": {
                    "docs": "Include only jobs that were created before or after `timestamp_ms`.",
                    "type": "optional<When>",
                  },
                },
              },
              "response": {
                "docs": "",
                "status-code": 200,
                "type": "list<JobRequest>",
              },
              "source": {
                "openapi": "../openapi.yaml",
              },
            },
            "Start Job": {
              "auth": true,
              "display-name": "Start Job",
              "docs": "Start a new batch job.",
              "examples": [
                {
                  "request": {},
                  "response": {
                    "body": {
                      "job_id": "job_id",
                    },
                  },
                },
              ],
              "method": "POST",
              "pagination": undefined,
              "path": "/v0/batch/jobs",
              "request": {
                "body": {
                  "properties": {
                    "callback_url": {
                      "docs": "If provided, a `POST` request will be made to the URL with the generated predictions on completion or the error message on failure.",
                      "type": "optional<string>",
                    },
                    "models": "optional<Models>",
                    "notify": {
                      "default": false,
                      "docs": "Whether to send an email notification to the user upon job failure.",
                      "type": "optional<boolean>",
                    },
                    "transcription": "optional<Transcription>",
                    "urls": {
                      "docs": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`) of media files.

If you wish to supply more than 100 URLs, consider providing them as an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`).",
                      "type": "optional<list<string>>",
                    },
                  },
                },
                "content-type": "application/json; charset=utf-8",
                "headers": undefined,
                "name": "BaseRequest",
                "path-parameters": undefined,
                "query-parameters": undefined,
              },
              "response": {
                "docs": "",
                "status-code": 200,
                "type": "JobId",
              },
              "source": {
                "openapi": "../openapi.yaml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yaml",
          },
        },
        "types": {
          "Bcp47Tag": {
            "enum": [
              "zh",
              "da",
              "nl",
              "en",
              {
                "name": "EnAu",
                "value": "en-AU",
              },
              {
                "name": "EnIn",
                "value": "en-IN",
              },
              {
                "name": "EnNz",
                "value": "en-NZ",
              },
              {
                "name": "EnGb",
                "value": "en-GB",
              },
              "fr",
              {
                "name": "FrCa",
                "value": "fr-CA",
              },
              "de",
              "hi",
              {
                "name": "HiLatn",
                "value": "hi-Latn",
              },
              "id",
              "it",
              "ja",
              "ko",
              "no",
              "pl",
              "pt",
              {
                "name": "PtBr",
                "value": "pt-BR",
              },
              {
                "name": "PtPt",
                "value": "pt-PT",
              },
              "ru",
              "es",
              {
                "name": "Es419",
                "value": "es-419",
              },
              "sv",
              "ta",
              "tr",
              "uk",
            ],
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "BoundingBox": {
            "docs": "A bounding box around a face.",
            "inline": undefined,
            "properties": {
              "h": {
                "docs": "Bounding box height.",
                "type": "double",
              },
              "w": {
                "docs": "Bounding box width.",
                "type": "double",
              },
              "x": {
                "docs": "x-coordinate of bounding box top left corner.",
                "type": "double",
              },
              "y": {
                "docs": "y-coordinate of bounding box top left corner.",
                "type": "double",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "BurstPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "descriptions": {
                "docs": "Modality-specific descriptive features and their scores.",
                "type": "list<DescriptionsScore>",
              },
              "emotions": {
                "docs": "A high-dimensional embedding in emotion space.",
                "type": "list<EmotionScore>",
              },
              "time": "TimeInterval",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Completed": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_timestamp_ms": {
                "docs": "When this job was created (Unix timestamp in milliseconds).",
                "type": "long",
              },
              "ended_timestamp_ms": {
                "docs": "When this job ended (Unix timestamp in milliseconds).",
                "type": "long",
              },
              "num_errors": {
                "docs": "The number of errors that occurred while running this job.",
                "type": "integer",
              },
              "num_predictions": {
                "docs": "The number of predictions that were generated by this job.",
                "type": "integer",
              },
              "started_timestamp_ms": {
                "docs": "When this job started (Unix timestamp in milliseconds).",
                "type": "long",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "DescriptionsScore": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "name": {
                "docs": "Name of the descriptive feature being expressed.",
                "type": "string",
              },
              "score": {
                "docs": "Embedding value for the descriptive feature being expressed.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Direction": {
            "enum": [
              "asc",
              "desc",
            ],
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "EmotionScore": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "name": {
                "docs": "Name of the emotion being expressed.",
                "type": "string",
              },
              "score": {
                "docs": "Embedding value for the emotion being expressed.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Empty": {
            "docs": "To include predictions for this model type, set this field to `{}`. It is currently not configurable further.",
            "type": "map<string, unknown>",
          },
          "Error": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "file": {
                "docs": "A file path relative to the top level source URL or file.",
                "type": "string",
              },
              "message": {
                "docs": "An error message.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Face": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "descriptions": "optional<Empty>",
              "facs": "optional<Empty>",
              "fps_pred": {
                "default": 3,
                "docs": "Number of frames per second to process. Other frames will be omitted from the response. Set to `0` to process every frame.",
                "type": "optional<double>",
              },
              "identify_faces": {
                "default": false,
                "docs": "Whether to return identifiers for faces across frames. If `true`, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If `false`, all faces will be tagged with an `unknown` ID.",
                "type": "optional<boolean>",
              },
              "min_face_size": {
                "docs": "Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response.",
                "type": "optional<uint64>",
              },
              "prob_threshold": {
                "default": 0.99,
                "docs": "Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response.",
                "type": "optional<double>",
                "validation": {
                  "exclusiveMax": undefined,
                  "exclusiveMin": undefined,
                  "max": 1,
                  "min": 0,
                  "multipleOf": undefined,
                },
              },
              "save_faces": {
                "default": false,
                "docs": "Whether to extract and save the detected faces in the artifacts zip created by each job.",
                "type": "optional<boolean>",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "FacePrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "box": "BoundingBox",
              "descriptions": {
                "docs": "Modality-specific descriptive features and their scores.",
                "type": "optional<list<DescriptionsScore>>",
              },
              "emotions": {
                "docs": "A high-dimensional embedding in emotion space.",
                "type": "list<EmotionScore>",
              },
              "facs": {
                "docs": "FACS 2.0 features and their scores.",
                "type": "optional<list<FacsScore>>",
              },
              "frame": {
                "docs": "Frame number",
                "type": "uint64",
              },
              "prob": {
                "docs": "The predicted probability that a detected face was actually a face.",
                "type": "double",
              },
              "time": {
                "docs": "Time in seconds when face detection occurred.",
                "type": "double",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "FacemeshPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "emotions": {
                "docs": "A high-dimensional embedding in emotion space.",
                "type": "list<EmotionScore>",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "FacsScore": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "name": {
                "docs": "Name of the FACS 2.0 feature being expressed.",
                "type": "string",
              },
              "score": {
                "docs": "Embedding value for the FACS 2.0 feature being expressed.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Failed": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_timestamp_ms": {
                "docs": "When this job was created (Unix timestamp in milliseconds).",
                "type": "long",
              },
              "ended_timestamp_ms": {
                "docs": "When this job ended (Unix timestamp in milliseconds).",
                "type": "long",
              },
              "message": {
                "docs": "An error message.",
                "type": "string",
              },
              "started_timestamp_ms": {
                "docs": "When this job started (Unix timestamp in milliseconds).",
                "type": "long",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "File": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "content_type": {
                "docs": "The content type of the file.",
                "type": "optional<string>",
              },
              "filename": {
                "docs": "The name of the file.",
                "type": "optional<string>",
              },
              "md5sum": {
                "docs": "The MD5 checksum of the file.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Granularity": {
            "docs": "The granularity at which to generate predictions. `utterance` corresponds to a natural pause or break in conversation, while `conversational_turn` corresponds to a change in speaker.",
            "enum": [
              "word",
              "sentence",
              "utterance",
              "conversational_turn",
            ],
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "GroupedPredictionsBurstPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
                "type": "string",
              },
              "predictions": "list<BurstPrediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "GroupedPredictionsFacePrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
                "type": "string",
              },
              "predictions": "list<FacePrediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "GroupedPredictionsFacemeshPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
                "type": "string",
              },
              "predictions": "list<FacemeshPrediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "GroupedPredictionsLanguagePrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
                "type": "string",
              },
              "predictions": "list<LanguagePrediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "GroupedPredictionsNerPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
                "type": "string",
              },
              "predictions": "list<NerPrediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "GroupedPredictionsProsodyPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "id": {
                "docs": "An automatically generated label to identify individuals in your media file. Will be `unknown` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
                "type": "string",
              },
              "predictions": "list<ProsodyPrediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "InProgress": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_timestamp_ms": {
                "docs": "When this job was created (Unix timestamp in milliseconds).",
                "type": "long",
              },
              "started_timestamp_ms": {
                "docs": "When this job started (Unix timestamp in milliseconds).",
                "type": "long",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "JobId": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "job_id": {
                "docs": "The ID of the started job.",
                "type": "string",
                "validation": {
                  "format": "uuid",
                  "maxLength": undefined,
                  "minLength": undefined,
                  "pattern": undefined,
                },
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "JobRequest": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "job_id": {
                "docs": "The ID associated with this job.",
                "type": "string",
                "validation": {
                  "format": "uuid",
                  "maxLength": undefined,
                  "minLength": undefined,
                  "pattern": undefined,
                },
              },
              "request": "Request",
              "state": "State",
              "user_id": {
                "docs": "Your user ID.",
                "type": "string",
                "validation": {
                  "format": "uuid",
                  "maxLength": undefined,
                  "minLength": undefined,
                  "pattern": undefined,
                },
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Language": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "granularity": "optional<Granularity>",
              "identify_speakers": {
                "default": false,
                "docs": "Whether to return identifiers for speakers over time. If `true`, unique identifiers will be assigned to spoken words to differentiate different speakers. If `false`, all speakers will be tagged with an `unknown` ID.",
                "type": "optional<boolean>",
              },
              "sentiment": "optional<Empty>",
              "toxicity": "optional<Empty>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "LanguagePrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "confidence": {
                "docs": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence in this text.",
                "type": "optional<double>",
              },
              "emotions": {
                "docs": "A high-dimensional embedding in emotion space.",
                "type": "list<EmotionScore>",
              },
              "position": "PositionInterval",
              "sentiment": {
                "docs": "Sentiment predictions returned as a distribution. This model predicts the probability that a given text could be interpreted as having each sentiment level from `1` (negative) to `9` (positive).

Compared to returning one estimate of sentiment, this enables a more nuanced analysis of a text's meaning. For example, a text with very neutral sentiment would have an average rating of `5`. But also a text that could be interpreted as having very positive sentiment or very negative sentiment would also have an average rating of `5`. The average sentiment is less informative than the distribution over sentiment, so this API returns a value for each sentiment level.",
                "type": "optional<list<SentimentScore>>",
              },
              "speaker_confidence": {
                "docs": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
                "type": "optional<double>",
              },
              "text": {
                "docs": "A segment of text (like a word or a sentence).",
                "type": "string",
              },
              "time": "optional<TimeInterval>",
              "toxicity": {
                "docs": "Toxicity predictions returned as probabilities that the text can be classified into the following categories: `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`.",
                "type": "optional<list<ToxicityScore>>",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Models": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "burst": "optional<Empty>",
              "face": "optional<Face>",
              "facemesh": "optional<Empty>",
              "language": "optional<Language>",
              "ner": "optional<Ner>",
              "prosody": "optional<Prosody>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "ModelsPredictions": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "burst": "optional<PredictionsOptionalNullBurstPrediction>",
              "face": "optional<PredictionsOptionalNullFacePrediction>",
              "facemesh": "optional<PredictionsOptionalNullFacemeshPrediction>",
              "language": "optional<PredictionsOptionalTranscriptionMetadataLanguagePrediction>",
              "ner": "optional<PredictionsOptionalTranscriptionMetadataNerPrediction>",
              "prosody": "optional<PredictionsOptionalTranscriptionMetadataProsodyPrediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Ner": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "identify_speakers": {
                "default": false,
                "docs": "Whether to return identifiers for speakers over time. If `true`, unique identifiers will be assigned to spoken words to differentiate different speakers. If `false`, all speakers will be tagged with an `unknown` ID.",
                "type": "optional<boolean>",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "NerPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "confidence": {
                "docs": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence in this text.",
                "type": "optional<double>",
              },
              "emotions": {
                "docs": "A high-dimensional embedding in emotion space.",
                "type": "list<EmotionScore>",
              },
              "entity": {
                "docs": "The recognized topic or entity.",
                "type": "string",
              },
              "entity_confidence": {
                "docs": "Our NER model's relative confidence in the recognized topic or entity.",
                "type": "double",
              },
              "link_word": {
                "docs": "The specific word to which the emotion predictions are linked.",
                "type": "string",
              },
              "position": "PositionInterval",
              "speaker_confidence": {
                "docs": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
                "type": "optional<double>",
              },
              "support": {
                "docs": "A measure of how often the entity is linked to by other entities.",
                "type": "double",
              },
              "time": "optional<TimeInterval>",
              "uri": {
                "docs": "A URL which provides more information about the recognized topic or entity.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Null": {
            "docs": "No associated metadata for this model. Value will be `null`.",
            "type": "map<string, unknown>",
          },
          "PositionInterval": {
            "docs": "Position of a segment of text within a larger document, measured in characters. Uses zero-based indexing. The beginning index is inclusive and the end index is exclusive.",
            "inline": undefined,
            "properties": {
              "begin": {
                "docs": "The index of the first character in the text segment, inclusive.",
                "type": "uint64",
              },
              "end": {
                "docs": "The index of the last character in the text segment, exclusive.",
                "type": "uint64",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Prediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "file": {
                "docs": "A file path relative to the top level source URL or file.",
                "type": "string",
              },
              "models": "ModelsPredictions",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "PredictionsOptionalNullBurstPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "grouped_predictions": "list<GroupedPredictionsBurstPrediction>",
              "metadata": "optional<Null>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "PredictionsOptionalNullFacePrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "grouped_predictions": "list<GroupedPredictionsFacePrediction>",
              "metadata": "optional<Null>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "PredictionsOptionalNullFacemeshPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "grouped_predictions": "list<GroupedPredictionsFacemeshPrediction>",
              "metadata": "optional<Null>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "PredictionsOptionalTranscriptionMetadataLanguagePrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "grouped_predictions": "list<GroupedPredictionsLanguagePrediction>",
              "metadata": "optional<TranscriptionMetadata>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "PredictionsOptionalTranscriptionMetadataNerPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "grouped_predictions": "list<GroupedPredictionsNerPrediction>",
              "metadata": "optional<TranscriptionMetadata>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "PredictionsOptionalTranscriptionMetadataProsodyPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "grouped_predictions": "list<GroupedPredictionsProsodyPrediction>",
              "metadata": "optional<TranscriptionMetadata>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Prosody": {
            "docs": "NOTE: the `granularity` field is ignored if transcription is not enabled or if the `window` field has been set.",
            "inline": undefined,
            "properties": {
              "granularity": "optional<Granularity>",
              "identify_speakers": {
                "default": false,
                "docs": "Whether to return identifiers for speakers over time. If `true`, unique identifiers will be assigned to spoken words to differentiate different speakers. If `false`, all speakers will be tagged with an `unknown` ID.",
                "type": "optional<boolean>",
              },
              "window": "optional<Window>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "ProsodyPrediction": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "confidence": {
                "docs": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence in this text.",
                "type": "optional<double>",
              },
              "emotions": {
                "docs": "A high-dimensional embedding in emotion space.",
                "type": "list<EmotionScore>",
              },
              "speaker_confidence": {
                "docs": "Value between `0.0` and `1.0` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
                "type": "optional<double>",
              },
              "text": {
                "docs": "A segment of text (like a word or a sentence).",
                "type": "optional<string>",
              },
              "time": "TimeInterval",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Queued": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "created_timestamp_ms": {
                "docs": "When this job was created (Unix timestamp in milliseconds).",
                "type": "long",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Request": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "callback_url": {
                "docs": "If provided, a `POST` request will be made to the URL with the generated predictions on completion or the error message on failure.",
                "type": "optional<string>",
              },
              "files": "list<File>",
              "models": "optional<Models>",
              "notify": {
                "default": false,
                "docs": "Whether to send an email notification to the user upon job completion/failure.",
                "type": "optional<boolean>",
              },
              "transcription": "optional<Transcription>",
              "urls": {
                "docs": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`) of media files.

If you wish to supply more than 100 URLs, consider providing them as an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`).",
                "type": "optional<list<string>>",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Results": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "errors": "list<Error>",
              "predictions": "list<Prediction>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "SentimentScore": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "name": {
                "docs": "Level of sentiment, ranging from `1` (negative) to `9` (positive)",
                "type": "string",
              },
              "score": {
                "docs": "Prediction for this level of sentiment",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "SortBy": {
            "enum": [
              "created",
              "started",
              "ended",
            ],
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Source": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "type",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
            "union": {
              "file": "SourceFile",
              "url": "SourceUrl",
            },
          },
          "SourceFile": {
            "docs": undefined,
            "extends": [
              "File",
            ],
            "inline": undefined,
            "properties": {},
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "SourceResult": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "error": {
                "docs": "An error message.",
                "type": "optional<string>",
              },
              "results": "optional<Results>",
              "source": "Source",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "SourceUrl": {
            "docs": undefined,
            "extends": [
              "Url",
            ],
            "inline": undefined,
            "properties": {},
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "State": {
            "availability": undefined,
            "base-properties": {},
            "discriminant": "status",
            "docs": undefined,
            "encoding": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
            "union": {
              "COMPLETED": "StateCompleted",
              "FAILED": "StateFailed",
              "IN_PROGRESS": "StateInProgress",
              "QUEUED": "StateQueued",
            },
          },
          "StateCompleted": {
            "docs": undefined,
            "extends": [
              "Completed",
            ],
            "inline": undefined,
            "properties": {},
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "StateFailed": {
            "docs": undefined,
            "extends": [
              "Failed",
            ],
            "inline": undefined,
            "properties": {},
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "StateInProgress": {
            "docs": undefined,
            "extends": [
              "InProgress",
            ],
            "inline": undefined,
            "properties": {},
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "StateQueued": {
            "docs": undefined,
            "extends": [
              "Queued",
            ],
            "inline": undefined,
            "properties": {},
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Status": {
            "enum": [
              "QUEUED",
              "IN_PROGRESS",
              "COMPLETED",
              "FAILED",
            ],
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "TimeInterval": {
            "docs": "A time range with a beginning and end, measured in seconds.",
            "inline": undefined,
            "properties": {
              "begin": {
                "docs": "Beginning of time range in seconds.",
                "type": "double",
              },
              "end": {
                "docs": "End of time range in seconds.",
                "type": "double",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "ToxicityScore": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "name": {
                "docs": "Category of toxicity.",
                "type": "string",
              },
              "score": {
                "docs": "Prediction for this category of toxicity",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Transcription": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "language": "optional<Bcp47Tag>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "TranscriptionMetadata": {
            "docs": "Transcription metadata for your media file.",
            "inline": undefined,
            "properties": {
              "confidence": {
                "docs": "Value between `0.0` and `1.0` indicating our transcription model’s relative confidence in the transcription of your media file.",
                "type": "double",
              },
              "detected_language": "optional<Bcp47Tag>",
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Url": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "url": {
                "docs": "The URL of the source media file.",
                "type": "string",
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "When": {
            "enum": [
              "created_before",
              "created_after",
            ],
            "inline": undefined,
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
          "Window": {
            "docs": undefined,
            "inline": undefined,
            "properties": {
              "length": {
                "default": 4,
                "docs": "The length of the sliding window.",
                "type": "optional<double>",
                "validation": {
                  "exclusiveMax": undefined,
                  "exclusiveMin": undefined,
                  "max": undefined,
                  "min": 0.5,
                  "multipleOf": undefined,
                },
              },
              "step": {
                "default": 1,
                "docs": "The step size of the sliding window.",
                "type": "optional<double>",
                "validation": {
                  "exclusiveMax": undefined,
                  "exclusiveMin": undefined,
                  "max": undefined,
                  "min": 0.5,
                  "multipleOf": undefined,
                },
              },
            },
            "source": {
              "openapi": "../openapi.yaml",
            },
          },
        },
      },
      "rawContents": "service:
  auth: false
  base-path: ''
  endpoints:
    List Jobs:
      path: /v0/batch/jobs
      method: GET
      auth: true
      docs: Sort and filter jobs.
      source:
        openapi: ../openapi.yaml
      display-name: List Jobs
      request:
        name: ListJobsRequest
        query-parameters:
          limit:
            type: optional<integer>
            default: 50
            docs: The maximum number of jobs to include in the response.
          status:
            type: optional<Status>
            allow-multiple: true
            docs: Include only jobs with these statuses.
          when:
            type: optional<When>
            docs: >-
              Include only jobs that were created before or after
              `timestamp_ms`.
          timestamp_ms:
            type: optional<long>
            docs: Defaults to the current date and time. See `when`.
          sort_by:
            type: optional<SortBy>
            docs: The job timestamp to sort by.
          direction:
            type: optional<Direction>
            docs: The sort direction.
      response:
        docs: ''
        type: list<JobRequest>
        status-code: 200
      examples:
        - response:
            body:
              - user_id: user_id
                job_id: job_id
                request:
                  urls:
                    - urls
                  callback_url: callback_url
                  notify: true
                  files:
                    - md5sum: md5sum
                state:
                  status: FAILED
                  created_timestamp_ms: 1000000
                  started_timestamp_ms: 1000000
                  ended_timestamp_ms: 1000000
                  message: state
    Start Job:
      path: /v0/batch/jobs
      method: POST
      auth: true
      docs: Start a new batch job.
      source:
        openapi: ../openapi.yaml
      display-name: Start Job
      request:
        name: BaseRequest
        body:
          properties:
            models: optional<Models>
            transcription: optional<Transcription>
            urls:
              type: optional<list<string>>
              docs: >-
                URLs to the media files to be processed. Each must be a valid
                public URL to a media file (see recommended input filetypes) or
                an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`) of media
                files.


                If you wish to supply more than 100 URLs, consider providing
                them as an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`).
            callback_url:
              type: optional<string>
              docs: >-
                If provided, a `POST` request will be made to the URL with the
                generated predictions on completion or the error message on
                failure.
            notify:
              type: optional<boolean>
              docs: >-
                Whether to send an email notification to the user upon job
                failure.
              default: false
        content-type: application/json; charset=utf-8
      response:
        docs: ''
        type: JobId
        status-code: 200
      examples:
        - request: {}
          response:
            body:
              job_id: job_id
    Get Job Predictions:
      path: /v0/batch/jobs/{id}/predictions
      method: GET
      auth: true
      docs: Get the JSON predictions of a completed job.
      source:
        openapi: ../openapi.yaml
      path-parameters:
        id: string
      display-name: Get Job Predictions
      response:
        docs: ''
        type: list<SourceResult>
        status-code: 200
      examples:
        - path-parameters:
            id: id
          response:
            body:
              - source:
                  type: file
                  filename: source
                  content_type: source
                  md5sum: source
                results:
                  predictions:
                    - file: file
                      models: {}
                  errors:
                    - message: message
                      file: file
                error: error
  source:
    openapi: ../openapi.yaml
types:
  Bcp47Tag:
    enum:
      - zh
      - da
      - nl
      - en
      - value: en-AU
        name: EnAu
      - value: en-IN
        name: EnIn
      - value: en-NZ
        name: EnNz
      - value: en-GB
        name: EnGb
      - fr
      - value: fr-CA
        name: FrCa
      - de
      - hi
      - value: hi-Latn
        name: HiLatn
      - id
      - it
      - ja
      - ko
      - 'no'
      - pl
      - pt
      - value: pt-BR
        name: PtBr
      - value: pt-PT
        name: PtPt
      - ru
      - es
      - value: es-419
        name: Es419
      - sv
      - ta
      - tr
      - uk
    source:
      openapi: ../openapi.yaml
  BoundingBox:
    docs: A bounding box around a face.
    properties:
      x:
        type: double
        docs: x-coordinate of bounding box top left corner.
      'y':
        type: double
        docs: y-coordinate of bounding box top left corner.
      w:
        type: double
        docs: Bounding box width.
      h:
        type: double
        docs: Bounding box height.
    source:
      openapi: ../openapi.yaml
  BurstPrediction:
    properties:
      time: TimeInterval
      emotions:
        docs: A high-dimensional embedding in emotion space.
        type: list<EmotionScore>
      descriptions:
        docs: Modality-specific descriptive features and their scores.
        type: list<DescriptionsScore>
    source:
      openapi: ../openapi.yaml
  Completed:
    properties:
      created_timestamp_ms:
        type: long
        docs: When this job was created (Unix timestamp in milliseconds).
      started_timestamp_ms:
        type: long
        docs: When this job started (Unix timestamp in milliseconds).
      ended_timestamp_ms:
        type: long
        docs: When this job ended (Unix timestamp in milliseconds).
      num_predictions:
        type: integer
        docs: The number of predictions that were generated by this job.
      num_errors:
        type: integer
        docs: The number of errors that occurred while running this job.
    source:
      openapi: ../openapi.yaml
  DescriptionsScore:
    properties:
      name:
        type: string
        docs: Name of the descriptive feature being expressed.
      score:
        type: string
        docs: Embedding value for the descriptive feature being expressed.
    source:
      openapi: ../openapi.yaml
  Direction:
    enum:
      - asc
      - desc
    source:
      openapi: ../openapi.yaml
  EmotionScore:
    properties:
      name:
        type: string
        docs: Name of the emotion being expressed.
      score:
        type: string
        docs: Embedding value for the emotion being expressed.
    source:
      openapi: ../openapi.yaml
  Empty:
    type: map<string, unknown>
    docs: >-
      To include predictions for this model type, set this field to `{}`. It is
      currently not configurable further.
  Error:
    properties:
      message:
        type: string
        docs: An error message.
      file:
        type: string
        docs: A file path relative to the top level source URL or file.
    source:
      openapi: ../openapi.yaml
  Face:
    properties:
      fps_pred:
        type: optional<double>
        docs: >-
          Number of frames per second to process. Other frames will be omitted
          from the response. Set to `0` to process every frame.
        default: 3
      prob_threshold:
        type: optional<double>
        docs: >-
          Face detection probability threshold. Faces detected with a
          probability less than this threshold will be omitted from the
          response.
        default: 0.99
        validation:
          min: 0
          max: 1
      identify_faces:
        type: optional<boolean>
        docs: >-
          Whether to return identifiers for faces across frames. If `true`,
          unique identifiers will be assigned to face bounding boxes to
          differentiate different faces. If `false`, all faces will be tagged
          with an `unknown` ID.
        default: false
      min_face_size:
        type: optional<uint64>
        docs: >-
          Minimum bounding box side length in pixels to treat as a face. Faces
          detected with a bounding box side length in pixels less than this
          threshold will be omitted from the response.
      facs: optional<Empty>
      descriptions: optional<Empty>
      save_faces:
        type: optional<boolean>
        docs: >-
          Whether to extract and save the detected faces in the artifacts zip
          created by each job.
        default: false
    source:
      openapi: ../openapi.yaml
  FacePrediction:
    properties:
      frame:
        type: uint64
        docs: Frame number
      time:
        type: double
        docs: Time in seconds when face detection occurred.
      prob:
        type: double
        docs: The predicted probability that a detected face was actually a face.
      box: BoundingBox
      emotions:
        docs: A high-dimensional embedding in emotion space.
        type: list<EmotionScore>
      facs:
        type: optional<list<FacsScore>>
        docs: FACS 2.0 features and their scores.
      descriptions:
        type: optional<list<DescriptionsScore>>
        docs: Modality-specific descriptive features and their scores.
    source:
      openapi: ../openapi.yaml
  FacemeshPrediction:
    properties:
      emotions:
        docs: A high-dimensional embedding in emotion space.
        type: list<EmotionScore>
    source:
      openapi: ../openapi.yaml
  FacsScore:
    properties:
      name:
        type: string
        docs: Name of the FACS 2.0 feature being expressed.
      score:
        type: string
        docs: Embedding value for the FACS 2.0 feature being expressed.
    source:
      openapi: ../openapi.yaml
  Failed:
    properties:
      created_timestamp_ms:
        type: long
        docs: When this job was created (Unix timestamp in milliseconds).
      started_timestamp_ms:
        type: long
        docs: When this job started (Unix timestamp in milliseconds).
      ended_timestamp_ms:
        type: long
        docs: When this job ended (Unix timestamp in milliseconds).
      message:
        type: string
        docs: An error message.
    source:
      openapi: ../openapi.yaml
  File:
    properties:
      filename:
        type: optional<string>
        docs: The name of the file.
      content_type:
        type: optional<string>
        docs: The content type of the file.
      md5sum:
        type: string
        docs: The MD5 checksum of the file.
    source:
      openapi: ../openapi.yaml
  Granularity:
    enum:
      - word
      - sentence
      - utterance
      - conversational_turn
    docs: >-
      The granularity at which to generate predictions. `utterance` corresponds
      to a natural pause or break in conversation, while `conversational_turn`
      corresponds to a change in speaker.
    source:
      openapi: ../openapi.yaml
  GroupedPredictionsBurstPrediction:
    properties:
      id:
        type: string
        docs: >-
          An automatically generated label to identify individuals in your media
          file. Will be `unknown` if you have chosen to disable identification,
          or if the model is unable to distinguish between individuals.
      predictions: list<BurstPrediction>
    source:
      openapi: ../openapi.yaml
  GroupedPredictionsFacePrediction:
    properties:
      id:
        type: string
        docs: >-
          An automatically generated label to identify individuals in your media
          file. Will be `unknown` if you have chosen to disable identification,
          or if the model is unable to distinguish between individuals.
      predictions: list<FacePrediction>
    source:
      openapi: ../openapi.yaml
  GroupedPredictionsFacemeshPrediction:
    properties:
      id:
        type: string
        docs: >-
          An automatically generated label to identify individuals in your media
          file. Will be `unknown` if you have chosen to disable identification,
          or if the model is unable to distinguish between individuals.
      predictions: list<FacemeshPrediction>
    source:
      openapi: ../openapi.yaml
  GroupedPredictionsLanguagePrediction:
    properties:
      id:
        type: string
        docs: >-
          An automatically generated label to identify individuals in your media
          file. Will be `unknown` if you have chosen to disable identification,
          or if the model is unable to distinguish between individuals.
      predictions: list<LanguagePrediction>
    source:
      openapi: ../openapi.yaml
  GroupedPredictionsNerPrediction:
    properties:
      id:
        type: string
        docs: >-
          An automatically generated label to identify individuals in your media
          file. Will be `unknown` if you have chosen to disable identification,
          or if the model is unable to distinguish between individuals.
      predictions: list<NerPrediction>
    source:
      openapi: ../openapi.yaml
  GroupedPredictionsProsodyPrediction:
    properties:
      id:
        type: string
        docs: >-
          An automatically generated label to identify individuals in your media
          file. Will be `unknown` if you have chosen to disable identification,
          or if the model is unable to distinguish between individuals.
      predictions: list<ProsodyPrediction>
    source:
      openapi: ../openapi.yaml
  InProgress:
    properties:
      created_timestamp_ms:
        type: long
        docs: When this job was created (Unix timestamp in milliseconds).
      started_timestamp_ms:
        type: long
        docs: When this job started (Unix timestamp in milliseconds).
    source:
      openapi: ../openapi.yaml
  JobRequest:
    properties:
      user_id:
        type: string
        docs: Your user ID.
        validation:
          format: uuid
      job_id:
        type: string
        docs: The ID associated with this job.
        validation:
          format: uuid
      request: Request
      state: State
    source:
      openapi: ../openapi.yaml
  JobId:
    properties:
      job_id:
        type: string
        docs: The ID of the started job.
        validation:
          format: uuid
    source:
      openapi: ../openapi.yaml
  Language:
    properties:
      granularity: optional<Granularity>
      identify_speakers:
        type: optional<boolean>
        docs: >-
          Whether to return identifiers for speakers over time. If `true`,
          unique identifiers will be assigned to spoken words to differentiate
          different speakers. If `false`, all speakers will be tagged with an
          `unknown` ID.
        default: false
      sentiment: optional<Empty>
      toxicity: optional<Empty>
    source:
      openapi: ../openapi.yaml
  LanguagePrediction:
    properties:
      text:
        type: string
        docs: A segment of text (like a word or a sentence).
      position: PositionInterval
      time: optional<TimeInterval>
      confidence:
        type: optional<double>
        docs: >-
          Value between `0.0` and `1.0` that indicates our transcription model’s
          relative confidence in this text.
      speaker_confidence:
        type: optional<double>
        docs: >-
          Value between `0.0` and `1.0` that indicates our transcription model’s
          relative confidence that this text was spoken by this speaker.
      emotions:
        docs: A high-dimensional embedding in emotion space.
        type: list<EmotionScore>
      sentiment:
        type: optional<list<SentimentScore>>
        docs: >-
          Sentiment predictions returned as a distribution. This model predicts
          the probability that a given text could be interpreted as having each
          sentiment level from `1` (negative) to `9` (positive).


          Compared to returning one estimate of sentiment, this enables a more
          nuanced analysis of a text's meaning. For example, a text with very
          neutral sentiment would have an average rating of `5`. But also a text
          that could be interpreted as having very positive sentiment or very
          negative sentiment would also have an average rating of `5`. The
          average sentiment is less informative than the distribution over
          sentiment, so this API returns a value for each sentiment level.
      toxicity:
        type: optional<list<ToxicityScore>>
        docs: >-
          Toxicity predictions returned as probabilities that the text can be
          classified into the following categories: `toxic`, `severe_toxic`,
          `obscene`, `threat`, `insult`, and `identity_hate`.
    source:
      openapi: ../openapi.yaml
  Models:
    properties:
      face: optional<Face>
      burst: optional<Empty>
      prosody: optional<Prosody>
      language: optional<Language>
      ner: optional<Ner>
      facemesh: optional<Empty>
    source:
      openapi: ../openapi.yaml
  ModelsPredictions:
    properties:
      face: optional<PredictionsOptionalNullFacePrediction>
      burst: optional<PredictionsOptionalNullBurstPrediction>
      prosody: optional<PredictionsOptionalTranscriptionMetadataProsodyPrediction>
      language: optional<PredictionsOptionalTranscriptionMetadataLanguagePrediction>
      ner: optional<PredictionsOptionalTranscriptionMetadataNerPrediction>
      facemesh: optional<PredictionsOptionalNullFacemeshPrediction>
    source:
      openapi: ../openapi.yaml
  Ner:
    properties:
      identify_speakers:
        type: optional<boolean>
        docs: >-
          Whether to return identifiers for speakers over time. If `true`,
          unique identifiers will be assigned to spoken words to differentiate
          different speakers. If `false`, all speakers will be tagged with an
          `unknown` ID.
        default: false
    source:
      openapi: ../openapi.yaml
  NerPrediction:
    properties:
      entity:
        type: string
        docs: The recognized topic or entity.
      position: PositionInterval
      entity_confidence:
        type: double
        docs: Our NER model's relative confidence in the recognized topic or entity.
      support:
        type: double
        docs: A measure of how often the entity is linked to by other entities.
      uri:
        type: string
        docs: >-
          A URL which provides more information about the recognized topic or
          entity.
      link_word:
        type: string
        docs: The specific word to which the emotion predictions are linked.
      time: optional<TimeInterval>
      confidence:
        type: optional<double>
        docs: >-
          Value between `0.0` and `1.0` that indicates our transcription model’s
          relative confidence in this text.
      speaker_confidence:
        type: optional<double>
        docs: >-
          Value between `0.0` and `1.0` that indicates our transcription model’s
          relative confidence that this text was spoken by this speaker.
      emotions:
        docs: A high-dimensional embedding in emotion space.
        type: list<EmotionScore>
    source:
      openapi: ../openapi.yaml
  'Null':
    type: map<string, unknown>
    docs: No associated metadata for this model. Value will be `null`.
  PositionInterval:
    docs: >-
      Position of a segment of text within a larger document, measured in
      characters. Uses zero-based indexing. The beginning index is inclusive and
      the end index is exclusive.
    properties:
      begin:
        type: uint64
        docs: The index of the first character in the text segment, inclusive.
      end:
        type: uint64
        docs: The index of the last character in the text segment, exclusive.
    source:
      openapi: ../openapi.yaml
  Prediction:
    properties:
      file:
        type: string
        docs: A file path relative to the top level source URL or file.
      models: ModelsPredictions
    source:
      openapi: ../openapi.yaml
  PredictionsOptionalNullBurstPrediction:
    properties:
      metadata: optional<Null>
      grouped_predictions: list<GroupedPredictionsBurstPrediction>
    source:
      openapi: ../openapi.yaml
  PredictionsOptionalNullFacePrediction:
    properties:
      metadata: optional<Null>
      grouped_predictions: list<GroupedPredictionsFacePrediction>
    source:
      openapi: ../openapi.yaml
  PredictionsOptionalNullFacemeshPrediction:
    properties:
      metadata: optional<Null>
      grouped_predictions: list<GroupedPredictionsFacemeshPrediction>
    source:
      openapi: ../openapi.yaml
  PredictionsOptionalTranscriptionMetadataLanguagePrediction:
    properties:
      metadata: optional<TranscriptionMetadata>
      grouped_predictions: list<GroupedPredictionsLanguagePrediction>
    source:
      openapi: ../openapi.yaml
  PredictionsOptionalTranscriptionMetadataNerPrediction:
    properties:
      metadata: optional<TranscriptionMetadata>
      grouped_predictions: list<GroupedPredictionsNerPrediction>
    source:
      openapi: ../openapi.yaml
  PredictionsOptionalTranscriptionMetadataProsodyPrediction:
    properties:
      metadata: optional<TranscriptionMetadata>
      grouped_predictions: list<GroupedPredictionsProsodyPrediction>
    source:
      openapi: ../openapi.yaml
  Prosody:
    docs: >-
      NOTE: the `granularity` field is ignored if transcription is not enabled
      or if the `window` field has been set.
    properties:
      granularity: optional<Granularity>
      identify_speakers:
        type: optional<boolean>
        docs: >-
          Whether to return identifiers for speakers over time. If `true`,
          unique identifiers will be assigned to spoken words to differentiate
          different speakers. If `false`, all speakers will be tagged with an
          `unknown` ID.
        default: false
      window: optional<Window>
    source:
      openapi: ../openapi.yaml
  ProsodyPrediction:
    properties:
      text:
        type: optional<string>
        docs: A segment of text (like a word or a sentence).
      time: TimeInterval
      confidence:
        type: optional<double>
        docs: >-
          Value between `0.0` and `1.0` that indicates our transcription model’s
          relative confidence in this text.
      speaker_confidence:
        type: optional<double>
        docs: >-
          Value between `0.0` and `1.0` that indicates our transcription model’s
          relative confidence that this text was spoken by this speaker.
      emotions:
        docs: A high-dimensional embedding in emotion space.
        type: list<EmotionScore>
    source:
      openapi: ../openapi.yaml
  Queued:
    properties:
      created_timestamp_ms:
        type: long
        docs: When this job was created (Unix timestamp in milliseconds).
    source:
      openapi: ../openapi.yaml
  Request:
    properties:
      models: optional<Models>
      transcription: optional<Transcription>
      urls:
        type: optional<list<string>>
        docs: >-
          URLs to the media files to be processed. Each must be a valid public
          URL to a media file (see recommended input filetypes) or an archive
          (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`) of media files.


          If you wish to supply more than 100 URLs, consider providing them as
          an archive (`.zip`, `.tar.gz`, `.tar.bz2`, `.tar.xz`).
      callback_url:
        type: optional<string>
        docs: >-
          If provided, a `POST` request will be made to the URL with the
          generated predictions on completion or the error message on failure.
      notify:
        type: optional<boolean>
        docs: >-
          Whether to send an email notification to the user upon job
          completion/failure.
        default: false
      files: list<File>
    source:
      openapi: ../openapi.yaml
  Results:
    properties:
      predictions: list<Prediction>
      errors: list<Error>
    source:
      openapi: ../openapi.yaml
  SentimentScore:
    properties:
      name:
        type: string
        docs: Level of sentiment, ranging from `1` (negative) to `9` (positive)
      score:
        type: string
        docs: Prediction for this level of sentiment
    source:
      openapi: ../openapi.yaml
  SortBy:
    enum:
      - created
      - started
      - ended
    source:
      openapi: ../openapi.yaml
  Source:
    discriminant: type
    base-properties: {}
    union:
      url: SourceUrl
      file: SourceFile
    source:
      openapi: ../openapi.yaml
  SourceResult:
    properties:
      source: Source
      results: optional<Results>
      error:
        type: optional<string>
        docs: An error message.
    source:
      openapi: ../openapi.yaml
  SourceFile:
    properties: {}
    extends:
      - File
    source:
      openapi: ../openapi.yaml
  SourceUrl:
    properties: {}
    extends:
      - Url
    source:
      openapi: ../openapi.yaml
  Url:
    properties:
      url:
        type: string
        docs: The URL of the source media file.
    source:
      openapi: ../openapi.yaml
  State:
    discriminant: status
    base-properties: {}
    union:
      QUEUED: StateQueued
      IN_PROGRESS: StateInProgress
      COMPLETED: StateCompleted
      FAILED: StateFailed
    source:
      openapi: ../openapi.yaml
  StateCompleted:
    properties: {}
    extends:
      - Completed
    source:
      openapi: ../openapi.yaml
  StateFailed:
    properties: {}
    extends:
      - Failed
    source:
      openapi: ../openapi.yaml
  StateInProgress:
    properties: {}
    extends:
      - InProgress
    source:
      openapi: ../openapi.yaml
  StateQueued:
    properties: {}
    extends:
      - Queued
    source:
      openapi: ../openapi.yaml
  Status:
    enum:
      - QUEUED
      - IN_PROGRESS
      - COMPLETED
      - FAILED
    source:
      openapi: ../openapi.yaml
  TimeInterval:
    docs: A time range with a beginning and end, measured in seconds.
    properties:
      begin:
        type: double
        docs: Beginning of time range in seconds.
      end:
        type: double
        docs: End of time range in seconds.
    source:
      openapi: ../openapi.yaml
  ToxicityScore:
    properties:
      name:
        type: string
        docs: Category of toxicity.
      score:
        type: string
        docs: Prediction for this category of toxicity
    source:
      openapi: ../openapi.yaml
  Transcription:
    properties:
      language: optional<Bcp47Tag>
    source:
      openapi: ../openapi.yaml
  TranscriptionMetadata:
    docs: Transcription metadata for your media file.
    properties:
      confidence:
        type: double
        docs: >-
          Value between `0.0` and `1.0` indicating our transcription model’s
          relative confidence in the transcription of your media file.
      detected_language: optional<Bcp47Tag>
    source:
      openapi: ../openapi.yaml
  When:
    enum:
      - created_before
      - created_after
    source:
      openapi: ../openapi.yaml
  Window:
    properties:
      length:
        type: optional<double>
        docs: The length of the sliding window.
        default: 4
        validation:
          min: 0.5
      step:
        type: optional<double>
        docs: The step size of the sliding window.
        default: 1
        validation:
          min: 0.5
    source:
      openapi: ../openapi.yaml
",
    },
    "getJobPredictions.yml": {
      "absoluteFilepath": "/DUMMY_PATH",
      "contents": {
        "imports": {
          "root": "__package__.yml",
        },
        "service": {
          "auth": false,
          "base-path": "",
          "display-name": "Get Job Predictions",
          "endpoints": {
            "get_job": {
              "auth": true,
              "display-name": "Get Job Details",
              "docs": "Get the request details and state of a given job.",
              "examples": [
                {
                  "path-parameters": {
                    "id": "id",
                  },
                  "response": {
                    "body": {
                      "job_id": "job_id",
                      "request": {
                        "callback_url": "callback_url",
                        "files": [
                          {
                            "md5sum": "md5sum",
                          },
                        ],
                        "models": {
                          "burst": {
                            "key": "value",
                          },
                          "facemesh": {
                            "key": "value",
                          },
                        },
                        "notify": true,
                        "transcription": {
                          "language": "zh",
                        },
                        "urls": [
                          "urls",
                        ],
                      },
                      "state": {
                        "created_timestamp_ms": 1000000,
                        "ended_timestamp_ms": 1000000,
                        "message": "state",
                        "started_timestamp_ms": 1000000,
                        "status": "FAILED",
                      },
                      "user_id": "user_id",
                    },
                  },
                },
              ],
              "method": "GET",
              "pagination": undefined,
              "path": "/v0/batch/jobs/{id}",
              "path-parameters": {
                "id": "string",
              },
              "response": {
                "docs": "",
                "status-code": 200,
                "type": "root.JobRequest",
              },
              "source": {
                "openapi": "../openapi.yaml",
              },
            },
            "get_job_artifacts": {
              "auth": true,
              "display-name": "Get Job Artifacts",
              "docs": "Get the artifacts ZIP of a completed job.",
              "method": "GET",
              "pagination": undefined,
              "path": "/v0/batch/jobs/{id}/artifacts",
              "path-parameters": {
                "id": "string",
              },
              "response": {
                "docs": "",
                "status-code": 200,
                "type": "file",
              },
              "source": {
                "openapi": "../openapi.yaml",
              },
            },
          },
          "source": {
            "openapi": "../openapi.yaml",
          },
        },
      },
      "rawContents": "service:
  auth: false
  base-path: ''
  endpoints:
    get_job_artifacts:
      path: /v0/batch/jobs/{id}/artifacts
      method: GET
      auth: true
      docs: Get the artifacts ZIP of a completed job.
      source:
        openapi: ../openapi.yaml
      path-parameters:
        id: string
      display-name: Get Job Artifacts
      response:
        docs: ''
        type: file
        status-code: 200
    get_job:
      path: /v0/batch/jobs/{id}
      method: GET
      auth: true
      docs: Get the request details and state of a given job.
      source:
        openapi: ../openapi.yaml
      path-parameters:
        id: string
      display-name: Get Job Details
      response:
        docs: ''
        type: root.JobRequest
        status-code: 200
      examples:
        - path-parameters:
            id: id
          response:
            body:
              user_id: user_id
              job_id: job_id
              request:
                models:
                  burst:
                    key: value
                  facemesh:
                    key: value
                transcription:
                  language: zh
                urls:
                  - urls
                callback_url: callback_url
                notify: true
                files:
                  - md5sum: md5sum
              state:
                status: FAILED
                created_timestamp_ms: 1000000
                started_timestamp_ms: 1000000
                ended_timestamp_ms: 1000000
                message: state
  source:
    openapi: ../openapi.yaml
  display-name: Get Job Predictions
imports:
  root: __package__.yml
",
    },
  },
  "packageMarkers": {},
  "rootApiFile": {
    "contents": {
      "auth": "Authentication",
      "auth-schemes": {
        "Authentication": {
          "header": "X-Hume-Api-Key",
          "name": "apiKey",
          "type": "string",
        },
      },
      "default-environment": "Default",
      "display-name": "Hume AI Batch API",
      "environments": {
        "Default": "https://api.hume.ai",
      },
      "error-discrimination": {
        "strategy": "status-code",
      },
      "name": "api",
    },
    "defaultUrl": undefined,
    "rawContents": "name: api
error-discrimination:
  strategy: status-code
display-name: Hume AI Batch API
environments:
  Default: https://api.hume.ai
default-environment: Default
auth-schemes:
  Authentication:
    header: X-Hume-Api-Key
    name: apiKey
    type: string
auth: Authentication
",
  },
}