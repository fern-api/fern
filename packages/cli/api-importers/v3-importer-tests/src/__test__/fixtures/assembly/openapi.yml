openapi: 3.1.0
info:
  title: AssemblyAI API
  description: AssemblyAI API
  version: 1.0.0
  contact:
    name: API Support
    email: support@assemblyai.com
    url: https://www.assemblyai.com/docs/

servers:
  - url: https://api.assemblyai.com
    description: AssemblyAI API

tags:
  - name: transcript
    description: Transcript related operations
    externalDocs:
      url: https://www.assemblyai.com/docs/Guides/transcribing_an_audio_file
  - name: LeMUR
    description: LeMUR related operations
    externalDocs:
      url: https://www.assemblyai.com/docs/Guides/processing_audio_with_llms_using_lemur
  - name: realtime
    description: Real-time transcription
    externalDocs:
      url: https://www.assemblyai.com/docs/Guides/real-time_streaming_transcription
security:
  - ApiKey: []

paths:
  /v2/upload:
    post:
      tags:
        - transcript
      summary: Upload an audio or video file which can be transcribed.
      operationId: uploadFile
      x-fern-sdk-group-name: files
      x-fern-sdk-method-name: upload
      description: Upload your audio or video file directly to the AssemblyAI API if it isn't accessible via a URL already.
      requestBody:
        content:
          application/octet-stream:
            schema:
              type: string
              format: binary
      responses:
        "200":
          description: File uploaded successfully
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UploadedFile"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/transcript:
    post:
      tags:
        - transcript
      summary: Create a transcript from an audio file
      operationId: createTranscript
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: create
      description: Create a transcript from an audio or video file that is accessible via a URL.
      requestBody:
        description: Parameters to create a transcript.
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateTranscriptParameters"
      responses:
        "201":
          description: Transcript created and queued for processing.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Transcript"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

    get:
      tags:
        - transcript
      summary: List transcripts
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: list
      operationId: listTranscripts
      description: Retrieve a list of transcripts you have created.
      parameters:
        - name: limit
          in: query
          description: Maximum amount of transcripts to retrieve
          schema:
            $ref: "#/components/schemas/TranscriptListParameters/properties/limit"
        - name: status
          in: query
          description: Filter by transcript status
          schema:
            $ref: "#/components/schemas/TranscriptListParameters/properties/status"

        - name: created_on
          in: query
          description: Only get transcripts created on this date
          schema:
            $ref: "#/components/schemas/TranscriptListParameters/properties/created_on"

        - name: before_id
          in: query
          description: Get transcripts that were created before this transcript ID
          schema:
            $ref: "#/components/schemas/TranscriptListParameters/properties/before_id"

        - name: after_id
          in: query
          description: Get transcripts that were created after this transcript ID
          schema:
            $ref: "#/components/schemas/TranscriptListParameters/properties/after_id"

        - name: throttled_only
          in: query
          description: Only get throttled transcripts, overrides the status filter
          schema:
            $ref: "#/components/schemas/TranscriptListParameters/properties/throttled_only"

      responses:
        "200":
          description: A list of transcripts filtered by `limit` and `status`
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/TranscriptList"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/transcript/{transcript_id}:
    get:
      tags:
        - transcript
      summary: Get the transcript
      operationId: getTranscript
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: get
      description: Get the transcript resource. The transcript is ready when the "status" is "completed".
      parameters:
        - name: transcript_id
          in: path
          description: ID of the transcript
          required: true
          schema:
            type: string
      responses:
        "200":
          description: The transcript resource
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Transcript"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

    delete:
      tags:
        - transcript
      summary: Delete the transcript
      operationId: deleteTranscript
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: delete
      description: Delete the transcript
      parameters:
        - name: transcript_id
          in: path
          description: ID of the transcript
          required: true
          schema:
            type: string
      responses:
        "200":
          description: The deleted transcript response.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Transcript"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/transcript/{transcript_id}/{subtitle_format}:
    get:
      tags:
        - transcript
      summary: Export transcript as SRT or VTT captions.
      operationId: getSubtitles
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: getSubtitles
      description: Export your transcript in SRT or VTT format, to be plugged into a video player for subtitles and closed captions.
      parameters:
        - name: transcript_id
          in: path
          description: ID of the transcript
          required: true
          schema:
            type: string
        - name: subtitle_format
          in: path
          description: The format of the captions.
          required: true
          schema:
            $ref: "#/components/schemas/SubtitleFormat"
        - name: chars_per_caption
          in: query
          description: The maximum number of characters per caption
          schema:
            type: integer

      responses:
        "200":
          description: The exported captions as text
          content:
            text/plain:
              schema:
                type: string
                example: |
                  WEBVTT
                  00:12.340 --> 00:16.220
                  Last year I showed these two slides said that demonstrate
                  00:16.200 --> 00:20.040
                  that the Arctic ice cap which for most of the last 3,000,000 years has been the
                  00:20.020 --> 00:25.040
                  size of the lower 48 States has shrunk by 40% but this understates
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/transcript/{transcript_id}/sentences:
    get:
      tags:
        - transcript
      summary: Get the transcript split by sentences
      operationId: getTranscriptSentences
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: getSentences
      description: Get the transcript split by sentences. The API will attempt to semantically segment the transcript into sentences to create more reader-friendly transcripts.
      parameters:
        - name: transcript_id
          in: path
          description: ID of the transcript
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Exported sentences
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/SentencesResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/transcript/{transcript_id}/paragraphs:
    get:
      tags:
        - transcript
      summary: Get the transcript split by paragraphs
      operationId: getTranscriptParagraphs
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: getParagraphs
      description: Get the transcript split by paragraphs. The API will attempt to semantically segment your transcript into paragraphs to create more reader-friendly transcripts.
      parameters:
        - name: transcript_id
          in: path
          description: ID of the transcript
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Exported paragraphs
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ParagraphsResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/transcript/{transcript_id}/word-search:
    get:
      tags:
        - transcript
      summary: Search the given transcript for words, numbers, or phrases
      operationId: wordSearch
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: wordSearch
      description: Search through the transcript for a specific set of keywords. You can search for individual words, numbers, or phrases containing up to five words or numbers.
      parameters:
        - name: transcript_id
          in: path
          description: ID of the transcript
          required: true
          schema:
            type: string
        - name: words
          in: query
          description: Keywords to search for
          required: true
          schema:
            type: array
            items:
              type: string

      responses:
        "200":
          description: Word search response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/WordSearchResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/transcript/{transcript_id}/redacted-audio:
    get:
      tags:
        - transcript
      summary: Retrieves the redacted audio object containing the status and URL to the redacted audio.
      description: Retrieves the redacted audio object containing the status and URL to the redacted audio.
      operationId: getRedactedAudio
      x-fern-sdk-group-name: transcript
      x-fern-sdk-method-name: getRedactedAudio
      parameters:
        - name: transcript_id
          in: path
          description: ID of the transcript
          required: true
          schema:
            type: string

      responses:
        "200":
          description: The redacted audio object containing the status and URL to the redacted audio.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RedactedAudioResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /v2/realtime/token:
    post:
      tags:
        - realtime
      summary: Create a temporary authentication token for real-time transcription
      description: Create a temporary authentication token for real-time transcription
      operationId: createRealtimeToken
      x-fern-sdk-group-name: realtime
      x-fern-sdk-method-name: createTemporaryToken
      requestBody:
        description: Parameters to create a temporary authentication token.
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateRealtimeTemporaryTokenParameters"
      responses:
        "200":
          description: Temporary authentication token generated.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RealtimeTemporaryTokenResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /lemur/v3/generate/summary:
    post:
      tags:
        - LeMUR
      summary: Generate a custom summary from one or more transcripts.
      operationId: lemurSummary
      x-fern-sdk-group-name: lemur
      x-fern-sdk-method-name: summary
      description: Custom Summary allows you to distill a piece of audio into a few impactful sentences. You can give the model context to obtain more targeted results while outputting the results in a variety of formats described in human language.
      requestBody:
        description: Parameters to generate the summary.
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/LemurSummaryParameters"

      responses:
        "200":
          description: LeMUR summary response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LemurSummaryResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /lemur/v3/generate/question-answer:
    post:
      tags:
        - LeMUR
      summary: Create answers to one or more questions about one or more transcripts.
      operationId: lemurQuestionAnswer
      x-fern-sdk-group-name: lemur
      x-fern-sdk-method-name: questionAnswer
      description: Question & Answer allows you to ask free-form questions about a single transcript or a group of transcripts. The questions can be any whose answers you find useful, such as judging whether a caller is likely to become a customer or whether all items on a meeting's agenda were covered.
      requestBody:
        description: Parameters to ask questions about the transcripts.
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/LemurQuestionAnswerParameters"

      responses:
        "200":
          description: LeMUR question & answer response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LemurQuestionAnswerResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /lemur/v3/generate/action-items:
    post:
      tags:
        - LeMUR
      summary: Extract action items from one or more meeting transcripts.
      operationId: lemurActionItems
      x-fern-sdk-group-name: lemur
      x-fern-sdk-method-name: actionItems
      description: Use LeMUR to generate a list of Action Items from a transcript
      requestBody:
        description: Parameters to generate action items from transcripts.
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/LemurActionItemsParameters"

      responses:
        "200":
          description: LeMUR action items response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LemurActionItemsResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /lemur/v3/generate/task:
    post:
      tags:
        - LeMUR
      summary: Ask LeMUR to use one or more transcripts with a Custom Task to handle your specialized task.
      operationId: lemurTask
      x-fern-sdk-group-name: lemur
      x-fern-sdk-method-name: task
      description: Use LeMUR to ask anything with Custom Task
      requestBody:
        description: Parameters to run the custom task.
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/LemurTaskParameters"

      responses:
        "200":
          description: LeMUR task response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LemurTaskResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

  /lemur/v3/{request_id}:
    delete:
      tags:
        - LeMUR
      summary: Delete the data for a previously submitted LeMUR request.
      operationId: purgeLemurRequestData
      x-fern-sdk-group-name: lemur
      x-fern-sdk-method-name: purgeRequestData
      description: |
        Delete the data for a previously submitted LeMUR request.
        The LLM response data, as well as any context provided in the original request will be removed.
      parameters:
        - name: request_id
          in: path
          description: The ID of the LeMUR request whose data you want to delete. This would be found in the response of the original request.
          required: true
          schema:
            type: string
      responses:
        "200":
          description: LeMUR request data deleted.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/PurgeLemurRequestDataResponse"
        "400":
          $ref: "#/components/responses/BadRequest"
        "401":
          $ref: "#/components/responses/Unauthorized"
        "404":
          $ref: "#/components/responses/NotFound"
        "429":
          $ref: "#/components/responses/TooManyRequests"
        "500":
          $ref: "#/components/responses/InternalServerError"
        "503":
          $ref: "#/components/responses/ServiceUnavailable"
        "504":
          $ref: "#/components/responses/GatewayTimeout"

components:
  schemas:
    RedactedAudioResponse:
      type: object
      additionalProperties: false
      required:
        - status
        - redacted_audio_url
      properties:
        status:
          description: The status of the redacted audio
          $ref: "#/components/schemas/RedactedAudioStatus"
        redacted_audio_url:
          description: The URL of the redacted audio file
          type: string

    RedactedAudioStatus:
      description: The status of the redacted audio
      type: string
      enum:
        - redacted_audio_ready

    SubtitleFormat:
      description: Format of the subtitles
      type: string
      enum:
        - srt
        - vtt

    WordSearchResponse:
      type: object
      additionalProperties: false
      properties:
        id:
          description: The ID of the transcript
          type: string
        total_count:
          description: The total count of all matched instances. For e.g., word 1 matched 2 times, and word 2 matched 3 times, `total_count` will equal 5.
          type: integer
        matches:
          description: The matches of the search
          type: array
          items:
            $ref: "#/components/schemas/WordSearchMatch"
      required:
        - id
        - total_count
        - matches

    WordSearchMatch:
      type: object
      additionalProperties: false
      properties:
        text:
          description: The matched word
          type: string
        count:
          description: The total amount of times the word is in the transcript
          type: integer
        timestamps:
          description: An array of timestamps
          type: array
          items:
            $ref: "#/components/schemas/WordSearchTimestamp"
        indexes:
          description: An array of all index locations for that word within the `words` array of the completed transcript
          type: array
          items:
            type: integer
      required:
        - text
        - count
        - timestamps
        - indexes

    WordSearchTimestamp:
      description: An array of timestamps structured as [`start_time`, `end_time`] in milliseconds
      type: array
      items:
        type: integer

    Timestamp:
      description: Timestamp containing a start and end property in milliseconds.
      type: object
      additionalProperties: false
      properties:
        start:
          description: The start time in milliseconds
          type: integer
        end:
          description: The end time in milliseconds
          type: integer
      required:
        - start
        - end

    # This type is used by the Transcriber
    CreateTranscriptOptionalParameters:
      description: The parameters for creating a transcript
      type: object
      additionalProperties: false
      required: [audio_url]
      properties:
        language_code:
          description: |
            The language of your audio file. Possible values are found in [Supported Languages](https://www.assemblyai.com/docs/Concepts/supported_languages).
            The default value is 'en_us'.
          $ref: "#/components/schemas/TranscriptLanguageCode"

        punctuate:
          description: Enable Automatic Punctuation, can be true or false.
          type: boolean

        format_text:
          description: Enable Text Formatting, can be true or false.
          type: boolean

        dual_channel:
          description: Enable [Dual Channel](https://assemblyai.com/docs/Models/speech_recognition#dual-channel-transcription) transcription, can be true or false.
          type: boolean

        webhook_url:
          description: The URL to which we send webhooks upon trancription completion, if provided in the transcription request.
          type: string

        webhook_auth_header_name:
          description: The header name which should be sent back with webhook calls, if provided in the transcription request.
          type: [string, "null"]
          default: null

        webhook_auth_header_value:
          description: Defaults to null. Optionally allows a user to specify a header name and value to send back with a webhook call for added security.
          type: [string, "null"]
          default: null

        auto_highlights:
          description: Whether Key Phrases was enabled in the transcription request, either true or false
          type: boolean

        audio_start_from:
          description: The point in time, in milliseconds, to begin transcription from in your media file
          type: integer

        audio_end_at:
          description: The point in time, in milliseconds, to stop transcribing in your media file
          type: integer

        word_boost:
          description: The list of custom vocabulary to boost transcription probability for, if provided in the transcription request.
          type: array
          items:
            type: string

        boost_param:
          description: The word boost parameter value, if provided in the transcription request.
          $ref: "#/components/schemas/TranscriptBoostParam"

        filter_profanity:
          description: Filter profanity from the transcribed text, can be true or false.
          type: boolean

        redact_pii:
          description: Redact PII from the transcribed text using the Redact PII model, can be true or false
          type: boolean

        redact_pii_audio:
          description: Generate a copy of the original media file with spoken PII "beeped" out, can be true or false. See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more details.
          type: boolean

        redact_pii_audio_quality:
          description: Controls the filetype of the audio created by redact_pii_audio. Currently supports mp3 (default) and wav. See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more details.
          type: string
          default: mp3

        redact_pii_policies:
          description: The list of PII Redaction policies to enable. See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more details.
          type: array
          items:
            $ref: "#/components/schemas/PiiPolicy"

        redact_pii_sub:
          description: The replacement logic for detected PII, can be "entity_type" or "hash". See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more details.
          $ref: "#/components/schemas/SubstitutionPolicy"

        speaker_labels:
          description: Enable [Speaker diarization](https://www.assemblyai.com/docs/Models/speaker_diarization), can be true or false
          type: boolean

        speakers_expected:
          description: Tells the speaker label model how many speakers it should attempt to identify, up to 10. See [Speaker diarization](https://www.assemblyai.com/docs/Models/speaker_diarization) for more details.
          type: [integer, "null"]
          default: null

        content_safety:
          description: Enable [Content Moderation](https://www.assemblyai.com/docs/Models/content_moderation), can be true or false
          type: boolean

        iab_categories:
          description: Enable [Topic Detection](https://www.assemblyai.com/docs/Models/iab_classification), can be true or false
          type: boolean

        language_detection:
          description: Whether [Automatic language detection](https://www.assemblyai.com/docs/Models/speech_recognition#automatic-language-detection) was enabled in the transcription request, either true or false.
          type: boolean

        custom_spelling:
          description: Customize how words are spelled and formatted using to and from values
          type: array
          items:
            $ref: "#/components/schemas/TranscriptCustomSpelling"

        disfluencies:
          description: Transcribe Filler Words, like "umm", in your media file; can be true or false.
          type: boolean

        sentiment_analysis:
          description: Enable [Sentiment Analysis](https://www.assemblyai.com/docs/Models/sentiment_analysis), can be true or false
          type: boolean

        auto_chapters:
          description: Enable [Auto Chapters](https://www.assemblyai.com/docs/Models/auto_chapters), can be true or false
          type: boolean

        entity_detection:
          description: Enable [Entity Detection](https://www.assemblyai.com/docs/Models/entity_detection), can be true or false
          type: boolean

        speech_threshold:
          description: |
            Reject audio files that contain less than this fraction of speech.
            Valid values are in the range [0, 1] inclusive.
          type: [number, "null"]
          format: float
          minimum: 0
          maximum: 1
          default: null

        summarization:
          description: Enable [Summarization](https://www.assemblyai.com/docs/Models/summarization), can be true or false
          type: boolean

        summary_model:
          description: The model to summarize the transcript
          default: informative
          $ref: "#/components/schemas/SummaryModel"

        summary_type:
          description: The type of summary
          default: bullets
          $ref: "#/components/schemas/SummaryType"

        custom_topics:
          description: Whether custom topics was enabled in the transcription request, either true or false
          type: boolean

        topics:
          description: The list of custom topics provided if custom topics was enabled in the transcription request
          type: array
          items:
            type: string

    CreateTranscriptParameters:
      description: The parameters for creating a transcript
      type: object
      additionalProperties: false
      allOf:
        - $ref: "#/components/schemas/CreateTranscriptOptionalParameters"
        - type: object
          required: [audio_url]
          properties:
            audio_url:
              description: The URL of the audio or video file to transcribe.
              type: string

    SummaryModel:
      type: string
      description: The model to summarize the transcript
      default: informative
      enum:
        - informative
        - conversational
        - catchy

    SummaryType:
      type: string
      description: The type of summary
      default: bullets
      enum:
        - bullets
        - bullets_verbose
        - gist
        - headline
        - paragraph

    TranscriptBoostParam:
      type: string
      description: The word boost parameter value, if provided in the transcription request.
      enum:
        - low
        - default
        - high

    TranscriptCustomSpelling:
      description: Object containing words or phrases to replace, and the word or phrase to replace with
      type: object
      additionalProperties: false
      properties:
        from:
          description: Words or phrases to replace
          type: array
          items:
            description: Word or phrase to replace
            type: string
        to:
          description: Word or phrase to replace with
          type: string
      required: [from, to]

    TranscriptUtterance:
      type: object
      additionalProperties: false
      properties:
        channel:
          type: string
        confidence:
          type: number
          format: double
          minimum: 0
          maximum: 1
        start:
          type: integer
        end:
          type: integer
        text:
          type: string
        words:
          type: array
          items:
            $ref: "#/components/schemas/TranscriptWord"
      required:
        - channel
        - confidence
        - start
        - end
        - text
        - words

    SubstitutionPolicy:
      type: [string, "null"]
      description: The replacement logic for detected PII, can be "entity_type" or "hash". See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more details.
      enum:
        - entity_type
        - hash

    PiiPolicy:
      type: string
      enum:
        - medical_process
        - medical_condition
        - blood_type
        - drug
        - injury
        - number_sequence
        - email_address
        - date_of_birth
        - phone_number
        - us_social_security_number
        - credit_card_number
        - credit_card_expiration
        - credit_card_cvv
        - date
        - nationality
        - event
        - language
        - location
        - money_amount
        - person_name
        - person_age
        - organization
        - political_affiliation
        - occupation
        - religion
        - drivers_license
        - banking_information

    TranscriptLanguageCode:
      type: [string, "null"]
      description: |
        The language of your audio file. Possible values are found in [Supported Languages](https://www.assemblyai.com/docs/Concepts/supported_languages).
        The default value is 'en_us'.
      default: en_us
      enum:
        - en
        - en_au
        - en_uk
        - en_us
        - es
        - fr
        - de
        - it
        - pt
        - nl
        - hi
        - ja
        - zh
        - fi
        - ko
        - pl
        - ru
        - tr
        - uk
        - vi

    TranscriptStatus:
      type: string
      description: The status of your transcription. Possible values are queued, processing, completed, or error.
      enum:
        - queued
        - processing
        - completed
        - error
      x-fern-enum:
        queued:
          description: The audio file is in the queue to be processed by the API.
        processing:
          description: The audio file is being processed by the API.
        completed:
          description: The transcription job has been completed successfully.
        error:
          description: An error occurred while processing the audio file.

    Transcript:
      description: A transcript object
      type: object
      additionalProperties: false
      properties:
        id:
          description: The unique identifier of your transcription
          type: string

        language_model:
          description: The language model that was used for the transcription
          type: string
          deprecated: true

        acoustic_model:
          description: The acoustic model that was used for the transcription
          type: string
          deprecated: true

        status:
          description: The status of your transcription. Possible values are queued, processing, completed, or error.
          $ref: "#/components/schemas/TranscriptStatus"

        language_code:
          description: |
            The language of your audio file.
            Possible values are found in [Supported Languages](https://www.assemblyai.com/docs/Concepts/supported_languages).
            The default value is 'en_us'.
          $ref: "#/components/schemas/TranscriptLanguageCode"

        audio_url:
          description: The URL of the media that was transcribed
          type: string

        text:
          description: The textual transcript of your media file
          type: [string, "null"]

        words:
          description: |
            An array of temporally-sequential word objects, one for each word in the transcript.
            See [Speech recognition](https://www.assemblyai.com/docs/Models/speech_recognition) for more information.
          type: [array, "null"]
          items:
            $ref: "#/components/schemas/TranscriptWord"

        utterances:
          description: |
            When dual_channel or speaker_labels is enabled, a list of turn-by-turn utterance objects.
            See [Speaker diarization](https://www.assemblyai.com/docs/Models/speaker_diarization) for more information.
          type: [array, "null"]
          items:
            $ref: "#/components/schemas/TranscriptUtterance"

        confidence:
          description: The confidence score for the transcript, between 0.0 (low confidence) and 1.0 (high confidence)
          type: [number, "null"]
          format: double
          minimum: 0
          maximum: 1

        audio_duration:
          description: The duration of this transcript object's media file, in seconds
          type: [number, "null"]
          format: float

        punctuate:
          description: Whether Automatic Punctuation was enabled in the transcription request, either true or false.
          type: [boolean, "null"]

        format_text:
          description: Whether Text Formatting was enabled in the transcription request, either true or false
          type: [boolean, "null"]

        dual_channel:
          description: Whether [Dual channel transcription](https://www.assemblyai.com/docs/Models/speech_recognition#dual-channel-transcription) was enabled in the transcription request, either true or false
          type: [boolean, "null"]

        webhook_url:
          description: The URL to which we send webhooks upon trancription completion, if provided in the transcription request
          type: [string, "null"]

        webhook_status_code:
          description: The status code we received from your server when delivering your webhook, if a webhook URL was provided in the transcription request
          type: [integer, "null"]

        webhook_auth:
          description: Whether webhook authentication details were provided in the transcription request
          type: boolean

        webhook_auth_header_name:
          description: The header name which should be sent back with webhook calls, if provided in the transcription request
          type: [string, "null"]

        speed_boost:
          description: Whether speed boost was enabled in the transcription request
          type: [boolean, "null"]
          deprecated: true

        auto_highlights:
          description: Whether Key Phrases was enabled in the transcription request, either true or false
          type: boolean

        auto_highlights_result:
          description: |
            An array of results for the Key Phrases model, if it was enabled during the transcription request.
            See [Key phrases](https://www.assemblyai.com/docs/Models/key_phrases) for more information.
          $ref: "#/components/schemas/AutoHighlightsResult"

        audio_start_from:
          description: The point in time, in milliseconds, in the file at which the transcription was started, if provided in the transcription request
          type: [integer, "null"]

        audio_end_at:
          description: The point in time, in milliseconds, in the file at which the transcription was terminated, if provided in the transcription request
          type: [integer, "null"]

        word_boost:
          description: The list of custom vocabulary to boost transcription probability for, if provided in the transcription request
          type: array
          items:
            type: string

        boost_param:
          description: The word boost parameter value, if provided in the transcription request
          type: [string, "null"]

        filter_profanity:
          description: Whether [Profanity Filtering](https://www.assemblyai.com/docs/Models/speech_recognition#profanity-filtering) was enabled in the transcription request, either true or false
          type: [boolean, "null"]

        redact_pii:
          description: Whether [PII Redaction](https://www.assemblyai.com/docs/Models/pii_redaction) was enabled in the transcription request, either true or false
          type: boolean

        redact_pii_audio:
          description: |
            Whether a redacted version of the audio file was generated (enabled or disabled in the transcription request),
            either true or false. See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more information.
          type: [boolean, "null"]

        redact_pii_audio_quality:
          description: |
            The audio quality of the PII-redacted audio file, if enabled in the transcription request.
            See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more information.
          type: [string, "null"]

        redact_pii_policies:
          description: |
            The list of PII Redaction policies that were enabled, if PII Redaction is enabled.
            See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more information.
          type: [array, "null"]
          items:
            $ref: "#/components/schemas/PiiPolicy"

        redact_pii_sub:
          description: The replacement logic for detected PII, can be "entity_type" or "hash". See [PII redaction](https://www.assemblyai.com/docs/Models/pii_redaction) for more details.
          $ref: "#/components/schemas/SubstitutionPolicy"

        speaker_labels:
          description: Enable [Speaker diarization](https://www.assemblyai.com/docs/Models/speaker_diarization), can be true or false
          type: [boolean, "null"]

        speakers_expected:
          description: Defaults to null. Tells the speaker label model how many speakers it should attempt to identify, up to 10. See [Speaker diarization](https://www.assemblyai.com/docs/Models/speaker_diarization) for more details.
          type: [integer, "null"]

        content_safety:
          description: Enable [Content Moderation](https://www.assemblyai.com/docs/Models/content_moderation), can be true or false
          type: [boolean, "null"]

        content_safety_labels:
          description: |
            An array of results for the Content Moderation model, if it was enabled during the transcription request.
            See [Content moderation](https://www.assemblyai.com/docs/Models/content_moderation) for more information.
          type: [object, "null"]
          required:
            - status
            - results
          properties:
            status:
              description: Will be either success, or unavailable in the rare case that the Content Safety Labels model failed.
              $ref: "#/components/schemas/AudioIntelligenceModelStatus"
            results:
              type: array
              items:
                $ref: "#/components/schemas/ContentSafetyLabelResult"

        iab_categories:
          description: Enable [Topic Detection](https://www.assemblyai.com/docs/Models/iab_classification), can be true or false
          type: [boolean, "null"]

        iab_categories_result:
          description: |
            An array of results for the Topic Detection model, if it was enabled during the transcription request.
            See [Topic Detection](https://www.assemblyai.com/docs/Models/iab_classification) for more information.
          type: [object, "null"]
          required:
            - status
            - results
            - summary
          properties:
            status:
              description: Will be either success, or unavailable in the rare case that the Content Moderation model failed.
              $ref: "#/components/schemas/AudioIntelligenceModelStatus"
            results:
              description: An array of results for the Topic Detection model.
              type: array
              items:
                $ref: "#/components/schemas/TopicDetectionResult"
            summary:
              description: The overall relevance of topic to the entire audio file
              type: object
              additionalProperties:
                type: number
                format: double
                minimum: 0
                maximum: 1

        language_detection:
          description: Whether [Automatic language detection](https://www.assemblyai.com/docs/Models/speech_recognition#automatic-language-detection) was enabled in the transcription request, either true or false
          type: [boolean, "null"]

        custom_spelling:
          description: Customize how words are spelled and formatted using to and from values
          type: [array, "null"]
          items:
            $ref: "#/components/schemas/TranscriptCustomSpelling"

        auto_chapters:
          description: Enable [Auto Chapters](https://www.assemblyai.com/docs/Models/auto_chapters), can be true or false
          type: [boolean, "null"]

        chapters:
          description: An array of temporally sequential chapters for the audio file
          type: [array, "null"]
          items:
            $ref: "#/components/schemas/Chapter"

        summarization:
          description: Whether [Summarization](https://www.assemblyai.com/docs/Models/summarization) was enabled in the transcription request, either true or false
          type: boolean

        summary_type:
          description: The type of summary generated, if [Summarization](https://www.assemblyai.com/docs/Models/summarization) was enabled in the transcription request
          type: [string, "null"]

        summary_model:
          description: |
            The Summarization model used to generate the summary,
            if [Summarization](https://www.assemblyai.com/docs/Models/summarization) was enabled in the transcription request
          type: [string, "null"]

        summary:
          description: The generated summary of the media file, if [Summarization](https://www.assemblyai.com/docs/Models/summarization) was enabled in the transcription request
          type: [string, "null"]

        custom_topics:
          description: Whether custom topics was enabled in the transcription request, either true or false
          type: [boolean, "null"]

        topics:
          description: The list of custom topics provided if custom topics was enabled in the transcription request
          type: array
          items:
            type: string

        disfluencies:
          description: Transcribe Filler Words, like "umm", in your media file; can be true or false
          type: [boolean, "null"]

        sentiment_analysis:
          description: Enable [Sentiment Analysis](https://www.assemblyai.com/docs/Models/sentiment_analysis), can be true or false
          type: [boolean, "null"]

        sentiment_analysis_results:
          description: |
            An array of results for the Sentiment Analysis model, if it was enabled during the transcription request.
            See [Sentiment analysis](https://www.assemblyai.com/docs/Models/sentiment_analysis) for more information.
          type: [array, "null"]
          items:
            $ref: "#/components/schemas/SentimentAnalysisResult"

        entity_detection:
          description: Enable [Entity Detection](https://www.assemblyai.com/docs/Models/entity_detection), can be true or false
          type: [boolean, "null"]

        entities:
          description: |
            An array of results for the Entity Detection model, if it was enabled during the transcription request.
            See [Entity detection](https://www.assemblyai.com/docs/Models/entity_detection) for more information.
          type: [array, "null"]
          items:
            $ref: "#/components/schemas/Entity"

        speech_threshold:
          description: |
            Defaults to null. Reject audio files that contain less than this fraction of speech.
            Valid values are in the range [0, 1] inclusive.
          type: [number, "null"]
          minimum: 0
          maximum: 1
          format: float

        throttled:
          description: True while a request is throttled and false when a request is no longer throttled
          type: [boolean, "null"]

        error:
          description: Error message of why the transcript failed
          type: string
      required:
        - id
        - language_model
        - acoustic_model
        - status
        - audio_url
        - webhook_auth
        - auto_highlights
        - redact_pii
        - summarization

    Chapter:
      description: Chapter of the audio file
      type: object
      additionalProperties: false
      required:
        - gist
        - headline
        - summary
        - start
        - end
      properties:
        gist:
          description: An ultra-short summary (just a few words) of the content spoken in the chapter
          type: string
        headline:
          description: A single sentence summary of the content spoken during the chapter
          type: string
        summary:
          description: A one paragraph summary of the content spoken during the chapter
          type: string
        start:
          description: The starting time, in milliseconds, for the chapter
          type: integer
        end:
          description: The starting time, in milliseconds, for the chapter
          type: integer

    Entity:
      description: A detected entity
      type: object
      additionalProperties: false
      required:
        - entity_type
        - text
        - start
        - end
      properties:
        entity_type:
          description: The type of entity for the detected entity
          $ref: "#/components/schemas/EntityType"
        text:
          description: The text for the detected entity
          type: string
        start:
          description: The starting time, in milliseconds, at which the detected entity appears in the audio file
          type: integer
        end:
          description: The ending time, in milliseconds, for the detected entity in the audio file
          type: integer

    EntityType:
      description: The type of entity for the detected entity
      type: string
      enum:
        - banking_information
        - blood_type
        - credit_card_cvv
        - credit_card_expiration
        - credit_card_number
        - date
        - date_of_birth
        - drivers_license
        - drug
        - email_address
        - event
        - injury
        - language
        - location
        - medical_condition
        - medical_process
        - money_amount
        - nationality
        - occupation
        - organization
        - password
        - person_age
        - person_name
        - phone_number
        - political_affiliation
        - religion
        - time
        - url
        - us_social_security_number
      x-fern-enum:
        banking_information:
          description: Banking information, including account and routing numbers
        blood_type:
          description: Blood type (e.g., O-, AB positive)
        credit_card_cvv:
          description: |
            Credit card verification code (e.g., CVV: 080)
        credit_card_expiration:
          description: Expiration date of a credit card
        credit_card_number:
          description: Credit card number
        date:
          description: Specific calendar date (e.g., December 18)
        date_of_birth:
          description: |
            Date of Birth (e.g., Date of Birth: March 7, 1961)
        drivers_license:
          description: |
            Driver's license number (e.g., DL #356933-540)
        drug:
          description: Medications, vitamins, or supplements (e.g., Advil, Acetaminophen, Panadol)
        email_address:
          description: Email address (e.g., support@assemblyai.com)
        event:
          description: Name of an event or holiday (e.g., Olympics, Yom Kippur)
        injury:
          description: Bodily injury (e.g., I broke my arm, I have a sprained wrist)
        language:
          description: Name of a natural language (e.g., Spanish, French)
        location:
          description: Any location reference including mailing address, postal code, city, state, province, or country
        medical_condition:
          description: Name of a medical condition, disease, syndrome, deficit, or disorder (e.g., chronic fatigue syndrome, arrhythmia, depression)
        medical_process:
          description: Medical process, including treatments, procedures, and tests (e.g., heart surgery, CT scan)
        money_amount:
          description: Name and/or amount of currency (e.g., 15 pesos, $94.50)
        nationality:
          description: Terms indicating nationality, ethnicity, or race (e.g., American, Asian, Caucasian)
        occupation:
          description: Job title or profession (e.g., professor, actors, engineer, CPA)
        organization:
          description: Name of an organization (e.g., CNN, McDonalds, University of Alaska)
        password:
          description: Account passwords, PINs, access keys, or verification answers (e.g., 27%alfalfa, temp1234, My mother's maiden name is Smith)
        person_age:
          description: Number associated with an age (e.g., 27, 75)
        person_name:
          description: Name of a person (e.g., Bob, Doug Jones)
        phone_number:
          description: Telephone or fax number
        political_affiliation:
          description: Terms referring to a political party, movement, or ideology (e.g., Republican, Liberal)
        religion:
          description: Terms indicating religious affiliation (e.g., Hindu, Catholic)
        time:
          description: Expressions indicating clock times (e.g., 19:37:28, 10pm EST)
        url:
          description: Internet addresses (e.g., www.assemblyai.com)
        us_social_security_number:
          description: Social Security Number or equivalent

    SentimentAnalysisResult:
      description: The result of the sentiment analysis model.
      type: object
      additionalProperties: false
      required:
        - text
        - start
        - end
        - sentiment
        - confidence
      properties:
        text:
          description: The transcript of the sentence
          type: string
        start:
          description: The starting time, in milliseconds, of the sentence
          type: integer
        end:
          description: The ending time, in milliseconds, of the sentence
          type: integer
        sentiment:
          description: The detected sentiment for the sentence, one of POSITIVE, NEUTRAL, NEGATIVE
          $ref: "#/components/schemas/Sentiment"
        confidence:
          description: The confidence score for the detected sentiment of the sentence, from 0 to 1
          type: number
          format: double
          minimum: 0
          maximum: 1
        speaker:
          description: The speaker of the sentence if Speaker Diarization is enabled, else null
          type: [string, "null"]

    Sentiment:
      enum:
        - POSITIVE
        - NEUTRAL
        - NEGATIVE

    TopicDetectionResult:
      description: THe result of the topic detection model.
      type: object
      additionalProperties: false
      required:
        - text
      properties:
        text:
          description: The text in the transcript in which a detected topic occurs
          type: string
        labels:
          type: array
          items:
            type: object
            additionalProperties: false
            required:
              - relevance
              - label
            properties:
              relevance:
                description: How relevant the detected topic is of a detected topic
                type: number
                format: double
                minimum: 0
                maximum: 1
              label:
                description: The IAB taxonomical label for the label of the detected topic, where > denotes supertopic/subtopic relationship
                type: string
        timestamp:
          $ref: "#/components/schemas/Timestamp"

    ContentSafetyLabel:
      type: object
      additionalProperties: false
      required:
        - label
        - confidence
        - severity
      properties:
        label:
          description: The label of the sensitive topic
          type: string
        confidence:
          description: The confidence score for the topic being discussed, from 0 to 1
          type: number
          format: double
          minimum: 0
          maximum: 1
        severity:
          description: How severely the topic is discussed in the section, from 0 to 1
          type: number
          format: double
          minimum: 0
          maximum: 1

    ContentSafetyLabelResult:
      type: object
      additionalProperties: false
      required:
        - text
        - labels
        - sentences_idx_start
        - sentences_idx_end
        - timestamp
        - summary
        - severity_score_summary
      properties:
        text:
          description: The transcript of the section flagged by the Content Moderation model
          type: string
        labels:
          description: An array of objects, one per sensitive topic that was detected in the section
          type: array
          items:
            $ref: "#/components/schemas/ContentSafetyLabel"
        sentences_idx_start:
          description: The sentence index at which the section begins
          type: integer
        sentences_idx_end:
          description: The sentence index at which the section ends
          type: integer
        timestamp:
          description: Timestamp information for the section
          $ref: "#/components/schemas/Timestamp"
        summary:
          description: A summary of the Content Moderation confidence results for the entire audio file
          type: object
          additionalProperties:
            description: A confidence score for the presence of the sensitive topic "topic" across the entire audio file
            type: number
            format: double
            minimum: 0
            maximum: 1
        severity_score_summary:
          description: A summary of the Content Moderation severity results for the entire audio file
          type: object
          additionalProperties:
            $ref: "#/components/schemas/SeverityScoreSummary"

    SeverityScoreSummary:
      type: object
      required:
        - low
        - medium
        - high
      properties:
        low:
          type: number
          format: double
          minimum: 0
          maximum: 1
        medium:
          type: number
          format: double
          minimum: 0
          maximum: 1
        high:
          type: number
          format: double
          minimum: 0
          maximum: 1

    AutoHighlightsResult:
      description: |
        An array of results for the Key Phrases model, if it was enabled during the transcription request.
        See [Key phrases](https://www.assemblyai.com/docs/Models/key_phrases) for more information.
      type: [object, "null"]
      required:
        - results
      properties:
        results:
          description: A temporally-sequential array of Key Phrases
          type: array
          items:
            $ref: "#/components/schemas/AutoHighlightResult"

    AutoHighlightResult:
      type: object
      additionalProperties: false
      required:
        - count
        - rank
        - text
        - timestamps
      properties:
        count:
          description: The total number of times the key phrase appears in the audio file
          type: integer
        rank:
          description: The total relevancy to the overall audio file of this key phrase - a greater number means more relevant
          type: number
          format: float
          minimum: 0
          maximum: 1
        text:
          description: The text itself of the key phrase
          type: string
        timestamps:
          description: The timestamp of the of the key phrase
          type: array
          items:
            $ref: "#/components/schemas/Timestamp"

    TranscriptWord:
      type: object
      additionalProperties: false
      required:
        - confidence
        - start
        - end
        - text
      properties:
        confidence:
          type: number
          format: double
          minimum: 0
          maximum: 1
        start:
          type: integer
        end:
          type: integer
        text:
          type: string
        speaker:
          type: [string, "null"]

    TranscriptSentence:
      type: object
      additionalProperties: false
      required:
        - text
        - start
        - end
        - confidence
        - words
      properties:
        text:
          type: string
        start:
          type: integer
        end:
          type: integer
        confidence:
          type: number
          format: double
          minimum: 0
          maximum: 1
        words:
          type: array
          items:
            $ref: "#/components/schemas/TranscriptWord"

    SentencesResponse:
      type: object
      additionalProperties: false
      required:
        - id
        - confidence
        - audio_duration
        - sentences
      properties:
        id:
          type: string
        confidence:
          type: number
          format: double
          minimum: 0
          maximum: 1
        audio_duration:
          type: number
        sentences:
          type: array
          items:
            $ref: "#/components/schemas/TranscriptSentence"

    TranscriptParagraph:
      type: object
      additionalProperties: false
      required:
        - text
        - start
        - end
        - confidence
        - words
      properties:
        text:
          type: string
        start:
          type: integer
        end:
          type: integer
        confidence:
          type: number
          format: double
          minimum: 0
          maximum: 1
        words:
          type: array
          items:
            $ref: "#/components/schemas/TranscriptWord"

    ParagraphsResponse:
      type: object
      additionalProperties: false
      required:
        - id
        - confidence
        - audio_duration
        - paragraphs
      properties:
        id:
          type: string
        confidence:
          type: number
          format: double
          minimum: 0
          maximum: 1
        audio_duration:
          type: number
        paragraphs:
          type: array
          items:
            $ref: "#/components/schemas/TranscriptParagraph"

    PageDetails:
      type: object
      additionalProperties: false
      required:
        - limit
        - result_count
        - current_url
        - prev_url
      properties:
        limit:
          type: integer
        result_count:
          type: integer
        current_url:
          type: string
        prev_url:
          type: string
        next_url:
          type: [string, "null"]

    TranscriptListParameters:
      type: object
      additionalProperties: false
      properties:
        limit:
          description: Maximum amount of transcripts to retrieve
          type: integer
          format: int64
          minimum: 1
          maximum: 200
          default: 10
        status:
          description: Filter by transcript status
          $ref: "#/components/schemas/TranscriptStatus"
        created_on:
          description: Only get transcripts created on this date
          type: string
          format: date
        before_id:
          description: Get transcripts that were created before this transcript ID
          type: string
        after_id:
          description: Get transcripts that were created after this transcript ID
          type: string
        throttled_only:
          description: Only get throttled transcripts, overrides the status filter
          type: boolean

    TranscriptListItem:
      type: object
      additionalProperties: false
      required:
        - id
        - resource_url
        - status
        - created
        - audio_url
      properties:
        id:
          type: string
        resource_url:
          type: string
        status:
          $ref: "#/components/schemas/TranscriptStatus"
        created:
          type: string
          pattern: '^(?:(\d{4}-\d{2}-\d{2})T(\d{2}:\d{2}:\d{2}(?:\.\d+)?))$'
          x-fern-type: datetime
        completed:
          type: [string, "null"]
          pattern: '^(?:(\d{4}-\d{2}-\d{2})T(\d{2}:\d{2}:\d{2}(?:\.\d+)?))$'
          x-fern-type: datetime
        audio_url:
          type: string

    TranscriptList:
      type: object
      additionalProperties: false
      required:
        - page_details
        - transcripts
      properties:
        page_details:
          $ref: "#/components/schemas/PageDetails"
        transcripts:
          type: array
          items:
            $ref: "#/components/schemas/TranscriptListItem"

    UploadedFile:
      type: object
      additionalProperties: false
      required:
        - upload_url
      properties:
        upload_url:
          description: A URL that points to your audio file, accessible only by AssemblyAI's servers
          type: string

    CreateRealtimeTemporaryTokenParameters:
      type: object
      additionalProperties: false
      properties:
        expires_in:
          description: The amount of time until the token expires in seconds.
          type: integer
          minimum: 60
      required: [expires_in]

    RealtimeTemporaryTokenResponse:
      type: object
      additionalProperties: false
      required:
        - token
      properties:
        token:
          description: The temporary authentication token for real-time transcription
          type: string

    AudioIntelligenceModelStatus:
      type: string
      description: Will be either success, or unavailable in the rare case that the model failed.
      enum:
        - success
        - unavailable

    PurgeLemurRequestDataResponse:
      type: object
      additionalProperties: false
      properties:
        request_id:
          type: string
          description: The ID of the LeMUR request
        request_id_to_purge:
          type: string
          description: The ID of the deletion request of the LeMUR request
        deleted:
          type: boolean
          description: Whether the request data was deleted.
      required:
        - request_id
        - request_id_to_purge
        - deleted

    # This is to have a type that can be used to get the ID so it can be deleted
    LemurBaseResponse:
      type: object
      additionalProperties: false
      properties:
        request_id:
          description: The ID of the LeMUR request
          type: string
      required: [request_id]

    LemurSummaryResponse:
      allOf:
        - $ref: "#/components/schemas/LemurBaseResponse"
        - type: object
          additionalProperties: false
          properties:
            response:
              description: The response generated by LeMUR.
              type: string
          required: [response]

    LemurQuestionAnswerResponse:
      allOf:
        - $ref: "#/components/schemas/LemurBaseResponse"
        - type: object
          additionalProperties: false
          properties:
            response:
              description: The answers generated by LeMUR and their questions.
              type: array
              items:
                $ref: "#/components/schemas/LemurQuestionAnswer"
          required: [response]

    LemurQuestionAnswer:
      type: object
      description: An answer generated by LeMUR and its question.
      additionalProperties: false
      properties:
        question:
          description: The question for LeMUR to answer.
          type: string
        answer:
          description: The answer generated by LeMUR.
          type: string
      required: [question, answer]

    LemurActionItemsResponse:
      allOf:
        - $ref: "#/components/schemas/LemurBaseResponse"
        - type: object
          additionalProperties: false
          properties:
            response:
              description: The response generated by LeMUR.
              type: string
          required: [response]

    LemurTaskResponse:
      allOf:
        - $ref: "#/components/schemas/LemurBaseResponse"
        - type: object
          additionalProperties: false
          properties:
            response:
              description: The response generated by LeMUR.
              type: string
          required: [response]

    LemurBaseParameters:
      type: object
      additionalProperties: false
      properties:
        transcript_ids:
          description: A list of completed transcripts with text. Up to 100 files max, or 100 hours max. Whichever is lower.
          type: array
          items:
            type: string
        context:
          description: Context to provide the model. This can be a string or a free-form JSON value.
          oneOf:
            - type: string
            - type: object
              additionalProperties: true
        final_model:
          $ref: "#/components/schemas/LemurModel"
        max_output_size:
          description: Max output size in tokens. Up to 4000 allowed.
          type: integer
        temperature:
          description: |
            The temperature to use for the model.
            Higher values result in answers that are more creative, lower values are more conservative.
            Can be any value between 0.0 and 1.0 inclusive.
          type: number
          format: float
          minimum: 0
          maximum: 1
      required: [transcript_ids]

    LemurSummaryParameters:
      allOf:
        - $ref: "#/components/schemas/LemurBaseParameters"
        - type: object
          additionalProperties: false
          properties:
            answer_format:
              description: |
                How you want the summary to be returned. This can be any text. Examples: "TLDR", "bullet points"
              type: string

    LemurQuestionAnswerParameters:
      allOf:
        - $ref: "#/components/schemas/LemurBaseParameters"
        - type: object
          additionalProperties: false
          properties:
            questions:
              description: A list of questions to ask.
              type: array
              items:
                $ref: "#/components/schemas/LemurQuestion"
          required: [questions]

    LemurQuestion:
      type: object
      additionalProperties: false
      required: [question]
      properties:
        question:
          description: The question you wish to ask. For more complex questions use default model.
          type: string
        context:
          description: Any context about the transcripts you wish to provide. This can be a string, or free-form JSON.
          oneOf:
            - type: string
            - type: object
              additionalProperties: true
        answer_format:
          description: |
            How you want the answer to be returned. This can be any text. Can't be used with answer_options. Examples: "short sentence", "bullet points"
          type: string
        answer_options:
          description: |
            What discrete options to return. Useful for precise responses. Can't be used with answer_format. Example: ["Yes", "No"]
          type: array
          items:
            type: string

    LemurActionItemsParameters:
      allOf:
        - $ref: "#/components/schemas/LemurBaseParameters"

    LemurTaskParameters:
      allOf:
        - $ref: "#/components/schemas/LemurBaseParameters"
        - type: object
          additionalProperties: false
          properties:
            prompt:
              description: Your text to prompt the model to produce a desired output, including any context you want to pass into the model.
              type: string
          required: [prompt]

    LemurModel:
      type: string
      description: |
        The model that is used for the final prompt after compression is performed (options: "basic" and "default").
      enum:
        - default
        - basic

    Error:
      type: object
      additionalProperties: false
      required: [error]
      properties:
        error:
          description: Error message
          type: string
        status:
          type: string
          const: error

  responses:
    BadRequest:
      description: Bad Request
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
    Unauthorized:
      description: Unauthorized
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
    NotFound:
      description: Not found
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
    TooManyRequests:
      description: Too Many Requests
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
    InternalServerError:
      description: An error occurred while processing the request
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
    ServiceUnavailable:
      description: Service Unavailable
    GatewayTimeout:
      description: Gateway Timeout

  securitySchemes:
    ApiKey:
      type: apiKey
      in: header
      name: Authorization
