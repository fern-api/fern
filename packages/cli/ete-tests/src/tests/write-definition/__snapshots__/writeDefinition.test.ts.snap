// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`validate > petstore 1`] = `
[
  {
    "contents": "types:
  Error:
    properties:
      code: integer
      message: string
    source:
      openapi: openapi/openapi.yml
  Pet:
    properties:
      id: long
      name: string
      tag: optional<string>
    source:
      openapi: openapi/openapi.yml
  Pets: list<Pet>
",
    "name": "__package__.yml",
    "type": "file",
  },
  {
    "contents": "default-environment: Default
display-name: Swagger Petstore
environments:
  Default: http://petstore.swagger.io/v1
error-discrimination:
  strategy: status-code
name: api
",
    "name": "api.yml",
    "type": "file",
  },
  {
    "contents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    createPets:
      auth: false
      display-name: Create a pet
      examples:
        - {}
      method: POST
      path: /pets
      source:
        openapi: openapi/openapi.yml
    listPets:
      auth: false
      display-name: List all pets
      examples:
        - response:
            body:
              - id: 1000000
                name: name
                tag: tag
      method: GET
      path: /pets
      request:
        name: ListPetsRequest
        query-parameters:
          limit:
            docs: How many items to return at one time (max 100)
            type: optional<integer>
            validation:
              max: 100
      response:
        docs: A paged array of pets
        status-code: 200
        type: root.Pets
      source:
        openapi: openapi/openapi.yml
    showPetById:
      auth: false
      display-name: Info for a specific pet
      examples:
        - path-parameters:
            petId: petId
          response:
            body:
              id: 1000000
              name: name
              tag: tag
      method: GET
      path: /pets/{petId}
      path-parameters:
        petId:
          docs: The id of the pet to retrieve
          type: string
      response:
        docs: Expected response to a valid request
        status-code: 200
        type: root.Pet
      source:
        openapi: openapi/openapi.yml
  source:
    openapi: openapi/openapi.yml
",
    "name": "pets.yml",
    "type": "file",
  },
]
`;

exports[`validate header overrides > header-overrides 1`] = `
[
  {
    "contents": "types:
  Error:
    properties:
      code: integer
      message: string
    source:
      openapi: openapi/openapi.yml
  Pet:
    properties:
      id: long
      name: string
      tag: optional<string>
    source:
      openapi: openapi/openapi.yml
  Pets: list<Pet>
",
    "name": "__package__.yml",
    "type": "file",
  },
  {
    "contents": "default-environment: Default
display-name: Swagger Petstore
environments:
  Default: http://petstore.swagger.io/v1
error-discrimination:
  strategy: status-code
headers:
  X-Dummy-Header: optional<string>
name: api
",
    "name": "api.yml",
    "type": "file",
  },
  {
    "contents": "imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    createPets:
      auth: false
      display-name: Create a pet
      examples:
        - {}
      method: POST
      path: /pets
      source:
        openapi: openapi/openapi.yml
    listPets:
      auth: false
      display-name: List all pets
      examples:
        - response:
            body:
              - id: 1000000
                name: name
                tag: tag
      method: GET
      path: /pets
      request:
        name: ListPetsRequest
        query-parameters:
          limit:
            docs: How many items to return at one time (max 100)
            type: optional<integer>
            validation:
              max: 100
      response:
        docs: A paged array of pets
        status-code: 200
        type: root.Pets
      source:
        openapi: openapi/openapi.yml
    showPetById:
      auth: false
      display-name: Info for a specific pet
      examples:
        - path-parameters:
            petId: petId
          response:
            body:
              id: 1000000
              name: name
              tag: tag
      method: GET
      path: /pets/{petId}
      path-parameters:
        petId:
          docs: The id of the pet to retrieve
          type: string
      response:
        docs: Expected response to a valid request
        status-code: 200
        type: root.Pet
      source:
        openapi: openapi/openapi.yml
  source:
    openapi: openapi/openapi.yml
",
    "name": "pets.yml",
    "type": "file",
  },
]
`;

exports[`validate namespaced API from Cohere > namespaced-fleshedout 1`] = `
[
  {
    "contents": "{}
",
    "name": "__package__.yml",
    "type": "file",
  },
  {
    "contents": "auth: BearerAuthScheme
auth-schemes:
  BearerAuthScheme:
    scheme: bearer
    token:
      env: CO_API_KEY
default-environment: Production
display-name: API Reference
environments:
  Production: https://api.cohere.com
error-discrimination:
  strategy: status-code
name: api
",
    "name": "api.yml",
    "type": "file",
  },
  {
    "contents": [
      {
        "contents": "types:
  BadRequestErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  ChatRequestPromptTruncation:
    docs: >
      Defaults to \`AUTO\` when \`connectors\` are specified and \`OFF\` in all other
      cases.


      Dictates how the prompt will be constructed.


      With \`prompt_truncation\` set to "AUTO", some elements from \`chat_history\`
      and \`documents\` will be dropped in an attempt to construct a prompt that
      fits within the model's context length limit. During this process the
      order of the documents and chat history will be changed and ranked by
      relevance.


      With \`prompt_truncation\` set to "AUTO_PRESERVE_ORDER", some elements from
      \`chat_history\` and \`documents\` will be dropped in an attempt to construct
      a prompt that fits within the model's context length limit. During this
      process the order of the documents and chat history will be preserved as
      they are inputted into the API.


      With \`prompt_truncation\` set to "OFF", no elements will be dropped. If the
      sum of the inputs exceeds the model's context length limit, a
      \`TooManyTokens\` error will be returned.


      Compatible Deployments: 
       - AUTO: Cohere Platform Only
       - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
    enum:
      - 'OFF'
      - AUTO
      - AUTO_PRESERVE_ORDER
    inline: true
    source:
      openapi: openapi/cohere.yaml
  ChatRequestSafetyMode:
    docs: >
      Used to select the [safety instruction](/docs/safety-modes) inserted into
      the prompt. Defaults to \`CONTEXTUAL\`.

      When \`NONE\` is specified, the safety instruction will be omitted.


      Safety modes are not yet configurable in combination with \`tools\`,
      \`tool_results\` and \`documents\` parameters.


      **Note**: This parameter is only compatible with models [Command R
      08-2024](/docs/command-r#august-2024-release), [Command R+
      08-2024](/docs/command-r-plus#august-2024-release) and newer.


      Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock,
      Private Deployments
    enum:
      - CONTEXTUAL
      - STRICT
      - NONE
    inline: true
    source:
      openapi: openapi/cohere.yaml
  ClientClosedRequestErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  ForbiddenErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  GatewayTimeoutErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  InternalServerErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  InvalidTokenErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  NotFoundErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  NotImplementedErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  ServiceUnavailableErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  TooManyRequestsErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  UnauthorizedErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
  UnprocessableEntityErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere.yaml
errors:
  BadRequestError:
    docs: >
      This error is returned when the request is not well formed. This could be
      because:
        - JSON is invalid
        - The request is missing required fields
        - The request contains an invalid combination of fields
    examples:
      - value: {}
    status-code: 400
    type: unknown
  ClientClosedRequestError:
    docs: |
      This error is returned when a request is cancelled by the user.
    examples:
      - value: {}
    status-code: 499
    type: unknown
  ForbiddenError:
    docs: >
      This error indicates that the operation attempted to be performed is not
      allowed. This could be because:
        - The api token is invalid
        - The user does not have the necessary permissions
    examples:
      - value: {}
    status-code: 403
    type: unknown
  GatewayTimeoutError:
    docs: >
      This error is returned when a request to the server times out. This could
      be due to:
        - An internal services taking too long to respond
    examples:
      - value: {}
    status-code: 504
    type: unknown
  InternalServerError:
    docs: |
      This error is returned when an uncategorized internal server error occurs.
    examples:
      - value: {}
    status-code: 500
    type: unknown
  InvalidTokenError:
    docs: >
      This error is returned when a request or response contains a deny-listed
      token.
    examples:
      - value: {}
    status-code: 498
    type: unknown
  NotFoundError:
    docs: >
      This error is returned when a resource is not found. This could be
      because:
        - The endpoint does not exist
        - The resource does not exist eg model id, dataset id
    examples:
      - value: {}
    status-code: 404
    type: unknown
  NotImplementedError:
    docs: |
      This error is returned when the requested feature is not implemented.
    examples:
      - value: {}
    status-code: 501
    type: unknown
  ServiceUnavailableError:
    docs: >
      This error is returned when the service is unavailable. This could be due
      to:
        - Too many users trying to access the service at the same time
    examples:
      - value: {}
    status-code: 503
    type: unknown
  TooManyRequestsError:
    docs: Too many requests
    examples:
      - value: {}
    status-code: 429
    type: unknown
  UnauthorizedError:
    docs: >
      This error indicates that the operation attempted to be performed is not
      allowed. This could be because:
        - The api token is invalid
        - The user does not have the necessary permissions
    examples:
      - value: {}
    status-code: 401
    type: unknown
  UnprocessableEntityError:
    docs: >
      This error is returned when the request is not well formed. This could be
      because:
        - JSON is invalid
        - The request is missing required fields
        - The request contains an invalid combination of fields
    examples:
      - value: {}
    status-code: 422
    type: unknown
service:
  auth: false
  base-path: ''
  endpoints:
    chat:
      audiences:
        - public
      auth: true
      display-name: Chat
      docs: >
        Generates a text response to a user message.

        To learn how to use the Chat API and RAG follow our [Text Generation
        guides](https://docs.cohere.com/docs/chat-api).
      errors:
        - BadRequestError
        - UnauthorizedError
        - ForbiddenError
        - NotFoundError
        - UnprocessableEntityError
        - TooManyRequestsError
        - InvalidTokenError
        - ClientClosedRequestError
        - InternalServerError
        - NotImplementedError
        - ServiceUnavailableError
        - GatewayTimeoutError
      examples:
        - request:
            message: message
          response:
            body:
              - string
      method: POST
      path: /v1/chat
      request:
        body:
          properties:
            chat_history:
              audiences:
                - public
              docs: >
                A list of previous messages between the user and the model,
                giving the model conversational context for responding to the
                user's \`message\`.


                Each item represents a single message in the chat history,
                excluding the current user turn. It has two properties: \`role\`
                and \`message\`. The \`role\` identifies the sender (\`CHATBOT\`,
                \`SYSTEM\`, or \`USER\`), while the \`message\` contains the text
                content.


                The chat_history parameter should not be used for \`SYSTEM\`
                messages in most cases. Instead, to add a \`SYSTEM\` role message
                at the beginning of a conversation, the \`preamble\` parameter
                should be used.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              type: optional<list<unknown>>
            conversation_id:
              audiences:
                - public
              docs: >
                An alternative to \`chat_history\`.


                Providing a \`conversation_id\` creates or resumes a persisted
                conversation with the specified ID. The ID can be any non empty
                string.


                Compatible Deployments: Cohere Platform
              type: optional<string>
            force_single_step:
              audiences:
                - public
              docs: Forces the chat to be single step. Defaults to \`false\`.
              type: optional<boolean>
            message:
              audiences:
                - public
              docs: >
                Text input for the model to respond to.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              type: string
            model:
              audiences:
                - public
              docs: >
                Defaults to \`command-r-plus-08-2024\`.


                The name of a compatible [Cohere
                model](https://docs.cohere.com/docs/models) or the ID of a
                [fine-tuned](https://docs.cohere.com/docs/chat-fine-tuning)
                model.


                Compatible Deployments: Cohere Platform, Private Deployments
              type: optional<string>
            preamble:
              audiences:
                - public
              docs: >
                When specified, the default Cohere preamble will be replaced
                with the provided one. Preambles are a part of the prompt used
                to adjust the model's overall behavior and conversation style,
                and use the \`SYSTEM\` role.


                The \`SYSTEM\` role is also used for the contents of the optional
                \`chat_history=\` parameter. When used with the \`chat_history=\`
                parameter it adds content throughout a conversation. Conversely,
                when used with the \`preamble=\` parameter it adds content at the
                start of the conversation only.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              type: optional<string>
            prompt_truncation:
              audiences:
                - public
              docs: >
                Defaults to \`AUTO\` when \`connectors\` are specified and \`OFF\` in
                all other cases.


                Dictates how the prompt will be constructed.


                With \`prompt_truncation\` set to "AUTO", some elements from
                \`chat_history\` and \`documents\` will be dropped in an attempt to
                construct a prompt that fits within the model's context length
                limit. During this process the order of the documents and chat
                history will be changed and ranked by relevance.


                With \`prompt_truncation\` set to "AUTO_PRESERVE_ORDER", some
                elements from \`chat_history\` and \`documents\` will be dropped in
                an attempt to construct a prompt that fits within the model's
                context length limit. During this process the order of the
                documents and chat history will be preserved as they are
                inputted into the API.


                With \`prompt_truncation\` set to "OFF", no elements will be
                dropped. If the sum of the inputs exceeds the model's context
                length limit, a \`TooManyTokens\` error will be returned.


                Compatible Deployments: 
                 - AUTO: Cohere Platform Only
                 - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
              type: optional<ChatRequestPromptTruncation>
            safety_mode:
              audiences:
                - public
              availability: pre-release
              docs: >
                Used to select the [safety instruction](/docs/safety-modes)
                inserted into the prompt. Defaults to \`CONTEXTUAL\`.

                When \`NONE\` is specified, the safety instruction will be
                omitted.


                Safety modes are not yet configurable in combination with
                \`tools\`, \`tool_results\` and \`documents\` parameters.


                **Note**: This parameter is only compatible with models [Command
                R 08-2024](/docs/command-r#august-2024-release), [Command R+
                08-2024](/docs/command-r-plus#august-2024-release) and newer.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              type: optional<ChatRequestSafetyMode>
            stream:
              audiences:
                - public
              docs: >
                Defaults to \`false\`.


                When \`true\`, the response will be a JSON stream of events. The
                final event will contain the complete response, and will have an
                \`event_type\` of \`"stream-end"\`.


                Streaming is beneficial for user interfaces that render the
                contents of the response piece by piece, as it gets generated.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              type: optional<boolean>
        content-type: application/json
        headers:
          Accepts:
            docs: >
              Pass text/event-stream to receive the streamed response as
              server-sent events. The default is \`\\n\` delimited events.
            name: accepts
            type: optional<literal<"text/event-stream">>
        name: ChatRequest
      response:
        docs: OK
        status-code: 200
        type: list<string>
      source:
        openapi: openapi/cohere.yaml
  source:
    openapi: openapi/cohere.yaml
",
        "name": "__package__.yml",
        "type": "file",
      },
    ],
    "name": "v1",
    "type": "directory",
  },
  {
    "contents": [
      {
        "contents": "types:
  BadRequestErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  ClientClosedRequestErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  ForbiddenErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  GatewayTimeoutErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  InternalServerErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  InvalidTokenErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  NotFoundErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  NotImplementedErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  ServiceUnavailableErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  TooManyRequestsErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  UnauthorizedErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
  UnprocessableEntityErrorBody:
    properties:
      data: optional<string>
    source:
      openapi: openapi/cohere-v2.yaml
errors:
  BadRequestError:
    docs: >
      This error is returned when the request is not well formed. This could be
      because:
        - JSON is invalid
        - The request is missing required fields
        - The request contains an invalid combination of fields
    examples:
      - value: {}
    status-code: 400
    type: unknown
  ClientClosedRequestError:
    docs: |
      This error is returned when a request is cancelled by the user.
    examples:
      - value: {}
    status-code: 499
    type: unknown
  ForbiddenError:
    docs: >
      This error indicates that the operation attempted to be performed is not
      allowed. This could be because:
        - The api token is invalid
        - The user does not have the necessary permissions
    examples:
      - value: {}
    status-code: 403
    type: unknown
  GatewayTimeoutError:
    docs: >
      This error is returned when a request to the server times out. This could
      be due to:
        - An internal services taking too long to respond
    examples:
      - value: {}
    status-code: 504
    type: unknown
  InternalServerError:
    docs: |
      This error is returned when an uncategorized internal server error occurs.
    examples:
      - value: {}
    status-code: 500
    type: unknown
  InvalidTokenError:
    docs: >
      This error is returned when a request or response contains a deny-listed
      token.
    examples:
      - value: {}
    status-code: 498
    type: unknown
  NotFoundError:
    docs: >
      This error is returned when a resource is not found. This could be
      because:
        - The endpoint does not exist
        - The resource does not exist eg model id, dataset id
    examples:
      - value: {}
    status-code: 404
    type: unknown
  NotImplementedError:
    docs: |
      This error is returned when the requested feature is not implemented.
    examples:
      - value: {}
    status-code: 501
    type: unknown
  ServiceUnavailableError:
    docs: >
      This error is returned when the service is unavailable. This could be due
      to:
        - Too many users trying to access the service at the same time
    examples:
      - value: {}
    status-code: 503
    type: unknown
  TooManyRequestsError:
    docs: Too many requests
    examples:
      - value: {}
    status-code: 429
    type: unknown
  UnauthorizedError:
    docs: >
      This error indicates that the operation attempted to be performed is not
      allowed. This could be because:
        - The api token is invalid
        - The user does not have the necessary permissions
    examples:
      - value: {}
    status-code: 401
    type: unknown
  UnprocessableEntityError:
    docs: >
      This error is returned when the request is not well formed. This could be
      because:
        - JSON is invalid
        - The request is missing required fields
        - The request contains an invalid combination of fields
    examples:
      - value: {}
    status-code: 422
    type: unknown
",
        "name": "__package__.yml",
        "type": "file",
      },
      {
        "contents": "imports:
  v2Root: __package__.yml
types:
  V2ChatRequestSafetyMode:
    docs: >
      Used to select the [safety instruction](/docs/safety-modes) inserted into
      the prompt. Defaults to \`CONTEXTUAL\`.

      When \`NONE\` is specified, the safety instruction will be omitted.


      Safety modes are not yet configurable in combination with \`tools\`,
      \`tool_results\` and \`documents\` parameters.


      **Note**: This parameter is only compatible with models [Command R
      08-2024](/docs/command-r#august-2024-release), [Command R+
      08-2024](/docs/command-r-plus#august-2024-release) and newer.


      Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock,
      Private Deployments
    enum:
      - CONTEXTUAL
      - STRICT
      - NONE
    inline: true
    source:
      openapi: openapi/cohere-v2.yaml
service:
  auth: false
  base-path: ''
  endpoints:
    chat:
      audiences:
        - v2-beta
      auth: true
      display-name: Chat with the model
      docs: >
        Generates a message from the model in response to a provided
        conversation. To learn how to use the Chat API with Streaming and RAG
        follow our Text Generation guides.
      errors:
        - v2Root.BadRequestError
        - v2Root.UnauthorizedError
        - v2Root.ForbiddenError
        - v2Root.NotFoundError
        - v2Root.UnprocessableEntityError
        - v2Root.TooManyRequestsError
        - v2Root.InvalidTokenError
        - v2Root.ClientClosedRequestError
        - v2Root.InternalServerError
        - v2Root.NotImplementedError
        - v2Root.ServiceUnavailableError
        - v2Root.GatewayTimeoutError
      examples:
        - request:
            model: model
          response:
            body:
              - string
      method: POST
      path: /v2/chat
      request:
        body:
          properties:
            documents:
              docs: >
                A list of relevant documents that the model can cite to generate
                a more accurate reply. Each document is either a string or
                document object with content and metadata.
              type: optional<list<string>>
            max_tokens:
              docs: >
                The maximum number of tokens the model will generate as part of
                the response. Note: Setting a low value may result in incomplete
                generations.
              type: optional<integer>
            model:
              docs: >-
                The name of a compatible [Cohere
                model](https://docs.cohere.com/docs/models) (such as command-r
                or command-r-plus) or the ID of a
                [fine-tuned](https://docs.cohere.com/docs/chat-fine-tuning)
                model.
              type: string
            return_prompt:
              docs: Whether to return the prompt in the response.
              type: optional<boolean>
            safety_mode:
              docs: >
                Used to select the [safety instruction](/docs/safety-modes)
                inserted into the prompt. Defaults to \`CONTEXTUAL\`.

                When \`NONE\` is specified, the safety instruction will be
                omitted.


                Safety modes are not yet configurable in combination with
                \`tools\`, \`tool_results\` and \`documents\` parameters.


                **Note**: This parameter is only compatible with models [Command
                R 08-2024](/docs/command-r#august-2024-release), [Command R+
                08-2024](/docs/command-r-plus#august-2024-release) and newer.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              type: optional<V2ChatRequestSafetyMode>
            stop_sequences:
              docs: >
                A list of up to 5 strings that the model will use to stop
                generation. If the model generates a string that matches any of
                the strings in the list, it will stop generating tokens and
                return the generated text up to that point not including the
                stop sequence.
              type: optional<list<string>>
            temperature:
              docs: >
                Defaults to \`0.3\`.


                A non-negative float that tunes the degree of randomness in
                generation. Lower temperatures mean less random generations, and
                higher temperatures mean more random generations.


                Randomness can be further maximized by increasing the  value of
                the \`p\` parameter.
              type: optional<float>
        content-type: application/json
        name: V2ChatRequest
      response:
        docs: OK
        status-code: 200
        type: list<string>
      source:
        openapi: openapi/cohere-v2.yaml
  source:
    openapi: openapi/cohere-v2.yaml
",
        "name": "v2.yml",
        "type": "file",
      },
    ],
    "name": "v2",
    "type": "directory",
  },
]
`;
