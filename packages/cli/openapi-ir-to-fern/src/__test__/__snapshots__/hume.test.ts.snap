// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`open api parser hume docs 1`] = `
{
  "definitionFiles": {
    "getJobPredictions.yml": {
      "imports": {
        "root": "__package__.yml",
      },
      "service": {
        "auth": false,
        "base-path": "",
        "display-name": "Get Job Predictions",
        "endpoints": {
          "get_job": {
            "auth": true,
            "display-name": "Get Job Details",
            "docs": "Get the request details and state of a given job.",
            "method": "GET",
            "pagination": undefined,
            "path": "/v0/batch/jobs/{id}",
            "path-parameters": {
              "id": "string",
            },
            "response": {
              "docs": "",
              "type": "root.JobRequest",
            },
          },
          "get_job_artifacts": {
            "auth": true,
            "display-name": "Get Job Artifacts",
            "docs": "Get the artifacts ZIP of a completed job.",
            "method": "GET",
            "pagination": undefined,
            "path": "/v0/batch/jobs/{id}/artifacts",
            "path-parameters": {
              "id": "string",
            },
            "response": {
              "docs": "",
              "type": "file",
            },
          },
        },
      },
    },
  },
  "packageMarkerFile": {
    "service": {
      "auth": false,
      "base-path": "",
      "endpoints": {
        "Get Job Predictions": {
          "auth": true,
          "display-name": "Get Job Predictions",
          "docs": "Get the JSON predictions of a completed job.",
          "examples": [
            {
              "path-parameters": {
                "id": "id",
              },
              "response": {
                "body": [],
              },
            },
          ],
          "method": "GET",
          "pagination": undefined,
          "path": "/v0/batch/jobs/{id}/predictions",
          "path-parameters": {
            "id": "string",
          },
          "response": {
            "docs": "",
            "type": "list<SourceResult>",
          },
        },
        "List Jobs": {
          "auth": true,
          "display-name": "List Jobs",
          "docs": "Sort and filter jobs.",
          "examples": [
            {
              "response": {
                "body": [],
              },
            },
          ],
          "method": "GET",
          "pagination": undefined,
          "path": "/v0/batch/jobs",
          "request": {
            "name": "ListJobsRequest",
            "query-parameters": {
              "direction": {
                "docs": "The sort direction.",
                "type": "optional<Direction>",
              },
              "limit": {
                "docs": "The maximum number of jobs to include in the response.",
                "type": "optional<integer>",
              },
              "sort_by": {
                "docs": "The job timestamp to sort by.",
                "type": "optional<SortBy>",
              },
              "status": {
                "allow-multiple": true,
                "docs": "Include only jobs with these statuses.",
                "type": "optional<Status>",
              },
              "timestamp_ms": {
                "docs": "Defaults to the current date and time. See \`when\`.",
                "type": "optional<long>",
              },
              "when": {
                "docs": "Include only jobs that were created before or after \`timestamp_ms\`.",
                "type": "optional<When>",
              },
            },
          },
          "response": {
            "docs": "",
            "type": "list<JobRequest>",
          },
        },
        "Start Job": {
          "auth": true,
          "display-name": "Start Job",
          "docs": "Start a new batch job.",
          "examples": [
            {
              "request": {},
              "response": {
                "body": {
                  "job_id": "job_id",
                },
              },
            },
          ],
          "method": "POST",
          "pagination": undefined,
          "path": "/v0/batch/jobs",
          "request": {
            "body": {
              "properties": {
                "callback_url": {
                  "docs": "If provided, a \`POST\` request will be made to the URL with the generated predictions on completion or the error message on failure.",
                  "type": "optional<string>",
                },
                "models": "optional<Models>",
                "notify": {
                  "default": false,
                  "docs": "Whether to send an email notification to the user upon job failure.",
                  "type": "optional<boolean>",
                },
                "transcription": "optional<Transcription>",
                "urls": {
                  "docs": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`) of media files.

If you wish to supply more than 100 URLs, consider providing them as an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`).",
                  "type": "optional<list<string>>",
                },
              },
            },
            "headers": undefined,
            "name": "BaseRequest",
            "query-parameters": undefined,
          },
          "response": {
            "docs": "",
            "type": "JobId",
          },
        },
      },
    },
    "types": {
      "Bcp47Tag": {
        "enum": [
          "zh",
          "da",
          "nl",
          "en",
          {
            "name": "EnAu",
            "value": "en-AU",
          },
          {
            "name": "EnIn",
            "value": "en-IN",
          },
          {
            "name": "EnNz",
            "value": "en-NZ",
          },
          {
            "name": "EnGb",
            "value": "en-GB",
          },
          "fr",
          {
            "name": "FrCa",
            "value": "fr-CA",
          },
          "de",
          "hi",
          {
            "name": "HiLatn",
            "value": "hi-Latn",
          },
          "id",
          "it",
          "ja",
          "ko",
          "no",
          "pl",
          "pt",
          {
            "name": "PtBr",
            "value": "pt-BR",
          },
          {
            "name": "PtPt",
            "value": "pt-PT",
          },
          "ru",
          "es",
          {
            "name": "Es419",
            "value": "es-419",
          },
          "sv",
          "ta",
          "tr",
          "uk",
        ],
      },
      "BoundingBox": {
        "docs": "A bounding box around a face.",
        "properties": {
          "h": {
            "docs": "Bounding box height.",
            "type": "double",
          },
          "w": {
            "docs": "Bounding box width.",
            "type": "double",
          },
          "x": {
            "docs": "x-coordinate of bounding box top left corner.",
            "type": "double",
          },
          "y": {
            "docs": "y-coordinate of bounding box top left corner.",
            "type": "double",
          },
        },
      },
      "BurstPrediction": {
        "docs": undefined,
        "properties": {
          "descriptions": {
            "docs": "Modality-specific descriptive features and their scores.",
            "type": "list<DescriptionsScore>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "time": "TimeInterval",
        },
      },
      "Completed": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "ended_timestamp_ms": {
            "docs": "When this job ended (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "num_errors": {
            "docs": "The number of errors that occurred while running this job.",
            "type": "integer",
          },
          "num_predictions": {
            "docs": "The number of predictions that were generated by this job.",
            "type": "integer",
          },
          "started_timestamp_ms": {
            "docs": "When this job started (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "DescriptionsScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Name of the descriptive feature being expressed.",
            "type": "string",
          },
          "score": {
            "docs": "Embedding value for the descriptive feature being expressed.",
            "type": "string",
          },
        },
      },
      "Direction": {
        "enum": [
          "asc",
          "desc",
        ],
      },
      "EmotionScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Name of the emotion being expressed.",
            "type": "string",
          },
          "score": {
            "docs": "Embedding value for the emotion being expressed.",
            "type": "string",
          },
        },
      },
      "Empty": {
        "docs": "To include predictions for this model type, set this field to \`{}\`. It is currently not configurable further.",
        "type": "map<string, unknown>",
      },
      "Error": {
        "docs": undefined,
        "properties": {
          "file": {
            "docs": "A file path relative to the top level source URL or file.",
            "type": "string",
          },
          "message": {
            "docs": "An error message.",
            "type": "string",
          },
        },
      },
      "Face": {
        "docs": undefined,
        "properties": {
          "descriptions": "optional<Empty>",
          "facs": "optional<Empty>",
          "fps_pred": {
            "default": 3,
            "docs": "Number of frames per second to process. Other frames will be omitted from the response. Set to \`0\` to process every frame.",
            "type": "optional<double>",
          },
          "identify_faces": {
            "default": false,
            "docs": "Whether to return identifiers for faces across frames. If \`true\`, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If \`false\`, all faces will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
          "min_face_size": {
            "docs": "Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response.",
            "type": "optional<uint64>",
          },
          "prob_threshold": {
            "default": 0.99,
            "docs": "Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response.",
            "type": "optional<double>",
            "validation": {
              "exclusiveMax": undefined,
              "exclusiveMin": undefined,
              "max": 1,
              "min": 0,
              "multipleOf": undefined,
            },
          },
          "save_faces": {
            "default": false,
            "docs": "Whether to extract and save the detected faces in the artifacts zip created by each job.",
            "type": "optional<boolean>",
          },
        },
      },
      "FacePrediction": {
        "docs": undefined,
        "properties": {
          "box": "BoundingBox",
          "descriptions": {
            "docs": "Modality-specific descriptive features and their scores.",
            "type": "optional<list<DescriptionsScore>>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "facs": {
            "docs": "FACS 2.0 features and their scores.",
            "type": "optional<list<FacsScore>>",
          },
          "frame": {
            "docs": "Frame number",
            "type": "uint64",
          },
          "prob": {
            "docs": "The predicted probability that a detected face was actually a face.",
            "type": "double",
          },
          "time": {
            "docs": "Time in seconds when face detection occurred.",
            "type": "double",
          },
        },
      },
      "FacemeshPrediction": {
        "docs": undefined,
        "properties": {
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
        },
      },
      "FacsScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Name of the FACS 2.0 feature being expressed.",
            "type": "string",
          },
          "score": {
            "docs": "Embedding value for the FACS 2.0 feature being expressed.",
            "type": "string",
          },
        },
      },
      "Failed": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "ended_timestamp_ms": {
            "docs": "When this job ended (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "message": {
            "docs": "An error message.",
            "type": "string",
          },
          "started_timestamp_ms": {
            "docs": "When this job started (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "File": {
        "docs": undefined,
        "properties": {
          "content_type": {
            "docs": "The content type of the file.",
            "type": "optional<string>",
          },
          "filename": {
            "docs": "The name of the file.",
            "type": "optional<string>",
          },
          "md5sum": {
            "docs": "The MD5 checksum of the file.",
            "type": "string",
          },
        },
      },
      "Granularity": {
        "docs": "The granularity at which to generate predictions. \`utterance\` corresponds to a natural pause or break in conversation, while \`conversational_turn\` corresponds to a change in speaker.",
        "enum": [
          "word",
          "sentence",
          "utterance",
          "conversational_turn",
        ],
      },
      "GroupedPredictionsBurstPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<BurstPrediction>",
        },
      },
      "GroupedPredictionsFacePrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<FacePrediction>",
        },
      },
      "GroupedPredictionsFacemeshPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<FacemeshPrediction>",
        },
      },
      "GroupedPredictionsLanguagePrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<LanguagePrediction>",
        },
      },
      "GroupedPredictionsNerPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<NerPrediction>",
        },
      },
      "GroupedPredictionsProsodyPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<ProsodyPrediction>",
        },
      },
      "InProgress": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "started_timestamp_ms": {
            "docs": "When this job started (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "JobId": {
        "docs": undefined,
        "properties": {
          "job_id": {
            "docs": "The ID of the started job.",
            "type": "string",
            "validation": {
              "format": "uuid",
              "maxLength": undefined,
              "minLength": undefined,
              "pattern": undefined,
            },
          },
        },
      },
      "JobRequest": {
        "docs": undefined,
        "properties": {
          "job_id": {
            "docs": "The ID associated with this job.",
            "type": "string",
            "validation": {
              "format": "uuid",
              "maxLength": undefined,
              "minLength": undefined,
              "pattern": undefined,
            },
          },
          "request": "Request",
          "state": "State",
          "user_id": {
            "docs": "Your user ID.",
            "type": "string",
            "validation": {
              "format": "uuid",
              "maxLength": undefined,
              "minLength": undefined,
              "pattern": undefined,
            },
          },
        },
      },
      "Language": {
        "docs": undefined,
        "properties": {
          "granularity": "optional<Granularity>",
          "identify_speakers": {
            "default": false,
            "docs": "Whether to return identifiers for speakers over time. If \`true\`, unique identifiers will be assigned to spoken words to differentiate different speakers. If \`false\`, all speakers will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
          "sentiment": "optional<Empty>",
          "toxicity": "optional<Empty>",
        },
      },
      "LanguagePrediction": {
        "docs": undefined,
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence in this text.",
            "type": "optional<double>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "position": "PositionInterval",
          "sentiment": {
            "docs": "Sentiment predictions returned as a distribution. This model predicts the probability that a given text could be interpreted as having each sentiment level from \`1\` (negative) to \`9\` (positive).

Compared to returning one estimate of sentiment, this enables a more nuanced analysis of a text's meaning. For example, a text with very neutral sentiment would have an average rating of \`5\`. But also a text that could be interpreted as having very positive sentiment or very negative sentiment would also have an average rating of \`5\`. The average sentiment is less informative than the distribution over sentiment, so this API returns a value for each sentiment level.",
            "type": "optional<list<SentimentScore>>",
          },
          "speaker_confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
            "type": "optional<double>",
          },
          "text": {
            "docs": "A segment of text (like a word or a sentence).",
            "type": "string",
          },
          "time": "optional<TimeInterval>",
          "toxicity": {
            "docs": "Toxicity predictions returned as probabilities that the text can be classified into the following categories: \`toxic\`, \`severe_toxic\`, \`obscene\`, \`threat\`, \`insult\`, and \`identity_hate\`.",
            "type": "optional<list<ToxicityScore>>",
          },
        },
      },
      "Models": {
        "docs": undefined,
        "properties": {
          "burst": "optional<Empty>",
          "face": "optional<Face>",
          "facemesh": "optional<Empty>",
          "language": "optional<Language>",
          "ner": "optional<Ner>",
          "prosody": "optional<Prosody>",
        },
      },
      "ModelsPredictions": {
        "docs": undefined,
        "properties": {
          "burst": "optional<PredictionsOptionalNullBurstPrediction>",
          "face": "optional<PredictionsOptionalNullFacePrediction>",
          "facemesh": "optional<PredictionsOptionalNullFacemeshPrediction>",
          "language": "optional<PredictionsOptionalTranscriptionMetadataLanguagePrediction>",
          "ner": "optional<PredictionsOptionalTranscriptionMetadataNerPrediction>",
          "prosody": "optional<PredictionsOptionalTranscriptionMetadataProsodyPrediction>",
        },
      },
      "Ner": {
        "docs": undefined,
        "properties": {
          "identify_speakers": {
            "default": false,
            "docs": "Whether to return identifiers for speakers over time. If \`true\`, unique identifiers will be assigned to spoken words to differentiate different speakers. If \`false\`, all speakers will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
        },
      },
      "NerPrediction": {
        "docs": undefined,
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence in this text.",
            "type": "optional<double>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "entity": {
            "docs": "The recognized topic or entity.",
            "type": "string",
          },
          "entity_confidence": {
            "docs": "Our NER model's relative confidence in the recognized topic or entity.",
            "type": "double",
          },
          "link_word": {
            "docs": "The specific word to which the emotion predictions are linked.",
            "type": "string",
          },
          "position": "PositionInterval",
          "speaker_confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
            "type": "optional<double>",
          },
          "support": {
            "docs": "A measure of how often the entity is linked to by other entities.",
            "type": "double",
          },
          "time": "optional<TimeInterval>",
          "uri": {
            "docs": "A URL which provides more information about the recognized topic or entity.",
            "type": "string",
          },
        },
      },
      "Null": {
        "docs": "No associated metadata for this model. Value will be \`null\`.",
        "type": "map<string, unknown>",
      },
      "PositionInterval": {
        "docs": "Position of a segment of text within a larger document, measured in characters. Uses zero-based indexing. The beginning index is inclusive and the end index is exclusive.",
        "properties": {
          "begin": {
            "docs": "The index of the first character in the text segment, inclusive.",
            "type": "uint64",
          },
          "end": {
            "docs": "The index of the last character in the text segment, exclusive.",
            "type": "uint64",
          },
        },
      },
      "Prediction": {
        "docs": undefined,
        "properties": {
          "file": {
            "docs": "A file path relative to the top level source URL or file.",
            "type": "string",
          },
          "models": "ModelsPredictions",
        },
      },
      "PredictionsOptionalNullBurstPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsBurstPrediction>",
          "metadata": "optional<Null>",
        },
      },
      "PredictionsOptionalNullFacePrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsFacePrediction>",
          "metadata": "optional<Null>",
        },
      },
      "PredictionsOptionalNullFacemeshPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsFacemeshPrediction>",
          "metadata": "optional<Null>",
        },
      },
      "PredictionsOptionalTranscriptionMetadataLanguagePrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsLanguagePrediction>",
          "metadata": "optional<TranscriptionMetadata>",
        },
      },
      "PredictionsOptionalTranscriptionMetadataNerPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsNerPrediction>",
          "metadata": "optional<TranscriptionMetadata>",
        },
      },
      "PredictionsOptionalTranscriptionMetadataProsodyPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsProsodyPrediction>",
          "metadata": "optional<TranscriptionMetadata>",
        },
      },
      "Prosody": {
        "docs": "NOTE: the \`granularity\` field is ignored if transcription is not enabled or if the \`window\` field has been set.",
        "properties": {
          "granularity": "optional<Granularity>",
          "identify_speakers": {
            "default": false,
            "docs": "Whether to return identifiers for speakers over time. If \`true\`, unique identifiers will be assigned to spoken words to differentiate different speakers. If \`false\`, all speakers will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
          "window": "optional<Window>",
        },
      },
      "ProsodyPrediction": {
        "docs": undefined,
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence in this text.",
            "type": "optional<double>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "speaker_confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
            "type": "optional<double>",
          },
          "text": {
            "docs": "A segment of text (like a word or a sentence).",
            "type": "optional<string>",
          },
          "time": "TimeInterval",
        },
      },
      "Queued": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "Request": {
        "docs": undefined,
        "properties": {
          "callback_url": {
            "docs": "If provided, a \`POST\` request will be made to the URL with the generated predictions on completion or the error message on failure.",
            "type": "optional<string>",
          },
          "files": "list<File>",
          "models": "optional<Models>",
          "notify": {
            "default": false,
            "docs": "Whether to send an email notification to the user upon job completion/failure.",
            "type": "optional<boolean>",
          },
          "transcription": "optional<Transcription>",
          "urls": {
            "docs": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`) of media files.

If you wish to supply more than 100 URLs, consider providing them as an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`).",
            "type": "optional<list<string>>",
          },
        },
      },
      "Results": {
        "docs": undefined,
        "properties": {
          "errors": "list<Error>",
          "predictions": "list<Prediction>",
        },
      },
      "SentimentScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Level of sentiment, ranging from \`1\` (negative) to \`9\` (positive)",
            "type": "string",
          },
          "score": {
            "docs": "Prediction for this level of sentiment",
            "type": "string",
          },
        },
      },
      "SortBy": {
        "enum": [
          "created",
          "started",
          "ended",
        ],
      },
      "Source": {
        "base-properties": {},
        "discriminant": "type",
        "docs": undefined,
        "union": {
          "file": "SourceFile",
          "url": "SourceUrl",
        },
      },
      "SourceFile": {
        "docs": undefined,
        "extends": [
          "File",
        ],
        "properties": {},
      },
      "SourceResult": {
        "docs": undefined,
        "properties": {
          "error": {
            "docs": "An error message.",
            "type": "optional<string>",
          },
          "results": "optional<Results>",
          "source": "Source",
        },
      },
      "SourceUrl": {
        "docs": undefined,
        "extends": [
          "Url",
        ],
        "properties": {},
      },
      "State": {
        "base-properties": {},
        "discriminant": "status",
        "docs": undefined,
        "union": {
          "COMPLETED": "StateCompleted",
          "FAILED": "StateFailed",
          "IN_PROGRESS": "StateInProgress",
          "QUEUED": "StateQueued",
        },
      },
      "StateCompleted": {
        "docs": undefined,
        "extends": [
          "Completed",
        ],
        "properties": {},
      },
      "StateFailed": {
        "docs": undefined,
        "extends": [
          "Failed",
        ],
        "properties": {},
      },
      "StateInProgress": {
        "docs": undefined,
        "extends": [
          "InProgress",
        ],
        "properties": {},
      },
      "StateQueued": {
        "docs": undefined,
        "extends": [
          "Queued",
        ],
        "properties": {},
      },
      "Status": {
        "enum": [
          "QUEUED",
          "IN_PROGRESS",
          "COMPLETED",
          "FAILED",
        ],
      },
      "TimeInterval": {
        "docs": "A time range with a beginning and end, measured in seconds.",
        "properties": {
          "begin": {
            "docs": "Beginning of time range in seconds.",
            "type": "double",
          },
          "end": {
            "docs": "End of time range in seconds.",
            "type": "double",
          },
        },
      },
      "ToxicityScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Category of toxicity.",
            "type": "string",
          },
          "score": {
            "docs": "Prediction for this category of toxicity",
            "type": "string",
          },
        },
      },
      "Transcription": {
        "docs": undefined,
        "properties": {
          "language": "optional<Bcp47Tag>",
        },
      },
      "TranscriptionMetadata": {
        "docs": "Transcription metadata for your media file.",
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` indicating our transcription model’s relative confidence in the transcription of your media file.",
            "type": "double",
          },
          "detected_language": "optional<Bcp47Tag>",
        },
      },
      "Url": {
        "docs": undefined,
        "properties": {
          "url": {
            "docs": "The URL of the source media file.",
            "type": "string",
          },
        },
      },
      "When": {
        "enum": [
          "created_before",
          "created_after",
        ],
      },
      "Window": {
        "docs": undefined,
        "properties": {
          "length": {
            "default": 4,
            "docs": "The length of the sliding window.",
            "type": "optional<double>",
            "validation": {
              "exclusiveMax": undefined,
              "exclusiveMin": undefined,
              "max": undefined,
              "min": 0.5,
              "multipleOf": undefined,
            },
          },
          "step": {
            "default": 1,
            "docs": "The step size of the sliding window.",
            "type": "optional<double>",
            "validation": {
              "exclusiveMax": undefined,
              "exclusiveMin": undefined,
              "max": undefined,
              "min": 0.5,
              "multipleOf": undefined,
            },
          },
        },
      },
    },
  },
  "rootApiFile": {
    "auth": "Authentication",
    "auth-schemes": {
      "Authentication": {
        "header": "X-Hume-Api-Key",
        "name": "apiKey",
        "type": "string",
      },
    },
    "default-environment": "Default",
    "display-name": "Hume AI Batch API",
    "environments": {
      "Default": "https://api.hume.ai",
    },
    "error-discrimination": {
      "strategy": "status-code",
    },
    "name": "api",
  },
}
`;

exports[`open api parser hume simple 1`] = `
{
  "definitionFiles": {
    "getJobPredictions.yml": {
      "imports": {
        "root": "__package__.yml",
      },
      "service": {
        "auth": false,
        "base-path": "",
        "display-name": "Get Job Predictions",
        "endpoints": {
          "get_job": {
            "auth": true,
            "display-name": "Get Job Details",
            "docs": "Get the request details and state of a given job.",
            "method": "GET",
            "pagination": undefined,
            "path": "/v0/batch/jobs/{id}",
            "path-parameters": {
              "id": "string",
            },
            "response": {
              "docs": "",
              "type": "root.JobRequest",
            },
          },
          "get_job_artifacts": {
            "auth": true,
            "display-name": "Get Job Artifacts",
            "docs": "Get the artifacts ZIP of a completed job.",
            "method": "GET",
            "pagination": undefined,
            "path": "/v0/batch/jobs/{id}/artifacts",
            "path-parameters": {
              "id": "string",
            },
            "response": {
              "docs": "",
              "type": "file",
            },
          },
        },
      },
    },
  },
  "packageMarkerFile": {
    "service": {
      "auth": false,
      "base-path": "",
      "endpoints": {
        "Get Job Predictions": {
          "auth": true,
          "display-name": "Get Job Predictions",
          "docs": "Get the JSON predictions of a completed job.",
          "examples": [
            {
              "path-parameters": {
                "id": "id",
              },
              "response": {
                "body": [],
              },
            },
          ],
          "method": "GET",
          "pagination": undefined,
          "path": "/v0/batch/jobs/{id}/predictions",
          "path-parameters": {
            "id": "string",
          },
          "response": {
            "docs": "",
            "type": "list<SourceResult>",
          },
        },
        "List Jobs": {
          "auth": true,
          "display-name": "List Jobs",
          "docs": "Sort and filter jobs.",
          "examples": [
            {
              "response": {
                "body": [],
              },
            },
          ],
          "method": "GET",
          "pagination": undefined,
          "path": "/v0/batch/jobs",
          "request": {
            "name": "ListJobsRequest",
            "query-parameters": {
              "direction": {
                "docs": "The sort direction.",
                "type": "optional<Direction>",
              },
              "limit": {
                "docs": "The maximum number of jobs to include in the response.",
                "type": "optional<integer>",
              },
              "sort_by": {
                "docs": "The job timestamp to sort by.",
                "type": "optional<SortBy>",
              },
              "status": {
                "allow-multiple": true,
                "docs": "Include only jobs with these statuses.",
                "type": "optional<Status>",
              },
              "timestamp_ms": {
                "docs": "Defaults to the current date and time. See \`when\`.",
                "type": "optional<long>",
              },
              "when": {
                "docs": "Include only jobs that were created before or after \`timestamp_ms\`.",
                "type": "optional<When>",
              },
            },
          },
          "response": {
            "docs": "",
            "type": "list<JobRequest>",
          },
        },
        "Start Job": {
          "auth": true,
          "display-name": "Start Job",
          "docs": "Start a new batch job.",
          "examples": [
            {
              "request": {},
              "response": {
                "body": {
                  "job_id": "job_id",
                },
              },
            },
          ],
          "method": "POST",
          "pagination": undefined,
          "path": "/v0/batch/jobs",
          "request": {
            "body": {
              "properties": {
                "callback_url": {
                  "docs": "If provided, a \`POST\` request will be made to the URL with the generated predictions on completion or the error message on failure.",
                  "type": "optional<string>",
                },
                "models": "optional<Models>",
                "notify": {
                  "default": false,
                  "docs": "Whether to send an email notification to the user upon job failure.",
                  "type": "optional<boolean>",
                },
                "transcription": "optional<Transcription>",
                "urls": {
                  "docs": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`) of media files.

If you wish to supply more than 100 URLs, consider providing them as an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`).",
                  "type": "optional<list<string>>",
                },
              },
            },
            "headers": undefined,
            "name": "BaseRequest",
            "query-parameters": undefined,
          },
          "response": {
            "docs": "",
            "type": "JobId",
          },
        },
      },
    },
    "types": {
      "Bcp47Tag": {
        "enum": [
          "zh",
          "da",
          "nl",
          "en",
          {
            "name": "EnAu",
            "value": "en-AU",
          },
          {
            "name": "EnIn",
            "value": "en-IN",
          },
          {
            "name": "EnNz",
            "value": "en-NZ",
          },
          {
            "name": "EnGb",
            "value": "en-GB",
          },
          "fr",
          {
            "name": "FrCa",
            "value": "fr-CA",
          },
          "de",
          "hi",
          {
            "name": "HiLatn",
            "value": "hi-Latn",
          },
          "id",
          "it",
          "ja",
          "ko",
          "no",
          "pl",
          "pt",
          {
            "name": "PtBr",
            "value": "pt-BR",
          },
          {
            "name": "PtPt",
            "value": "pt-PT",
          },
          "ru",
          "es",
          {
            "name": "Es419",
            "value": "es-419",
          },
          "sv",
          "ta",
          "tr",
          "uk",
        ],
      },
      "BoundingBox": {
        "docs": "A bounding box around a face.",
        "properties": {
          "h": {
            "docs": "Bounding box height.",
            "type": "double",
          },
          "w": {
            "docs": "Bounding box width.",
            "type": "double",
          },
          "x": {
            "docs": "x-coordinate of bounding box top left corner.",
            "type": "double",
          },
          "y": {
            "docs": "y-coordinate of bounding box top left corner.",
            "type": "double",
          },
        },
      },
      "BurstPrediction": {
        "docs": undefined,
        "properties": {
          "descriptions": {
            "docs": "Modality-specific descriptive features and their scores.",
            "type": "list<DescriptionsScore>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "time": "TimeInterval",
        },
      },
      "Completed": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "ended_timestamp_ms": {
            "docs": "When this job ended (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "num_errors": {
            "docs": "The number of errors that occurred while running this job.",
            "type": "integer",
          },
          "num_predictions": {
            "docs": "The number of predictions that were generated by this job.",
            "type": "integer",
          },
          "started_timestamp_ms": {
            "docs": "When this job started (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "DescriptionsScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Name of the descriptive feature being expressed.",
            "type": "string",
          },
          "score": {
            "docs": "Embedding value for the descriptive feature being expressed.",
            "type": "string",
          },
        },
      },
      "Direction": {
        "enum": [
          "asc",
          "desc",
        ],
      },
      "EmotionScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Name of the emotion being expressed.",
            "type": "string",
          },
          "score": {
            "docs": "Embedding value for the emotion being expressed.",
            "type": "string",
          },
        },
      },
      "Empty": {
        "docs": "To include predictions for this model type, set this field to \`{}\`. It is currently not configurable further.",
        "type": "map<string, unknown>",
      },
      "Error": {
        "docs": undefined,
        "properties": {
          "file": {
            "docs": "A file path relative to the top level source URL or file.",
            "type": "string",
          },
          "message": {
            "docs": "An error message.",
            "type": "string",
          },
        },
      },
      "Face": {
        "docs": undefined,
        "properties": {
          "descriptions": "optional<Empty>",
          "facs": "optional<Empty>",
          "fps_pred": {
            "default": 3,
            "docs": "Number of frames per second to process. Other frames will be omitted from the response. Set to \`0\` to process every frame.",
            "type": "optional<double>",
          },
          "identify_faces": {
            "default": false,
            "docs": "Whether to return identifiers for faces across frames. If \`true\`, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If \`false\`, all faces will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
          "min_face_size": {
            "docs": "Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response.",
            "type": "optional<uint64>",
          },
          "prob_threshold": {
            "default": 0.99,
            "docs": "Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response.",
            "type": "optional<double>",
            "validation": {
              "exclusiveMax": undefined,
              "exclusiveMin": undefined,
              "max": 1,
              "min": 0,
              "multipleOf": undefined,
            },
          },
          "save_faces": {
            "default": false,
            "docs": "Whether to extract and save the detected faces in the artifacts zip created by each job.",
            "type": "optional<boolean>",
          },
        },
      },
      "FacePrediction": {
        "docs": undefined,
        "properties": {
          "box": "BoundingBox",
          "descriptions": {
            "docs": "Modality-specific descriptive features and their scores.",
            "type": "optional<list<DescriptionsScore>>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "facs": {
            "docs": "FACS 2.0 features and their scores.",
            "type": "optional<list<FacsScore>>",
          },
          "frame": {
            "docs": "Frame number",
            "type": "uint64",
          },
          "prob": {
            "docs": "The predicted probability that a detected face was actually a face.",
            "type": "double",
          },
          "time": {
            "docs": "Time in seconds when face detection occurred.",
            "type": "double",
          },
        },
      },
      "FacemeshPrediction": {
        "docs": undefined,
        "properties": {
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
        },
      },
      "FacsScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Name of the FACS 2.0 feature being expressed.",
            "type": "string",
          },
          "score": {
            "docs": "Embedding value for the FACS 2.0 feature being expressed.",
            "type": "string",
          },
        },
      },
      "Failed": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "ended_timestamp_ms": {
            "docs": "When this job ended (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "message": {
            "docs": "An error message.",
            "type": "string",
          },
          "started_timestamp_ms": {
            "docs": "When this job started (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "File": {
        "docs": undefined,
        "properties": {
          "content_type": {
            "docs": "The content type of the file.",
            "type": "optional<string>",
          },
          "filename": {
            "docs": "The name of the file.",
            "type": "optional<string>",
          },
          "md5sum": {
            "docs": "The MD5 checksum of the file.",
            "type": "string",
          },
        },
      },
      "Granularity": {
        "docs": "The granularity at which to generate predictions. \`utterance\` corresponds to a natural pause or break in conversation, while \`conversational_turn\` corresponds to a change in speaker.",
        "enum": [
          "word",
          "sentence",
          "utterance",
          "conversational_turn",
        ],
      },
      "GroupedPredictionsBurstPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<BurstPrediction>",
        },
      },
      "GroupedPredictionsFacePrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<FacePrediction>",
        },
      },
      "GroupedPredictionsFacemeshPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<FacemeshPrediction>",
        },
      },
      "GroupedPredictionsLanguagePrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<LanguagePrediction>",
        },
      },
      "GroupedPredictionsNerPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<NerPrediction>",
        },
      },
      "GroupedPredictionsProsodyPrediction": {
        "docs": undefined,
        "properties": {
          "id": {
            "docs": "An automatically generated label to identify individuals in your media file. Will be \`unknown\` if you have chosen to disable identification, or if the model is unable to distinguish between individuals.",
            "type": "string",
          },
          "predictions": "list<ProsodyPrediction>",
        },
      },
      "InProgress": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
          "started_timestamp_ms": {
            "docs": "When this job started (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "JobId": {
        "docs": undefined,
        "properties": {
          "job_id": {
            "docs": "The ID of the started job.",
            "type": "string",
            "validation": {
              "format": "uuid",
              "maxLength": undefined,
              "minLength": undefined,
              "pattern": undefined,
            },
          },
        },
      },
      "JobRequest": {
        "docs": undefined,
        "properties": {
          "job_id": {
            "docs": "The ID associated with this job.",
            "type": "string",
            "validation": {
              "format": "uuid",
              "maxLength": undefined,
              "minLength": undefined,
              "pattern": undefined,
            },
          },
          "request": "Request",
          "state": "State",
          "user_id": {
            "docs": "Your user ID.",
            "type": "string",
            "validation": {
              "format": "uuid",
              "maxLength": undefined,
              "minLength": undefined,
              "pattern": undefined,
            },
          },
        },
      },
      "Language": {
        "docs": undefined,
        "properties": {
          "granularity": "optional<Granularity>",
          "identify_speakers": {
            "default": false,
            "docs": "Whether to return identifiers for speakers over time. If \`true\`, unique identifiers will be assigned to spoken words to differentiate different speakers. If \`false\`, all speakers will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
          "sentiment": "optional<Empty>",
          "toxicity": "optional<Empty>",
        },
      },
      "LanguagePrediction": {
        "docs": undefined,
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence in this text.",
            "type": "optional<double>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "position": "PositionInterval",
          "sentiment": {
            "docs": "Sentiment predictions returned as a distribution. This model predicts the probability that a given text could be interpreted as having each sentiment level from \`1\` (negative) to \`9\` (positive).

Compared to returning one estimate of sentiment, this enables a more nuanced analysis of a text's meaning. For example, a text with very neutral sentiment would have an average rating of \`5\`. But also a text that could be interpreted as having very positive sentiment or very negative sentiment would also have an average rating of \`5\`. The average sentiment is less informative than the distribution over sentiment, so this API returns a value for each sentiment level.",
            "type": "optional<list<SentimentScore>>",
          },
          "speaker_confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
            "type": "optional<double>",
          },
          "text": {
            "docs": "A segment of text (like a word or a sentence).",
            "type": "string",
          },
          "time": "optional<TimeInterval>",
          "toxicity": {
            "docs": "Toxicity predictions returned as probabilities that the text can be classified into the following categories: \`toxic\`, \`severe_toxic\`, \`obscene\`, \`threat\`, \`insult\`, and \`identity_hate\`.",
            "type": "optional<list<ToxicityScore>>",
          },
        },
      },
      "Models": {
        "docs": undefined,
        "properties": {
          "burst": "optional<Empty>",
          "face": "optional<Face>",
          "facemesh": "optional<Empty>",
          "language": "optional<Language>",
          "ner": "optional<Ner>",
          "prosody": "optional<Prosody>",
        },
      },
      "ModelsPredictions": {
        "docs": undefined,
        "properties": {
          "burst": "optional<PredictionsOptionalNullBurstPrediction>",
          "face": "optional<PredictionsOptionalNullFacePrediction>",
          "facemesh": "optional<PredictionsOptionalNullFacemeshPrediction>",
          "language": "optional<PredictionsOptionalTranscriptionMetadataLanguagePrediction>",
          "ner": "optional<PredictionsOptionalTranscriptionMetadataNerPrediction>",
          "prosody": "optional<PredictionsOptionalTranscriptionMetadataProsodyPrediction>",
        },
      },
      "Ner": {
        "docs": undefined,
        "properties": {
          "identify_speakers": {
            "default": false,
            "docs": "Whether to return identifiers for speakers over time. If \`true\`, unique identifiers will be assigned to spoken words to differentiate different speakers. If \`false\`, all speakers will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
        },
      },
      "NerPrediction": {
        "docs": undefined,
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence in this text.",
            "type": "optional<double>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "entity": {
            "docs": "The recognized topic or entity.",
            "type": "string",
          },
          "entity_confidence": {
            "docs": "Our NER model's relative confidence in the recognized topic or entity.",
            "type": "double",
          },
          "link_word": {
            "docs": "The specific word to which the emotion predictions are linked.",
            "type": "string",
          },
          "position": "PositionInterval",
          "speaker_confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
            "type": "optional<double>",
          },
          "support": {
            "docs": "A measure of how often the entity is linked to by other entities.",
            "type": "double",
          },
          "time": "optional<TimeInterval>",
          "uri": {
            "docs": "A URL which provides more information about the recognized topic or entity.",
            "type": "string",
          },
        },
      },
      "Null": {
        "docs": "No associated metadata for this model. Value will be \`null\`.",
        "type": "map<string, unknown>",
      },
      "PositionInterval": {
        "docs": "Position of a segment of text within a larger document, measured in characters. Uses zero-based indexing. The beginning index is inclusive and the end index is exclusive.",
        "properties": {
          "begin": {
            "docs": "The index of the first character in the text segment, inclusive.",
            "type": "uint64",
          },
          "end": {
            "docs": "The index of the last character in the text segment, exclusive.",
            "type": "uint64",
          },
        },
      },
      "Prediction": {
        "docs": undefined,
        "properties": {
          "file": {
            "docs": "A file path relative to the top level source URL or file.",
            "type": "string",
          },
          "models": "ModelsPredictions",
        },
      },
      "PredictionsOptionalNullBurstPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsBurstPrediction>",
          "metadata": "optional<Null>",
        },
      },
      "PredictionsOptionalNullFacePrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsFacePrediction>",
          "metadata": "optional<Null>",
        },
      },
      "PredictionsOptionalNullFacemeshPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsFacemeshPrediction>",
          "metadata": "optional<Null>",
        },
      },
      "PredictionsOptionalTranscriptionMetadataLanguagePrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsLanguagePrediction>",
          "metadata": "optional<TranscriptionMetadata>",
        },
      },
      "PredictionsOptionalTranscriptionMetadataNerPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsNerPrediction>",
          "metadata": "optional<TranscriptionMetadata>",
        },
      },
      "PredictionsOptionalTranscriptionMetadataProsodyPrediction": {
        "docs": undefined,
        "properties": {
          "grouped_predictions": "list<GroupedPredictionsProsodyPrediction>",
          "metadata": "optional<TranscriptionMetadata>",
        },
      },
      "Prosody": {
        "docs": "NOTE: the \`granularity\` field is ignored if transcription is not enabled or if the \`window\` field has been set.",
        "properties": {
          "granularity": "optional<Granularity>",
          "identify_speakers": {
            "default": false,
            "docs": "Whether to return identifiers for speakers over time. If \`true\`, unique identifiers will be assigned to spoken words to differentiate different speakers. If \`false\`, all speakers will be tagged with an \`unknown\` ID.",
            "type": "optional<boolean>",
          },
          "window": "optional<Window>",
        },
      },
      "ProsodyPrediction": {
        "docs": undefined,
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence in this text.",
            "type": "optional<double>",
          },
          "emotions": {
            "docs": "A high-dimensional embedding in emotion space.",
            "type": "list<EmotionScore>",
          },
          "speaker_confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` that indicates our transcription model’s relative confidence that this text was spoken by this speaker.",
            "type": "optional<double>",
          },
          "text": {
            "docs": "A segment of text (like a word or a sentence).",
            "type": "optional<string>",
          },
          "time": "TimeInterval",
        },
      },
      "Queued": {
        "docs": undefined,
        "properties": {
          "created_timestamp_ms": {
            "docs": "When this job was created (Unix timestamp in milliseconds).",
            "type": "long",
          },
        },
      },
      "Request": {
        "docs": undefined,
        "properties": {
          "callback_url": {
            "docs": "If provided, a \`POST\` request will be made to the URL with the generated predictions on completion or the error message on failure.",
            "type": "optional<string>",
          },
          "files": "list<File>",
          "models": "optional<Models>",
          "notify": {
            "default": false,
            "docs": "Whether to send an email notification to the user upon job completion/failure.",
            "type": "optional<boolean>",
          },
          "transcription": "optional<Transcription>",
          "urls": {
            "docs": "URLs to the media files to be processed. Each must be a valid public URL to a media file (see recommended input filetypes) or an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`) of media files.

If you wish to supply more than 100 URLs, consider providing them as an archive (\`.zip\`, \`.tar.gz\`, \`.tar.bz2\`, \`.tar.xz\`).",
            "type": "optional<list<string>>",
          },
        },
      },
      "Results": {
        "docs": undefined,
        "properties": {
          "errors": "list<Error>",
          "predictions": "list<Prediction>",
        },
      },
      "SentimentScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Level of sentiment, ranging from \`1\` (negative) to \`9\` (positive)",
            "type": "string",
          },
          "score": {
            "docs": "Prediction for this level of sentiment",
            "type": "string",
          },
        },
      },
      "SortBy": {
        "enum": [
          "created",
          "started",
          "ended",
        ],
      },
      "Source": {
        "base-properties": {},
        "discriminant": "type",
        "docs": undefined,
        "union": {
          "file": "SourceFile",
          "url": "SourceUrl",
        },
      },
      "SourceFile": {
        "docs": undefined,
        "extends": [
          "File",
        ],
        "properties": {},
      },
      "SourceResult": {
        "docs": undefined,
        "properties": {
          "error": {
            "docs": "An error message.",
            "type": "optional<string>",
          },
          "results": "optional<Results>",
          "source": "Source",
        },
      },
      "SourceUrl": {
        "docs": undefined,
        "extends": [
          "Url",
        ],
        "properties": {},
      },
      "State": {
        "base-properties": {},
        "discriminant": "status",
        "docs": undefined,
        "union": {
          "COMPLETED": "StateCompleted",
          "FAILED": "StateFailed",
          "IN_PROGRESS": "StateInProgress",
          "QUEUED": "StateQueued",
        },
      },
      "StateCompleted": {
        "docs": undefined,
        "extends": [
          "Completed",
        ],
        "properties": {},
      },
      "StateFailed": {
        "docs": undefined,
        "extends": [
          "Failed",
        ],
        "properties": {},
      },
      "StateInProgress": {
        "docs": undefined,
        "extends": [
          "InProgress",
        ],
        "properties": {},
      },
      "StateQueued": {
        "docs": undefined,
        "extends": [
          "Queued",
        ],
        "properties": {},
      },
      "Status": {
        "enum": [
          "QUEUED",
          "IN_PROGRESS",
          "COMPLETED",
          "FAILED",
        ],
      },
      "TimeInterval": {
        "docs": "A time range with a beginning and end, measured in seconds.",
        "properties": {
          "begin": {
            "docs": "Beginning of time range in seconds.",
            "type": "double",
          },
          "end": {
            "docs": "End of time range in seconds.",
            "type": "double",
          },
        },
      },
      "ToxicityScore": {
        "docs": undefined,
        "properties": {
          "name": {
            "docs": "Category of toxicity.",
            "type": "string",
          },
          "score": {
            "docs": "Prediction for this category of toxicity",
            "type": "string",
          },
        },
      },
      "Transcription": {
        "docs": undefined,
        "properties": {
          "language": "optional<Bcp47Tag>",
        },
      },
      "TranscriptionMetadata": {
        "docs": "Transcription metadata for your media file.",
        "properties": {
          "confidence": {
            "docs": "Value between \`0.0\` and \`1.0\` indicating our transcription model’s relative confidence in the transcription of your media file.",
            "type": "double",
          },
          "detected_language": "optional<Bcp47Tag>",
        },
      },
      "Url": {
        "docs": undefined,
        "properties": {
          "url": {
            "docs": "The URL of the source media file.",
            "type": "string",
          },
        },
      },
      "When": {
        "enum": [
          "created_before",
          "created_after",
        ],
      },
      "Window": {
        "docs": undefined,
        "properties": {
          "length": {
            "default": 4,
            "docs": "The length of the sliding window.",
            "type": "optional<double>",
            "validation": {
              "exclusiveMax": undefined,
              "exclusiveMin": undefined,
              "max": undefined,
              "min": 0.5,
              "multipleOf": undefined,
            },
          },
          "step": {
            "default": 1,
            "docs": "The step size of the sliding window.",
            "type": "optional<double>",
            "validation": {
              "exclusiveMax": undefined,
              "exclusiveMin": undefined,
              "max": undefined,
              "min": 0.5,
              "multipleOf": undefined,
            },
          },
        },
      },
    },
  },
  "rootApiFile": {
    "auth": "Authentication",
    "auth-schemes": {
      "Authentication": {
        "header": "X-Hume-Api-Key",
        "name": "apiKey",
        "type": "string",
      },
    },
    "default-environment": "Default",
    "display-name": "Hume AI Batch API",
    "environments": {
      "Default": "https://api.hume.ai",
    },
    "error-discrimination": {
      "strategy": "status-code",
    },
    "name": "api",
  },
}
`;
